{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# 判别分析\n",
    "\n",
    "分类问题是机器学习的经典问题，这个问题在多元统计的经典形式就是判别分析，其基本都依赖了概率结构。\n",
    "虽然在机器学习算法眼里都是非常虚弱而且假设过强的算法。\n",
    "\n",
    "判别分析将分类看成一个总体，对于一个给定样本，尝试根据某些规则判定其来自哪个总体。这个总体一般建模为某个多元正态分布。\n",
    "样本是$p$维向量，在机器学习眼里看来是$p$个特征。判别分析认为期望与各个特征的协方差矩阵，与多元正态分布的结构足以刻画一个类的属性。\n",
    "然后把分类问题转化为问这个样本设为是哪个总体生成的最靠谱，并以此为结论。这个在稍微复杂一点的情况下就不靠谱了。\n",
    "当然无论如何，起码可以作为某个基线。\n",
    "\n",
    "## 距离判别\n",
    "\n",
    "既然用了多元正态分布总体刻画类，最自然的距离就是综合了各维“标准化违抗度”的马氏距离，\n",
    "\n",
    "$$\n",
    "(X - \\mu)^T \\Sigma^{-1} (X - \\mu)\n",
    "$$\n",
    "\n",
    "我们知道这个东西在假设的确成立时服从$\\chi^2(p)$分布。而不成立时会偏向更大，这正是我们要的性质，可以看成类似那种类置信区间的，\n",
    "从假设检验里反推出的东西。\n",
    "\n",
    "那么我们可以拿已知分类的数据，一堆标记了类型的p维向量各自估计它们的总体。来新的数据再计算对其的各个距离，取距离最小者为我们的判别结果。\n",
    "当然如果没有“最小”，即不存在一类它的距离比其他类的严格小，则视为“待判”，如果一定要判可以在最小距离集合里随机选一个。\n",
    "\n",
    "这个方法在总体不服从正态分布时也有意义，当然正态分布时两阶矩就控制了所有信息，其他分布就不一定了。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "library(klaR)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "library(MASS)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 贝叶斯判别\n",
    "\n",
    "贝叶斯判别就是把样本直接代入总体的密度函数，看似然度。这个可以加上先验概率校准（即使对各个分类得到相同的值），这样就可以凑成严格的贝叶斯形式。\n",
    "\n",
    "$$\n",
    "P(B_i|A) = \\frac{P(A|B_i)P(B_i)}{{\\sum_{j=1}^k P(A|B_j)P(B_j)}}\n",
    "$$\n",
    "\n",
    "其中$A$表示出现给定样本这个事件，$B_i$是样本属于$i$类的概率。我们所知道的是\n",
    "\n",
    "$$\n",
    "P(A|B_i) = f(x_0;\\mu_i,\\Sigma_i)\n",
    "$$\n",
    "\n",
    "为样本$x_0$出现在$i$类对应的多元正态分布总体的似然度。先验概率$P(B_i)$不适合用占训练集的比例估计，\n",
    "显然那样多加一些特定类样本把估计精确化居然会影响先验分布。如果不把训练集看成某种超总体抽样，就应该与其无关的设定先验概率，\n",
    "比如全部设成一样的直接消掉这个项。\n",
    "\n",
    "参数取$(\\mu,\\Sigma)$的多元正态分布的密度分布函数为\n",
    "\n",
    "$$\n",
    "f(X;\\mu,\\Sigma) = \\frac{1}{(2\\pi)^{p/2}|\\Sigma|^{1/2}} exp\\left( -\\frac{1}{2} (x - \\mu)^T \\Sigma^{-1} (x - \\mu) \\right)\n",
    "$$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 210,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "rcov <- function(n, r, Lam=NULL){\n",
    "    if(is.null(Lam)){\n",
    "        lam <- rep(0,n)\n",
    "        lam[1:r] <- runif(r,0.5,1.5)\n",
    "        Lam <- diag(lam)\n",
    "    }\n",
    "    A <- matrix(runif(n*n,-2,2),n)\n",
    "    return(t(A) %*% Lam %*% A)\n",
    "}\n",
    "\n",
    "rmultinorm <- function(n,mu,Sigma){\n",
    "    res <- eigen(Sigma)\n",
    "    Lambda <- diag(res$values)\n",
    "    P <- res$vectors\n",
    "    r <- replicate(n,as.vector( P %*% Lambda^(1/2) %*% rnorm(length(mu))) + mu)\n",
    "    return(r)\n",
    "}\n",
    "\n",
    "pTsq <- function(x, p, n, lower.tail=TRUE){\n",
    "    pf((n-p+1)/(p*n) * x, p, n-p+1, lower.tail = lower.tail)\n",
    "}\n",
    "\n",
    "qTsq <- function(x, p, n, lower.tail=TRUE){\n",
    "    y <- qf(x, p, n-p+1, lower.tail = lower.tail)\n",
    "    return((p*n)/(n-p+1) * y)\n",
    "}\n",
    "\n",
    "decomp <- function(X,group){\n",
    "    # X is (p,n) matrix, group is n dimention vector\n",
    "    Xbar <- NULL\n",
    "    for(g in unique(group)){\n",
    "        index <- group == g\n",
    "        ni <- sum(index)\n",
    "        #Xbari <- mean(X[,index],1)\n",
    "        Xbari <- apply(X[,index],1,mean)\n",
    "        Xbar <- cbind(Xbar, matrix(rep(Xbari,ni),nrow(X)))\n",
    "    }\n",
    "    #Xbarbar <- matrix(rep(mean(X,1),ncol(X)),nrow(X))\n",
    "    Xbarbar <- matrix(rep(apply(X,1,mean),ncol(X)),nrow(X))\n",
    "    B <- (Xbar - Xbarbar) %*% t(Xbar - Xbarbar)\n",
    "    E <- (X - Xbar) %*% t(X - Xbar)\n",
    "    W <- (X - Xbarbar) %*% t(X - Xbarbar)\n",
    "    return(list(B = B, E = E, W = W))\n",
    "}\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 211,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "dmultinorm <- function(x, mu, sigma){\n",
    "    p <- length(mu)\n",
    "    coe <- 1/( (2*pi)^(p/2) * sqrt(det(sigma)) )\n",
    "    power <- -1/2 * t(x - mu) %*% solve(sigma) %*% (x-mu)\n",
    "    return( coe * exp(power))\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 212,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td> 6.4820342 </td><td>-1.82517073</td><td> 4.834666  </td><td>-4.17773760</td><td> 0.3791943 </td></tr>\n",
       "\t<tr><td>-1.8251707 </td><td> 3.54742021</td><td>-1.716157  </td><td> 0.08646848</td><td> 2.6174671 </td></tr>\n",
       "\t<tr><td> 4.8346656 </td><td>-1.71615741</td><td> 7.941692  </td><td>-1.27622487</td><td>-1.6590497 </td></tr>\n",
       "\t<tr><td>-4.1777376 </td><td> 0.08646848</td><td>-1.276225  </td><td> 5.69160465</td><td>-2.0025422 </td></tr>\n",
       "\t<tr><td> 0.3791943 </td><td> 2.61746715</td><td>-1.659050  </td><td>-2.00254222</td><td> 3.9769276 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllll}\n",
       "\t  6.4820342  & -1.82517073 &  4.834666   & -4.17773760 &  0.3791943 \\\\\n",
       "\t -1.8251707  &  3.54742021 & -1.716157   &  0.08646848 &  2.6174671 \\\\\n",
       "\t  4.8346656  & -1.71615741 &  7.941692   & -1.27622487 & -1.6590497 \\\\\n",
       "\t -4.1777376  &  0.08646848 & -1.276225   &  5.69160465 & -2.0025422 \\\\\n",
       "\t  0.3791943  &  2.61746715 & -1.659050   & -2.00254222 &  3.9769276 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. 6.48203419486627\n",
       "2. -1.82517072755561\n",
       "3. 4.83466564413861\n",
       "4. -4.17773759966868\n",
       "5. 0.379194262497066\n",
       "6. -1.82517072755561\n",
       "7. 3.54742021198419\n",
       "8. -1.71615740971738\n",
       "9. 0.0864684806915852\n",
       "10. 2.61746714711459\n",
       "11. 4.83466564413861\n",
       "12. -1.71615740971738\n",
       "13. 7.94169175990711\n",
       "14. -1.27622487215314\n",
       "15. -1.6590497391319\n",
       "16. -4.17773759966868\n",
       "17. 0.0864684806915854\n",
       "18. -1.27622487215314\n",
       "19. 5.69160464820554\n",
       "20. -2.00254222331335\n",
       "21. 0.379194262497067\n",
       "22. 2.61746714711459\n",
       "23. -1.6590497391319\n",
       "24. -2.00254222331335\n",
       "25. 3.97692763003313\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]       [,2]        [,3]      [,4]        [,5]      \n",
       "[1,]  6.4820342 -1.82517073  4.834666 -4.17773760  0.3791943\n",
       "[2,] -1.8251707  3.54742021 -1.716157  0.08646848  2.6174671\n",
       "[3,]  4.8346656 -1.71615741  7.941692 -1.27622487 -1.6590497\n",
       "[4,] -4.1777376  0.08646848 -1.276225  5.69160465 -2.0025422\n",
       "[5,]  0.3791943  2.61746715 -1.659050 -2.00254222  3.9769276"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "Sigma <- rcov(5,5)\n",
    "Sigma"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 213,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "\t<li>0</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\item 0\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 0\n",
       "2. 0\n",
       "3. 0\n",
       "4. 0\n",
       "5. 0\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "[1] 0 0 0 0 0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "mu <- rep(0,5)\n",
    "mu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 214,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.0008423307</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.0008423307\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "0.00084233067095186"
      ],
      "text/plain": [
       "     [,1]        \n",
       "[1,] 0.0008423307"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dmultinorm(c(0,0,0,0,0),mu,Sigma)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>5.352016e-11</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 5.352016e-11\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "5.35201613257163e-11"
      ],
      "text/plain": [
       "     [,1]        \n",
       "[1,] 5.352016e-11"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "dmultinorm(c(1,2,3,4,5),mu,Sigma)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "结果与python的`scipy.stats.multivariate_normal.pdf`一致，验证了其正确性。\n",
    "\n",
    "## Fisher判别\n",
    "\n",
    "对于k个类共$n = \\sum_i^k n_i$个样本。向量经过一个$p$维列向量$a$线性投影$a^T x$后后变为单变量。我们想寻求一个这样的的$a$，\n",
    "其使得单变量方差检验的统计量$F$，最大化。显然这意味着$H_0$，即各总体均值相同的假设显得越假，\n",
    "也就是这个$a$的投影使得各总体在此投影下最分散开（通过均值）。\n",
    "\n",
    "$$\n",
    "F = \\frac{SSA / (k-1)}{SSE/(n-k)} = \\frac{n-k}{k-1}\\frac{a^T B a}{a^T E a}\n",
    "$$\n",
    "\n",
    "其中$a$是投影向量，这里的$B,E$就是之前满足分解$W = B + E$的组间离差阵和组内离差阵。\n",
    "\n",
    "抛掉在优化过程中固定的常数,我们就是控制$a$来最大化\n",
    "\n",
    "$$\n",
    "\\max_a \\frac{a^T B a}{a^T E a}\n",
    "$$\n",
    "\n",
    "可以证明\n",
    "\n",
    "$$\n",
    "W^{-1}B = (B + E)^{-1}B\n",
    "$$\n",
    "\n",
    "的前几个特征向量就是前几优的$a$，但特征值是$\\frac{a^T B a}{a^T W a}$的最优值（两个分式的最优$a$是一样的。）\n",
    "而不是$\\frac{a^T B a}{a^T E a}$的。（《实用多元统计》P513）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 216,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th><th scope=col>Petal.Length</th><th scope=col>Petal.Width</th><th scope=col>Species</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>5.1   </td><td>3.5   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.9   </td><td>3.0   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.7   </td><td>3.2   </td><td>1.3   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.6   </td><td>3.1   </td><td>1.5   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>5.0   </td><td>3.6   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>5.4   </td><td>3.9   </td><td>1.7   </td><td>0.4   </td><td>setosa</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Sepal.Length & Sepal.Width & Petal.Length & Petal.Width & Species\\\\\n",
       "\\hline\n",
       "\t 5.1    & 3.5    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 4.9    & 3.0    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 4.7    & 3.2    & 1.3    & 0.2    & setosa\\\\\n",
       "\t 4.6    & 3.1    & 1.5    & 0.2    & setosa\\\\\n",
       "\t 5.0    & 3.6    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 5.4    & 3.9    & 1.7    & 0.4    & setosa\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n",
       "1 5.1          3.5         1.4          0.2         setosa \n",
       "2 4.9          3.0         1.4          0.2         setosa \n",
       "3 4.7          3.2         1.3          0.2         setosa \n",
       "4 4.6          3.1         1.5          0.2         setosa \n",
       "5 5.0          3.6         1.4          0.2         setosa \n",
       "6 5.4          3.9         1.7          0.4         setosa "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(iris)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 217,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "X <- t(as.matrix(iris[,-ncol(iris)]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 218,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Sepal.Length</th><td>5.1</td><td>4.9</td><td>4.7</td><td>4.6</td><td>5.0</td><td>5.4</td><td>4.6</td><td>5.0</td><td>4.4</td><td>4.9</td><td>...</td><td>6.7</td><td>6.9</td><td>5.8</td><td>6.8</td><td>6.7</td><td>6.7</td><td>6.3</td><td>6.5</td><td>6.2</td><td>5.9</td></tr>\n",
       "\t<tr><th scope=row>Sepal.Width</th><td>3.5</td><td>3.0</td><td>3.2</td><td>3.1</td><td>3.6</td><td>3.9</td><td>3.4</td><td>3.4</td><td>2.9</td><td>3.1</td><td>...</td><td>3.1</td><td>3.1</td><td>2.7</td><td>3.2</td><td>3.3</td><td>3.0</td><td>2.5</td><td>3.0</td><td>3.4</td><td>3.0</td></tr>\n",
       "\t<tr><th scope=row>Petal.Length</th><td>1.4</td><td>1.4</td><td>1.3</td><td>1.5</td><td>1.4</td><td>1.7</td><td>1.4</td><td>1.5</td><td>1.4</td><td>1.5</td><td>...</td><td>5.6</td><td>5.1</td><td>5.1</td><td>5.9</td><td>5.7</td><td>5.2</td><td>5.0</td><td>5.2</td><td>5.4</td><td>5.1</td></tr>\n",
       "\t<tr><th scope=row>Petal.Width</th><td>0.2</td><td>0.2</td><td>0.2</td><td>0.2</td><td>0.2</td><td>0.4</td><td>0.3</td><td>0.2</td><td>0.2</td><td>0.1</td><td>...</td><td>2.4</td><td>2.3</td><td>1.9</td><td>2.3</td><td>2.5</td><td>2.3</td><td>1.9</td><td>2.0</td><td>2.3</td><td>1.8</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "\tSepal.Length & 5.1 & 4.9 & 4.7 & 4.6 & 5.0 & 5.4 & 4.6 & 5.0 & 4.4 & 4.9 & ... & 6.7 & 6.9 & 5.8 & 6.8 & 6.7 & 6.7 & 6.3 & 6.5 & 6.2 & 5.9\\\\\n",
       "\tSepal.Width & 3.5 & 3.0 & 3.2 & 3.1 & 3.6 & 3.9 & 3.4 & 3.4 & 2.9 & 3.1 & ... & 3.1 & 3.1 & 2.7 & 3.2 & 3.3 & 3.0 & 2.5 & 3.0 & 3.4 & 3.0\\\\\n",
       "\tPetal.Length & 1.4 & 1.4 & 1.3 & 1.5 & 1.4 & 1.7 & 1.4 & 1.5 & 1.4 & 1.5 & ... & 5.6 & 5.1 & 5.1 & 5.9 & 5.7 & 5.2 & 5.0 & 5.2 & 5.4 & 5.1\\\\\n",
       "\tPetal.Width & 0.2 & 0.2 & 0.2 & 0.2 & 0.2 & 0.4 & 0.3 & 0.2 & 0.2 & 0.1 & ... & 2.4 & 2.3 & 1.9 & 2.3 & 2.5 & 2.3 & 1.9 & 2.0 & 2.3 & 1.8\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. 5.1\n",
       "2. 3.5\n",
       "3. 1.4\n",
       "4. 0.2\n",
       "5. 4.9\n",
       "6. 3\n",
       "7. 1.4\n",
       "8. 0.2\n",
       "9. 4.7\n",
       "10. 3.2\n",
       "11. 1.3\n",
       "12. 0.2\n",
       "13. 4.6\n",
       "14. 3.1\n",
       "15. 1.5\n",
       "16. 0.2\n",
       "17. 5\n",
       "18. 3.6\n",
       "19. 1.4\n",
       "20. 0.2\n",
       "21. 5.4\n",
       "22. 3.9\n",
       "23. 1.7\n",
       "24. 0.4\n",
       "25. 4.6\n",
       "26. 3.4\n",
       "27. 1.4\n",
       "28. 0.3\n",
       "29. 5\n",
       "30. 3.4\n",
       "31. 1.5\n",
       "32. 0.2\n",
       "33. 4.4\n",
       "34. 2.9\n",
       "35. 1.4\n",
       "36. 0.2\n",
       "37. 4.9\n",
       "38. 3.1\n",
       "39. 1.5\n",
       "40. 0.1\n",
       "41. 5.4\n",
       "42. 3.7\n",
       "43. 1.5\n",
       "44. 0.2\n",
       "45. 4.8\n",
       "46. 3.4\n",
       "47. 1.6\n",
       "48. 0.2\n",
       "49. 4.8\n",
       "50. 3\n",
       "51. 1.4\n",
       "52. 0.1\n",
       "53. 4.3\n",
       "54. 3\n",
       "55. 1.1\n",
       "56. 0.1\n",
       "57. 5.8\n",
       "58. 4\n",
       "59. 1.2\n",
       "60. 0.2\n",
       "61. 5.7\n",
       "62. 4.4\n",
       "63. 1.5\n",
       "64. 0.4\n",
       "65. 5.4\n",
       "66. 3.9\n",
       "67. 1.3\n",
       "68. 0.4\n",
       "69. 5.1\n",
       "70. 3.5\n",
       "71. 1.4\n",
       "72. 0.3\n",
       "73. 5.7\n",
       "74. 3.8\n",
       "75. 1.7\n",
       "76. 0.3\n",
       "77. 5.1\n",
       "78. 3.8\n",
       "79. 1.5\n",
       "80. 0.3\n",
       "81. 5.4\n",
       "82. 3.4\n",
       "83. 1.7\n",
       "84. 0.2\n",
       "85. 5.1\n",
       "86. 3.7\n",
       "87. 1.5\n",
       "88. 0.4\n",
       "89. 4.6\n",
       "90. 3.6\n",
       "91. 1\n",
       "92. 0.2\n",
       "93. 5.1\n",
       "94. 3.3\n",
       "95. 1.7\n",
       "96. 0.5\n",
       "97. 4.8\n",
       "98. 3.4\n",
       "99. 1.9\n",
       "100. 0.2\n",
       "101. 5\n",
       "102. 3\n",
       "103. 1.6\n",
       "104. 0.2\n",
       "105. 5\n",
       "106. 3.4\n",
       "107. 1.6\n",
       "108. 0.4\n",
       "109. 5.2\n",
       "110. 3.5\n",
       "111. 1.5\n",
       "112. 0.2\n",
       "113. 5.2\n",
       "114. 3.4\n",
       "115. 1.4\n",
       "116. 0.2\n",
       "117. 4.7\n",
       "118. 3.2\n",
       "119. 1.6\n",
       "120. 0.2\n",
       "121. 4.8\n",
       "122. 3.1\n",
       "123. 1.6\n",
       "124. 0.2\n",
       "125. 5.4\n",
       "126. 3.4\n",
       "127. 1.5\n",
       "128. 0.4\n",
       "129. 5.2\n",
       "130. 4.1\n",
       "131. 1.5\n",
       "132. 0.1\n",
       "133. 5.5\n",
       "134. 4.2\n",
       "135. 1.4\n",
       "136. 0.2\n",
       "137. 4.9\n",
       "138. 3.1\n",
       "139. 1.5\n",
       "140. 0.2\n",
       "141. 5\n",
       "142. 3.2\n",
       "143. 1.2\n",
       "144. 0.2\n",
       "145. 5.5\n",
       "146. 3.5\n",
       "147. 1.3\n",
       "148. 0.2\n",
       "149. 4.9\n",
       "150. 3.6\n",
       "151. 1.4\n",
       "152. 0.1\n",
       "153. 4.4\n",
       "154. 3\n",
       "155. 1.3\n",
       "156. 0.2\n",
       "157. 5.1\n",
       "158. 3.4\n",
       "159. 1.5\n",
       "160. 0.2\n",
       "161. 5\n",
       "162. 3.5\n",
       "163. 1.3\n",
       "164. 0.3\n",
       "165. 4.5\n",
       "166. 2.3\n",
       "167. 1.3\n",
       "168. 0.3\n",
       "169. 4.4\n",
       "170. 3.2\n",
       "171. 1.3\n",
       "172. 0.2\n",
       "173. 5\n",
       "174. 3.5\n",
       "175. 1.6\n",
       "176. 0.6\n",
       "177. 5.1\n",
       "178. 3.8\n",
       "179. 1.9\n",
       "180. 0.4\n",
       "181. 4.8\n",
       "182. 3\n",
       "183. 1.4\n",
       "184. 0.3\n",
       "185. 5.1\n",
       "186. 3.8\n",
       "187. 1.6\n",
       "188. 0.2\n",
       "189. 4.6\n",
       "190. 3.2\n",
       "191. 1.4\n",
       "192. 0.2\n",
       "193. 5.3\n",
       "194. 3.7\n",
       "195. 1.5\n",
       "196. 0.2\n",
       "197. 5\n",
       "198. 3.3\n",
       "199. 1.4\n",
       "200. 0.2\n",
       "201. 7\n",
       "202. 3.2\n",
       "203. 4.7\n",
       "204. 1.4\n",
       "205. 6.4\n",
       "206. 3.2\n",
       "207. 4.5\n",
       "208. 1.5\n",
       "209. 6.9\n",
       "210. 3.1\n",
       "211. 4.9\n",
       "212. 1.5\n",
       "213. 5.5\n",
       "214. 2.3\n",
       "215. 4\n",
       "216. 1.3\n",
       "217. 6.5\n",
       "218. 2.8\n",
       "219. 4.6\n",
       "220. 1.5\n",
       "221. 5.7\n",
       "222. 2.8\n",
       "223. 4.5\n",
       "224. 1.3\n",
       "225. 6.3\n",
       "226. 3.3\n",
       "227. 4.7\n",
       "228. 1.6\n",
       "229. 4.9\n",
       "230. 2.4\n",
       "231. 3.3\n",
       "232. 1\n",
       "233. 6.6\n",
       "234. 2.9\n",
       "235. 4.6\n",
       "236. 1.3\n",
       "237. 5.2\n",
       "238. 2.7\n",
       "239. 3.9\n",
       "240. 1.4\n",
       "241. 5\n",
       "242. 2\n",
       "243. 3.5\n",
       "244. 1\n",
       "245. 5.9\n",
       "246. 3\n",
       "247. 4.2\n",
       "248. 1.5\n",
       "249. 6\n",
       "250. 2.2\n",
       "251. 4\n",
       "252. 1\n",
       "253. 6.1\n",
       "254. 2.9\n",
       "255. 4.7\n",
       "256. 1.4\n",
       "257. 5.6\n",
       "258. 2.9\n",
       "259. 3.6\n",
       "260. 1.3\n",
       "261. 6.7\n",
       "262. 3.1\n",
       "263. 4.4\n",
       "264. 1.4\n",
       "265. 5.6\n",
       "266. 3\n",
       "267. 4.5\n",
       "268. 1.5\n",
       "269. 5.8\n",
       "270. 2.7\n",
       "271. 4.1\n",
       "272. 1\n",
       "273. 6.2\n",
       "274. 2.2\n",
       "275. 4.5\n",
       "276. 1.5\n",
       "277. 5.6\n",
       "278. 2.5\n",
       "279. 3.9\n",
       "280. 1.1\n",
       "281. 5.9\n",
       "282. 3.2\n",
       "283. 4.8\n",
       "284. 1.8\n",
       "285. 6.1\n",
       "286. 2.8\n",
       "287. 4\n",
       "288. 1.3\n",
       "289. 6.3\n",
       "290. 2.5\n",
       "291. 4.9\n",
       "292. 1.5\n",
       "293. 6.1\n",
       "294. 2.8\n",
       "295. 4.7\n",
       "296. 1.2\n",
       "297. 6.4\n",
       "298. 2.9\n",
       "299. 4.3\n",
       "300. 1.3\n",
       "301. 6.6\n",
       "302. 3\n",
       "303. 4.4\n",
       "304. 1.4\n",
       "305. 6.8\n",
       "306. 2.8\n",
       "307. 4.8\n",
       "308. 1.4\n",
       "309. 6.7\n",
       "310. 3\n",
       "311. 5\n",
       "312. 1.7\n",
       "313. 6\n",
       "314. 2.9\n",
       "315. 4.5\n",
       "316. 1.5\n",
       "317. 5.7\n",
       "318. 2.6\n",
       "319. 3.5\n",
       "320. 1\n",
       "321. 5.5\n",
       "322. 2.4\n",
       "323. 3.8\n",
       "324. 1.1\n",
       "325. 5.5\n",
       "326. 2.4\n",
       "327. 3.7\n",
       "328. 1\n",
       "329. 5.8\n",
       "330. 2.7\n",
       "331. 3.9\n",
       "332. 1.2\n",
       "333. 6\n",
       "334. 2.7\n",
       "335. 5.1\n",
       "336. 1.6\n",
       "337. 5.4\n",
       "338. 3\n",
       "339. 4.5\n",
       "340. 1.5\n",
       "341. 6\n",
       "342. 3.4\n",
       "343. 4.5\n",
       "344. 1.6\n",
       "345. 6.7\n",
       "346. 3.1\n",
       "347. 4.7\n",
       "348. 1.5\n",
       "349. 6.3\n",
       "350. 2.3\n",
       "351. 4.4\n",
       "352. 1.3\n",
       "353. 5.6\n",
       "354. 3\n",
       "355. 4.1\n",
       "356. 1.3\n",
       "357. 5.5\n",
       "358. 2.5\n",
       "359. 4\n",
       "360. 1.3\n",
       "361. 5.5\n",
       "362. 2.6\n",
       "363. 4.4\n",
       "364. 1.2\n",
       "365. 6.1\n",
       "366. 3\n",
       "367. 4.6\n",
       "368. 1.4\n",
       "369. 5.8\n",
       "370. 2.6\n",
       "371. 4\n",
       "372. 1.2\n",
       "373. 5\n",
       "374. 2.3\n",
       "375. 3.3\n",
       "376. 1\n",
       "377. 5.6\n",
       "378. 2.7\n",
       "379. 4.2\n",
       "380. 1.3\n",
       "381. 5.7\n",
       "382. 3\n",
       "383. 4.2\n",
       "384. 1.2\n",
       "385. 5.7\n",
       "386. 2.9\n",
       "387. 4.2\n",
       "388. 1.3\n",
       "389. 6.2\n",
       "390. 2.9\n",
       "391. 4.3\n",
       "392. 1.3\n",
       "393. 5.1\n",
       "394. 2.5\n",
       "395. 3\n",
       "396. 1.1\n",
       "397. 5.7\n",
       "398. 2.8\n",
       "399. 4.1\n",
       "400. 1.3\n",
       "401. 6.3\n",
       "402. 3.3\n",
       "403. 6\n",
       "404. 2.5\n",
       "405. 5.8\n",
       "406. 2.7\n",
       "407. 5.1\n",
       "408. 1.9\n",
       "409. 7.1\n",
       "410. 3\n",
       "411. 5.9\n",
       "412. 2.1\n",
       "413. 6.3\n",
       "414. 2.9\n",
       "415. 5.6\n",
       "416. 1.8\n",
       "417. 6.5\n",
       "418. 3\n",
       "419. 5.8\n",
       "420. 2.2\n",
       "421. 7.6\n",
       "422. 3\n",
       "423. 6.6\n",
       "424. 2.1\n",
       "425. 4.9\n",
       "426. 2.5\n",
       "427. 4.5\n",
       "428. 1.7\n",
       "429. 7.3\n",
       "430. 2.9\n",
       "431. 6.3\n",
       "432. 1.8\n",
       "433. 6.7\n",
       "434. 2.5\n",
       "435. 5.8\n",
       "436. 1.8\n",
       "437. 7.2\n",
       "438. 3.6\n",
       "439. 6.1\n",
       "440. 2.5\n",
       "441. 6.5\n",
       "442. 3.2\n",
       "443. 5.1\n",
       "444. 2\n",
       "445. 6.4\n",
       "446. 2.7\n",
       "447. 5.3\n",
       "448. 1.9\n",
       "449. 6.8\n",
       "450. 3\n",
       "451. 5.5\n",
       "452. 2.1\n",
       "453. 5.7\n",
       "454. 2.5\n",
       "455. 5\n",
       "456. 2\n",
       "457. 5.8\n",
       "458. 2.8\n",
       "459. 5.1\n",
       "460. 2.4\n",
       "461. 6.4\n",
       "462. 3.2\n",
       "463. 5.3\n",
       "464. 2.3\n",
       "465. 6.5\n",
       "466. 3\n",
       "467. 5.5\n",
       "468. 1.8\n",
       "469. 7.7\n",
       "470. 3.8\n",
       "471. 6.7\n",
       "472. 2.2\n",
       "473. 7.7\n",
       "474. 2.6\n",
       "475. 6.9\n",
       "476. 2.3\n",
       "477. 6\n",
       "478. 2.2\n",
       "479. 5\n",
       "480. 1.5\n",
       "481. 6.9\n",
       "482. 3.2\n",
       "483. 5.7\n",
       "484. 2.3\n",
       "485. 5.6\n",
       "486. 2.8\n",
       "487. 4.9\n",
       "488. 2\n",
       "489. 7.7\n",
       "490. 2.8\n",
       "491. 6.7\n",
       "492. 2\n",
       "493. 6.3\n",
       "494. 2.7\n",
       "495. 4.9\n",
       "496. 1.8\n",
       "497. 6.7\n",
       "498. 3.3\n",
       "499. 5.7\n",
       "500. 2.1\n",
       "501. 7.2\n",
       "502. 3.2\n",
       "503. 6\n",
       "504. 1.8\n",
       "505. 6.2\n",
       "506. 2.8\n",
       "507. 4.8\n",
       "508. 1.8\n",
       "509. 6.1\n",
       "510. 3\n",
       "511. 4.9\n",
       "512. 1.8\n",
       "513. 6.4\n",
       "514. 2.8\n",
       "515. 5.6\n",
       "516. 2.1\n",
       "517. 7.2\n",
       "518. 3\n",
       "519. 5.8\n",
       "520. 1.6\n",
       "521. 7.4\n",
       "522. 2.8\n",
       "523. 6.1\n",
       "524. 1.9\n",
       "525. 7.9\n",
       "526. 3.8\n",
       "527. 6.4\n",
       "528. 2\n",
       "529. 6.4\n",
       "530. 2.8\n",
       "531. 5.6\n",
       "532. 2.2\n",
       "533. 6.3\n",
       "534. 2.8\n",
       "535. 5.1\n",
       "536. 1.5\n",
       "537. 6.1\n",
       "538. 2.6\n",
       "539. 5.6\n",
       "540. 1.4\n",
       "541. 7.7\n",
       "542. 3\n",
       "543. 6.1\n",
       "544. 2.3\n",
       "545. 6.3\n",
       "546. 3.4\n",
       "547. 5.6\n",
       "548. 2.4\n",
       "549. 6.4\n",
       "550. 3.1\n",
       "551. 5.5\n",
       "552. 1.8\n",
       "553. 6\n",
       "554. 3\n",
       "555. 4.8\n",
       "556. 1.8\n",
       "557. 6.9\n",
       "558. 3.1\n",
       "559. 5.4\n",
       "560. 2.1\n",
       "561. 6.7\n",
       "562. 3.1\n",
       "563. 5.6\n",
       "564. 2.4\n",
       "565. 6.9\n",
       "566. 3.1\n",
       "567. 5.1\n",
       "568. 2.3\n",
       "569. 5.8\n",
       "570. 2.7\n",
       "571. 5.1\n",
       "572. 1.9\n",
       "573. 6.8\n",
       "574. 3.2\n",
       "575. 5.9\n",
       "576. 2.3\n",
       "577. 6.7\n",
       "578. 3.3\n",
       "579. 5.7\n",
       "580. 2.5\n",
       "581. 6.7\n",
       "582. 3\n",
       "583. 5.2\n",
       "584. 2.3\n",
       "585. 6.3\n",
       "586. 2.5\n",
       "587. 5\n",
       "588. 1.9\n",
       "589. 6.5\n",
       "590. 3\n",
       "591. 5.2\n",
       "592. 2\n",
       "593. 6.2\n",
       "594. 3.4\n",
       "595. 5.4\n",
       "596. 2.3\n",
       "597. 5.9\n",
       "598. 3\n",
       "599. 5.1\n",
       "600. 1.8\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "             [,1] [,2] [,3] [,4] [,5] [,6] [,7] [,8] [,9] [,10] [,11] [,12]\n",
       "Sepal.Length 5.1  4.9  4.7  4.6  5.0  5.4  4.6  5.0  4.4  4.9   ...   6.7  \n",
       "Sepal.Width  3.5  3.0  3.2  3.1  3.6  3.9  3.4  3.4  2.9  3.1   ...   3.1  \n",
       "Petal.Length 1.4  1.4  1.3  1.5  1.4  1.7  1.4  1.5  1.4  1.5   ...   5.6  \n",
       "Petal.Width  0.2  0.2  0.2  0.2  0.2  0.4  0.3  0.2  0.2  0.1   ...   2.4  \n",
       "             [,13] [,14] [,15] [,16] [,17] [,18] [,19] [,20] [,21]\n",
       "Sepal.Length 6.9   5.8   6.8   6.7   6.7   6.3   6.5   6.2   5.9  \n",
       "Sepal.Width  3.1   2.7   3.2   3.3   3.0   2.5   3.0   3.4   3.0  \n",
       "Petal.Length 5.1   5.1   5.9   5.7   5.2   5.0   5.2   5.4   5.1  \n",
       "Petal.Width  2.3   1.9   2.3   2.5   2.3   1.9   2.0   2.3   1.8  "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 219,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "group <- iris$Species"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 220,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>setosa</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>versicolor</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "\t<li>virginica</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item setosa\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item versicolor\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\item virginica\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. setosa\n",
       "2. setosa\n",
       "3. setosa\n",
       "4. setosa\n",
       "5. setosa\n",
       "6. setosa\n",
       "7. setosa\n",
       "8. setosa\n",
       "9. setosa\n",
       "10. setosa\n",
       "11. setosa\n",
       "12. setosa\n",
       "13. setosa\n",
       "14. setosa\n",
       "15. setosa\n",
       "16. setosa\n",
       "17. setosa\n",
       "18. setosa\n",
       "19. setosa\n",
       "20. setosa\n",
       "21. setosa\n",
       "22. setosa\n",
       "23. setosa\n",
       "24. setosa\n",
       "25. setosa\n",
       "26. setosa\n",
       "27. setosa\n",
       "28. setosa\n",
       "29. setosa\n",
       "30. setosa\n",
       "31. setosa\n",
       "32. setosa\n",
       "33. setosa\n",
       "34. setosa\n",
       "35. setosa\n",
       "36. setosa\n",
       "37. setosa\n",
       "38. setosa\n",
       "39. setosa\n",
       "40. setosa\n",
       "41. setosa\n",
       "42. setosa\n",
       "43. setosa\n",
       "44. setosa\n",
       "45. setosa\n",
       "46. setosa\n",
       "47. setosa\n",
       "48. setosa\n",
       "49. setosa\n",
       "50. setosa\n",
       "51. versicolor\n",
       "52. versicolor\n",
       "53. versicolor\n",
       "54. versicolor\n",
       "55. versicolor\n",
       "56. versicolor\n",
       "57. versicolor\n",
       "58. versicolor\n",
       "59. versicolor\n",
       "60. versicolor\n",
       "61. versicolor\n",
       "62. versicolor\n",
       "63. versicolor\n",
       "64. versicolor\n",
       "65. versicolor\n",
       "66. versicolor\n",
       "67. versicolor\n",
       "68. versicolor\n",
       "69. versicolor\n",
       "70. versicolor\n",
       "71. versicolor\n",
       "72. versicolor\n",
       "73. versicolor\n",
       "74. versicolor\n",
       "75. versicolor\n",
       "76. versicolor\n",
       "77. versicolor\n",
       "78. versicolor\n",
       "79. versicolor\n",
       "80. versicolor\n",
       "81. versicolor\n",
       "82. versicolor\n",
       "83. versicolor\n",
       "84. versicolor\n",
       "85. versicolor\n",
       "86. versicolor\n",
       "87. versicolor\n",
       "88. versicolor\n",
       "89. versicolor\n",
       "90. versicolor\n",
       "91. versicolor\n",
       "92. versicolor\n",
       "93. versicolor\n",
       "94. versicolor\n",
       "95. versicolor\n",
       "96. versicolor\n",
       "97. versicolor\n",
       "98. versicolor\n",
       "99. versicolor\n",
       "100. versicolor\n",
       "101. virginica\n",
       "102. virginica\n",
       "103. virginica\n",
       "104. virginica\n",
       "105. virginica\n",
       "106. virginica\n",
       "107. virginica\n",
       "108. virginica\n",
       "109. virginica\n",
       "110. virginica\n",
       "111. virginica\n",
       "112. virginica\n",
       "113. virginica\n",
       "114. virginica\n",
       "115. virginica\n",
       "116. virginica\n",
       "117. virginica\n",
       "118. virginica\n",
       "119. virginica\n",
       "120. virginica\n",
       "121. virginica\n",
       "122. virginica\n",
       "123. virginica\n",
       "124. virginica\n",
       "125. virginica\n",
       "126. virginica\n",
       "127. virginica\n",
       "128. virginica\n",
       "129. virginica\n",
       "130. virginica\n",
       "131. virginica\n",
       "132. virginica\n",
       "133. virginica\n",
       "134. virginica\n",
       "135. virginica\n",
       "136. virginica\n",
       "137. virginica\n",
       "138. virginica\n",
       "139. virginica\n",
       "140. virginica\n",
       "141. virginica\n",
       "142. virginica\n",
       "143. virginica\n",
       "144. virginica\n",
       "145. virginica\n",
       "146. virginica\n",
       "147. virginica\n",
       "148. virginica\n",
       "149. virginica\n",
       "150. virginica\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       "  [7] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       " [13] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       " [19] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       " [25] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       " [31] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       " [37] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       " [43] setosa     setosa     setosa     setosa     setosa     setosa    \n",
       " [49] setosa     setosa     versicolor versicolor versicolor versicolor\n",
       " [55] versicolor versicolor versicolor versicolor versicolor versicolor\n",
       " [61] versicolor versicolor versicolor versicolor versicolor versicolor\n",
       " [67] versicolor versicolor versicolor versicolor versicolor versicolor\n",
       " [73] versicolor versicolor versicolor versicolor versicolor versicolor\n",
       " [79] versicolor versicolor versicolor versicolor versicolor versicolor\n",
       " [85] versicolor versicolor versicolor versicolor versicolor versicolor\n",
       " [91] versicolor versicolor versicolor versicolor versicolor versicolor\n",
       " [97] versicolor versicolor versicolor versicolor virginica  virginica \n",
       "[103] virginica  virginica  virginica  virginica  virginica  virginica \n",
       "[109] virginica  virginica  virginica  virginica  virginica  virginica \n",
       "[115] virginica  virginica  virginica  virginica  virginica  virginica \n",
       "[121] virginica  virginica  virginica  virginica  virginica  virginica \n",
       "[127] virginica  virginica  virginica  virginica  virginica  virginica \n",
       "[133] virginica  virginica  virginica  virginica  virginica  virginica \n",
       "[139] virginica  virginica  virginica  virginica  virginica  virginica \n",
       "[145] virginica  virginica  virginica  virginica  virginica  virginica \n",
       "Levels: setosa versicolor virginica"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "group"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 221,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$B</dt>\n",
       "\t\t<dd><table>\n",
       "<tbody>\n",
       "\t<tr><td> 63.21213</td><td>-19.95267</td><td>165.2484 </td><td> 71.27933</td></tr>\n",
       "\t<tr><td>-19.95267</td><td> 11.34493</td><td>-57.2396 </td><td>-22.93267</td></tr>\n",
       "\t<tr><td>165.24840</td><td>-57.23960</td><td>437.1028 </td><td>186.77400</td></tr>\n",
       "\t<tr><td> 71.27933</td><td>-22.93267</td><td>186.7740 </td><td> 80.41333</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "\t<dt>$E</dt>\n",
       "\t\t<dd><table>\n",
       "<thead><tr><th></th><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th><th scope=col>Petal.Length</th><th scope=col>Petal.Width</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Sepal.Length</th><td>38.9562</td><td>13.6300</td><td>24.6246</td><td>5.6450 </td></tr>\n",
       "\t<tr><th scope=row>Sepal.Width</th><td>13.6300</td><td>16.9620</td><td> 8.1208</td><td>4.8084 </td></tr>\n",
       "\t<tr><th scope=row>Petal.Length</th><td>24.6246</td><td> 8.1208</td><td>27.2226</td><td>6.2718 </td></tr>\n",
       "\t<tr><th scope=row>Petal.Width</th><td> 5.6450</td><td> 4.8084</td><td> 6.2718</td><td>6.1566 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "\t<dt>$W</dt>\n",
       "\t\t<dd><table>\n",
       "<thead><tr><th></th><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th><th scope=col>Petal.Length</th><th scope=col>Petal.Width</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Sepal.Length</th><td>102.168333</td><td> -6.322667</td><td>189.8730  </td><td> 76.92433 </td></tr>\n",
       "\t<tr><th scope=row>Sepal.Width</th><td> -6.322667</td><td> 28.306933</td><td>-49.1188  </td><td>-18.12427 </td></tr>\n",
       "\t<tr><th scope=row>Petal.Length</th><td>189.873000</td><td>-49.118800</td><td>464.3254  </td><td>193.04580 </td></tr>\n",
       "\t<tr><th scope=row>Petal.Width</th><td> 76.924333</td><td>-18.124267</td><td>193.0458  </td><td> 86.56993 </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$B] \\begin{tabular}{llll}\n",
       "\t  63.21213 & -19.95267 & 165.2484  &  71.27933\\\\\n",
       "\t -19.95267 &  11.34493 & -57.2396  & -22.93267\\\\\n",
       "\t 165.24840 & -57.23960 & 437.1028  & 186.77400\\\\\n",
       "\t  71.27933 & -22.93267 & 186.7740  &  80.41333\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\item[\\$E] \\begin{tabular}{r|llll}\n",
       "  & Sepal.Length & Sepal.Width & Petal.Length & Petal.Width\\\\\n",
       "\\hline\n",
       "\tSepal.Length & 38.9562 & 13.6300 & 24.6246 & 5.6450 \\\\\n",
       "\tSepal.Width & 13.6300 & 16.9620 &  8.1208 & 4.8084 \\\\\n",
       "\tPetal.Length & 24.6246 &  8.1208 & 27.2226 & 6.2718 \\\\\n",
       "\tPetal.Width &  5.6450 &  4.8084 &  6.2718 & 6.1566 \\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\item[\\$W] \\begin{tabular}{r|llll}\n",
       "  & Sepal.Length & Sepal.Width & Petal.Length & Petal.Width\\\\\n",
       "\\hline\n",
       "\tSepal.Length & 102.168333 &  -6.322667 & 189.8730   &  76.92433 \\\\\n",
       "\tSepal.Width &  -6.322667 &  28.306933 & -49.1188   & -18.12427 \\\\\n",
       "\tPetal.Length & 189.873000 & -49.118800 & 464.3254   & 193.04580 \\\\\n",
       "\tPetal.Width &  76.924333 & -18.124267 & 193.0458   &  86.56993 \\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$B\n",
       ":   1. 63.2121333333334\n",
       "2. -19.9526666666667\n",
       "3. 165.2484\n",
       "4. 71.2793333333331\n",
       "5. -19.9526666666667\n",
       "6. 11.3449333333334\n",
       "7. -57.2395999999998\n",
       "8. -22.9326666666666\n",
       "9. 165.2484\n",
       "10. -57.2395999999998\n",
       "11. 437.1028\n",
       "12. 186.773999999999\n",
       "13. 71.2793333333331\n",
       "14. -22.9326666666666\n",
       "15. 186.773999999999\n",
       "16. 80.4133333333335\n",
       "\n",
       "\n",
       "\n",
       "$E\n",
       ":   1. 38.9562\n",
       "2. 13.63\n",
       "3. 24.6246\n",
       "4. 5.645\n",
       "5. 13.63\n",
       "6. 16.962\n",
       "7. 8.1208\n",
       "8. 4.8084\n",
       "9. 24.6246\n",
       "10. 8.1208\n",
       "11. 27.2226\n",
       "12. 6.2718\n",
       "13. 5.645\n",
       "14. 4.8084\n",
       "15. 6.2718\n",
       "16. 6.1566\n",
       "\n",
       "\n",
       "\n",
       "$W\n",
       ":   1. 102.168333333333\n",
       "2. -6.32266666666666\n",
       "3. 189.873\n",
       "4. 76.9243333333333\n",
       "5. -6.32266666666666\n",
       "6. 28.3069333333333\n",
       "7. -49.1188\n",
       "8. -18.1242666666667\n",
       "9. 189.873\n",
       "10. -49.1188\n",
       "11. 464.3254\n",
       "12. 193.0458\n",
       "13. 76.9243333333333\n",
       "14. -18.1242666666667\n",
       "15. 193.0458\n",
       "16. 86.5699333333333\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$B\n",
       "          [,1]      [,2]     [,3]      [,4]\n",
       "[1,]  63.21213 -19.95267 165.2484  71.27933\n",
       "[2,] -19.95267  11.34493 -57.2396 -22.93267\n",
       "[3,] 165.24840 -57.23960 437.1028 186.77400\n",
       "[4,]  71.27933 -22.93267 186.7740  80.41333\n",
       "\n",
       "$E\n",
       "             Sepal.Length Sepal.Width Petal.Length Petal.Width\n",
       "Sepal.Length      38.9562     13.6300      24.6246      5.6450\n",
       "Sepal.Width       13.6300     16.9620       8.1208      4.8084\n",
       "Petal.Length      24.6246      8.1208      27.2226      6.2718\n",
       "Petal.Width        5.6450      4.8084       6.2718      6.1566\n",
       "\n",
       "$W\n",
       "             Sepal.Length Sepal.Width Petal.Length Petal.Width\n",
       "Sepal.Length   102.168333   -6.322667     189.8730    76.92433\n",
       "Sepal.Width     -6.322667   28.306933     -49.1188   -18.12427\n",
       "Petal.Length   189.873000  -49.118800     464.3254   193.04580\n",
       "Petal.Width     76.924333  -18.124267     193.0458    86.56993\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "d <- decomp(X,group)\n",
    "d"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 222,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Sepal.Length</th><td>-0.09131889</td><td> 0.03408887</td><td>-0.2440232 </td><td>-0.1034254 </td></tr>\n",
       "\t<tr><th scope=row>Sepal.Width</th><td>-0.09364353</td><td> 0.20115865</td><td>-0.4175116 </td><td>-0.1203378 </td></tr>\n",
       "\t<tr><th scope=row>Petal.Length</th><td> 0.21153124</td><td>-0.14701085</td><td> 0.6337430 </td><td> 0.2454212 </td></tr>\n",
       "\t<tr><th scope=row>Petal.Width</th><td> 0.41320976</td><td> 0.07474593</td><td> 0.8737076 </td><td> 0.4483161 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "\tSepal.Length & -0.09131889 &  0.03408887 & -0.2440232  & -0.1034254 \\\\\n",
       "\tSepal.Width & -0.09364353 &  0.20115865 & -0.4175116  & -0.1203378 \\\\\n",
       "\tPetal.Length &  0.21153124 & -0.14701085 &  0.6337430  &  0.2454212 \\\\\n",
       "\tPetal.Width &  0.41320976 &  0.07474593 &  0.8737076  &  0.4483161 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. -0.0913188926468878\n",
       "2. -0.0936435336258494\n",
       "3. 0.211531236075395\n",
       "4. 0.413209757999804\n",
       "5. 0.0340888670011844\n",
       "6. 0.20115865046601\n",
       "7. -0.147010848637791\n",
       "8. 0.0747459264820893\n",
       "9. -0.244023195954076\n",
       "10. -0.417511591865476\n",
       "11. 0.633742992247868\n",
       "12. 0.873707584076811\n",
       "13. -0.103425410111735\n",
       "14. -0.120337831927178\n",
       "15. 0.245421223239014\n",
       "16. 0.448316074974622\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "             [,1]        [,2]        [,3]       [,4]      \n",
       "Sepal.Length -0.09131889  0.03408887 -0.2440232 -0.1034254\n",
       "Sepal.Width  -0.09364353  0.20115865 -0.4175116 -0.1203378\n",
       "Petal.Length  0.21153124 -0.14701085  0.6337430  0.2454212\n",
       "Petal.Width   0.41320976  0.07474593  0.8737076  0.4483161"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "M <- solve(d$W) %*% d$B\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$values</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>0.969872194110006</li>\n",
       "\t<li>0.22202663093148</li>\n",
       "\t<li>1.15766250800302e-13</li>\n",
       "\t<li>1.15670061225335e-14</li>\n",
       "</ol>\n",
       "</dd>\n",
       "\t<dt>$vectors</dt>\n",
       "\t\t<dd><table>\n",
       "<tbody>\n",
       "\t<tr><td> 0.2087418  </td><td>-0.006531964</td><td> 0.3074280  </td><td>-0.8830997  </td></tr>\n",
       "\t<tr><td> 0.3862037  </td><td>-0.586610553</td><td>-0.4167830  </td><td> 0.2674202  </td></tr>\n",
       "\t<tr><td>-0.5540117  </td><td> 0.252561540</td><td>-0.4748473  </td><td> 0.2399442  </td></tr>\n",
       "\t<tr><td>-0.7073504  </td><td>-0.769453092</td><td> 0.7115476  </td><td> 0.3017419  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$values] \\begin{enumerate*}\n",
       "\\item 0.969872194110006\n",
       "\\item 0.22202663093148\n",
       "\\item 1.15766250800302e-13\n",
       "\\item 1.15670061225335e-14\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$vectors] \\begin{tabular}{llll}\n",
       "\t  0.2087418   & -0.006531964 &  0.3074280   & -0.8830997  \\\\\n",
       "\t  0.3862037   & -0.586610553 & -0.4167830   &  0.2674202  \\\\\n",
       "\t -0.5540117   &  0.252561540 & -0.4748473   &  0.2399442  \\\\\n",
       "\t -0.7073504   & -0.769453092 &  0.7115476   &  0.3017419  \\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$values\n",
       ":   1. 0.969872194110006\n",
       "2. 0.22202663093148\n",
       "3. 1.15766250800302e-13\n",
       "4. 1.15670061225335e-14\n",
       "\n",
       "\n",
       "\n",
       "$vectors\n",
       ":   1. 0.208741821474547\n",
       "2. 0.386203686755042\n",
       "3. -0.554011715552842\n",
       "4. -0.707350396433407\n",
       "5. -0.00653196404728036\n",
       "6. -0.58661055312444\n",
       "7. 0.252561540044432\n",
       "8. -0.769453092071966\n",
       "9. 0.307428022805033\n",
       "10. -0.416782964811757\n",
       "11. -0.474847281278411\n",
       "12. 0.711547630520551\n",
       "13. -0.883099672344141\n",
       "14. 0.267420196901203\n",
       "15. 0.239944218969143\n",
       "16. 0.30174190756055\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$values\n",
       "[1] 9.698722e-01 2.220266e-01 1.157663e-13 1.156701e-14\n",
       "\n",
       "$vectors\n",
       "           [,1]         [,2]       [,3]       [,4]\n",
       "[1,]  0.2087418 -0.006531964  0.3074280 -0.8830997\n",
       "[2,]  0.3862037 -0.586610553 -0.4167830  0.2674202\n",
       "[3,] -0.5540117  0.252561540 -0.4748473  0.2399442\n",
       "[4,] -0.7073504 -0.769453092  0.7115476  0.3017419\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res <- eigen(M)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 224,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>0.9698722</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 0.9698722\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "0.969872194110009"
      ],
      "text/plain": [
       "     [,1]     \n",
       "[1,] 0.9698722"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a <- res$vectors[,1]\n",
    "(t(a) %*% d$B %*% a)/(t(a) %*% d$W %*% a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 225,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Sepal.Length</th><td>-3.058369 </td><td> 1.081383 </td><td> -8.111923</td><td>-3.458650 </td></tr>\n",
       "\t<tr><th scope=row>Sepal.Width</th><td>-5.561639 </td><td> 2.178219 </td><td>-14.964612</td><td>-6.307740 </td></tr>\n",
       "\t<tr><th scope=row>Petal.Length</th><td> 8.077439 </td><td>-2.942719 </td><td> 21.511591</td><td> 9.142065 </td></tr>\n",
       "\t<tr><th scope=row>Petal.Width</th><td>10.497082 </td><td>-3.419854 </td><td> 27.548525</td><td>11.845880 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       "\tSepal.Length & -3.058369  &  1.081383  &  -8.111923 & -3.458650 \\\\\n",
       "\tSepal.Width & -5.561639  &  2.178219  & -14.964612 & -6.307740 \\\\\n",
       "\tPetal.Length &  8.077439  & -2.942719  &  21.511591 &  9.142065 \\\\\n",
       "\tPetal.Width & 10.497082  & -3.419854  &  27.548525 & 11.845880 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. -3.05836939146714\n",
       "2. -5.56163926267313\n",
       "3. 8.07743878188315\n",
       "4. 10.4970818676847\n",
       "5. 1.08138264443293\n",
       "6. 2.17821866307576\n",
       "7. -2.9427185421935\n",
       "8. -3.41985449129305\n",
       "9. -8.1119227023193\n",
       "10. -14.964611937241\n",
       "11. 21.5115909007317\n",
       "12. 27.5485248160368\n",
       "13. -3.45864987234596\n",
       "14. -6.30773950581266\n",
       "15. 9.14206468196914\n",
       "16. 11.8458800685609\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "             [,1]      [,2]      [,3]       [,4]     \n",
       "Sepal.Length -3.058369  1.081383  -8.111923 -3.458650\n",
       "Sepal.Width  -5.561639  2.178219 -14.964612 -6.307740\n",
       "Petal.Length  8.077439 -2.942719  21.511591  9.142065\n",
       "Petal.Width  10.497082 -3.419854  27.548525 11.845880"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "M <- solve(d$E) %*% d$B\n",
    "M"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$values</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>32.191929198278</li>\n",
       "\t<li>0.285391042623103</li>\n",
       "\t<li>1.14299293240674e-13</li>\n",
       "\t<li>8.95552563754581e-15</li>\n",
       "</ol>\n",
       "</dd>\n",
       "\t<dt>$vectors</dt>\n",
       "\t\t<dd><table>\n",
       "<tbody>\n",
       "\t<tr><td>-0.2087418  </td><td>-0.006531964</td><td> 0.2897570  </td><td>-0.8827874  </td></tr>\n",
       "\t<tr><td>-0.3862037  </td><td>-0.586610553</td><td>-0.4133779  </td><td> 0.2656505  </td></tr>\n",
       "\t<tr><td> 0.5540117  </td><td> 0.252561540</td><td>-0.4723986  </td><td> 0.2378342  </td></tr>\n",
       "\t<tr><td> 0.7073504  </td><td>-0.769453092</td><td> 0.7224951  </td><td> 0.3058612  </td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$values] \\begin{enumerate*}\n",
       "\\item 32.191929198278\n",
       "\\item 0.285391042623103\n",
       "\\item 1.14299293240674e-13\n",
       "\\item 8.95552563754581e-15\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$vectors] \\begin{tabular}{llll}\n",
       "\t -0.2087418   & -0.006531964 &  0.2897570   & -0.8827874  \\\\\n",
       "\t -0.3862037   & -0.586610553 & -0.4133779   &  0.2656505  \\\\\n",
       "\t  0.5540117   &  0.252561540 & -0.4723986   &  0.2378342  \\\\\n",
       "\t  0.7073504   & -0.769453092 &  0.7224951   &  0.3058612  \\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$values\n",
       ":   1. 32.191929198278\n",
       "2. 0.285391042623103\n",
       "3. 1.14299293240674e-13\n",
       "4. 8.95552563754581e-15\n",
       "\n",
       "\n",
       "\n",
       "$vectors\n",
       ":   1. -0.208741821474553\n",
       "2. -0.386203686755053\n",
       "3. 0.554011715552865\n",
       "4. 0.707350396433382\n",
       "5. -0.00653196404725258\n",
       "6. -0.586610553124496\n",
       "7. 0.252561540044398\n",
       "8. -0.769453092071934\n",
       "9. 0.289756992865031\n",
       "10. -0.413377903395345\n",
       "11. -0.472398622681618\n",
       "12. 0.722495076356091\n",
       "13. -0.882787407000353\n",
       "14. 0.265650496856778\n",
       "15. 0.237834240756357\n",
       "16. 0.305861212783164\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$values\n",
       "[1] 3.219193e+01 2.853910e-01 1.142993e-13 8.955526e-15\n",
       "\n",
       "$vectors\n",
       "           [,1]         [,2]       [,3]       [,4]\n",
       "[1,] -0.2087418 -0.006531964  0.2897570 -0.8827874\n",
       "[2,] -0.3862037 -0.586610553 -0.4133779  0.2656505\n",
       "[3,]  0.5540117  0.252561540 -0.4723986  0.2378342\n",
       "[4,]  0.7073504 -0.769453092  0.7224951  0.3058612\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "res <- eigen(M)\n",
    "res"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>32.19193</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{l}\n",
       "\t 32.19193\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "32.191929198278"
      ],
      "text/plain": [
       "     [,1]    \n",
       "[1,] 32.19193"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "a <- res$vectors[,1]\n",
    "(t(a) %*% d$B %*% a)/(t(a) %*% d$E %*% a)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 228,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>-1.499210</td><td>-1.264360</td><td>-1.355253</td><td>-1.184956</td><td>-1.516956</td><td>-1.40864 </td><td>-1.285483</td><td>-1.384314</td><td>-1.121368</td><td>-1.318314</td><td>...      </td><td> 2.204305</td><td> 1.814816</td><td> 1.915973</td><td> 2.240279</td><td> 2.253200</td><td> 1.950586</td><td> 1.833442</td><td> 1.780129</td><td> 2.011277</td><td> 1.708503</td></tr>\n",
       "\t<tr><td>-1.886754</td><td>-1.592143</td><td>-1.733415</td><td>-1.623588</td><td>-1.944762</td><td>-2.20148 </td><td>-1.901773</td><td>-1.802184</td><td>-1.530216</td><td>-1.548602</td><td>...      </td><td>-2.294600</td><td>-2.345242</td><td>-1.795631</td><td>-2.201200</td><td>-2.463611</td><td>-2.260018</td><td>-1.706831</td><td>-2.027876</td><td>-2.440884</td><td>-1.895322</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{llllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllllll}\n",
       "\t -1.499210 & -1.264360 & -1.355253 & -1.184956 & -1.516956 & -1.40864  & -1.285483 & -1.384314 & -1.121368 & -1.318314 & ...       &  2.204305 &  1.814816 &  1.915973 &  2.240279 &  2.253200 &  1.950586 &  1.833442 &  1.780129 &  2.011277 &  1.708503\\\\\n",
       "\t -1.886754 & -1.592143 & -1.733415 & -1.623588 & -1.944762 & -2.20148  & -1.901773 & -1.802184 & -1.530216 & -1.548602 & ...       & -2.294600 & -2.345242 & -1.795631 & -2.201200 & -2.463611 & -2.260018 & -1.706831 & -2.027876 & -2.440884 & -1.895322\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. -1.49920971210221\n",
       "2. -1.88675441492895\n",
       "3. -1.26435950442978\n",
       "4. -1.59214274555726\n",
       "5. -1.35525304904116\n",
       "6. -1.73341461737714\n",
       "7. -1.18495615510763\n",
       "8. -1.62358805765109\n",
       "9. -1.51695589863027\n",
       "10. -1.94476227383668\n",
       "11. -1.40864013929407\n",
       "12. -2.201480381794\n",
       "13. -1.2854833930461\n",
       "14. -1.90177268680007\n",
       "15. -1.38431398972397\n",
       "16. -1.80218400920734\n",
       "17. -1.121368225017\n",
       "18. -1.53021570822118\n",
       "19. -1.31831374119334\n",
       "20. -1.54860233765807\n",
       "21. -1.5836718243403\n",
       "22. -1.98077996076359\n",
       "23. -1.28716445387377\n",
       "24. -1.77562146239345\n",
       "25. -1.31422036192566\n",
       "26. -1.51454423994534\n",
       "27. -1.37605296585424\n",
       "28. -1.58704671993503\n",
       "29. -1.9492331736225\n",
       "30. -2.23514437433316\n",
       "31. -1.77516687222453\n",
       "32. -2.5472575555793\n",
       "33. -1.63024482551521\n",
       "34. -2.30250499781175\n",
       "35. -1.42847467245888\n",
       "36. -1.96369972413615\n",
       "37. -1.50337735670426\n",
       "38. -2.06783360648853\n",
       "39. -1.48893460693011\n",
       "40. -2.11442673606906\n",
       "41. -1.35700837520322\n",
       "42. -1.75428448681736\n",
       "43. -1.37957919861126\n",
       "44. -2.1327109899638\n",
       "45. -1.65506385626159\n",
       "46. -2.04317410423554\n",
       "47. -1.04356034115533\n",
       "48. -1.92449976991232\n",
       "49. -1.12096093920791\n",
       "50. -1.69985300038013\n",
       "51. -1.17443134346666\n",
       "52. -1.5422836339531\n",
       "53. -1.18744273888201\n",
       "54. -1.93081847361729\n",
       "55. -1.46468272269438\n",
       "56. -1.86215145732924\n",
       "57. -1.48146352557417\n",
       "58. -1.82874655602123\n",
       "59. -1.18904953437531\n",
       "60. -1.65764615536382\n",
       "61. -1.17130334784726\n",
       "62. -1.5996382964561\n",
       "63. -1.32634063902711\n",
       "64. -1.95868741324063\n",
       "65. -1.76713997439075\n",
       "66. -2.13717247999674\n",
       "67. -1.85304902142057\n",
       "68. -2.299994587735\n",
       "69. -1.24757870155\n",
       "70. -1.62554764686527\n",
       "71. -1.47327676703882\n",
       "72. -1.76063036059576\n",
       "73. -1.63810761224732\n",
       "74. -1.9146233545523\n",
       "75. -1.56681675612615\n",
       "76. -1.86716376822476\n",
       "77. -1.21538976524779\n",
       "78. -1.61413291753807\n",
       "79. -1.40518817187142\n",
       "80. -1.80283720561206\n",
       "81. -1.46300166186671\n",
       "82. -1.98830268173586\n",
       "83. -0.895186327023369\n",
       "84. -1.28110403596284\n",
       "85. -1.2926305025988\n",
       "86. -1.73145502816297\n",
       "87. -1.08459302827083\n",
       "88. -2.14337014734412\n",
       "89. -1.19659488106562\n",
       "90. -2.09034742925849\n",
       "91. -1.17275028263899\n",
       "92. -1.66843485835972\n",
       "93. -1.50426847501816\n",
       "94. -2.01222527285742\n",
       "95. -1.27897769533842\n",
       "96. -1.70750526696798\n",
       "97. -1.56279764219285\n",
       "98. -1.98012676435886\n",
       "99. -1.40109479260375\n",
       "100. -1.76877910789933\n",
       "101. 0.897101070167164\n",
       "102. -1.81307260902119\n",
       "103. 0.98227885958466\n",
       "104. -1.93661104780891\n",
       "105. 1.13813300374404\n",
       "106. -1.78019135850233\n",
       "107. 1.0992538799282\n",
       "108. -1.37517293396215\n",
       "109. 1.17128732369451\n",
       "110. -1.6773638689594\n",
       "111. 1.14140953003219\n",
       "112. -1.54350383331165\n",
       "113. 1.14607005581052\n",
       "114. -2.02105190791495\n",
       "115. 0.585865284320402\n",
       "116. -1.37587196125575\n",
       "117. 0.970322693584876\n",
       "118. -1.58278750226219\n",
       "119. 1.02272881975659\n",
       "120. -1.71005902920941\n",
       "121. 0.830274919985541\n",
       "122. -1.0913686284018\n",
       "123. 0.997686993007088\n",
       "124. -1.89179141717371\n",
       "125. 0.821298218936411\n",
       "126. -1.08894193305175\n",
       "127. 1.20082981552078\n",
       "128. -1.63121067544132\n",
       "129. 0.625052799506564\n",
       "130. -1.82881707825933\n",
       "131. 0.832140470619176\n",
       "132. -1.82822042650789\n",
       "133. 1.22651305411531\n",
       "134. -1.81406336594621\n",
       "135. 0.725345911409081\n",
       "136. -1.35568466280011\n",
       "137. 1.41023091063462\n",
       "138. -1.34869410187497\n",
       "139. 0.804267709587767\n",
       "140. -1.36451377658183\n",
       "141. 1.46505840391781\n",
       "142. -2.08841253139355\n",
       "143. 0.780906943665939\n",
       "144. -1.67239738895275\n",
       "145. 1.4951003086818\n",
       "146. -1.42430584819928\n",
       "147. 1.09798010490961\n",
       "148. -1.41865900171448\n",
       "149. 0.845867543213927\n",
       "150. -1.65724957146606\n",
       "151. 0.891635021442136\n",
       "152. -1.76890617479071\n",
       "153. 1.14873208071938\n",
       "154. -1.5518658409575\n",
       "155. 1.41537298755641\n",
       "156. -1.84885837479038\n",
       "157. 1.181636694201\n",
       "158. -1.75801509625266\n",
       "159. 0.452433432900323\n",
       "160. -1.44790733510957\n",
       "161. 0.808361088855441\n",
       "162. -1.33045567886909\n",
       "163. 0.682224877656817\n",
       "164. -1.27876652366634\n",
       "165. 0.756013647585185\n",
       "166. -1.56008758922337\n",
       "167. 1.66201950052706\n",
       "168. -1.56610137080832\n",
       "169. 1.26826141841022\n",
       "170. -1.81275697313676\n",
       "171. 1.05926989046681\n",
       "172. -2.12826568202211\n",
       "173. 1.06907902492837\n",
       "174. -1.82939727370176\n",
       "175. 1.1538651089697\n",
       "176. -1.2793738891822\n",
       "177. 0.86343828860749\n",
       "178. -1.76119736354959\n",
       "179. 1.02201314257719\n",
       "180. -1.49249504458705\n",
       "181. 1.13426242047949\n",
       "182. -1.37318617467455\n",
       "183. 1.10680827528998\n",
       "184. -1.71512788475821\n",
       "185. 0.850035187815976\n",
       "186. -1.47617037990648\n",
       "187. 0.603611470848452\n",
       "188. -1.31786410234802\n",
       "189. 1.03470056618929\n",
       "190. -1.5599580436078\n",
       "191. 0.827230238371984\n",
       "192. -1.65964909674268\n",
       "193. 0.936585646690828\n",
       "194. -1.67793335063742\n",
       "195. 0.887615907508837\n",
       "196. -1.65594317865661\n",
       "197. 0.410028076327466\n",
       "198. -1.58855318059816\n",
       "199. 0.919804843811046\n",
       "200. -1.64452844932941\n",
       "201. 2.50290064281929\n",
       "202. -2.38522968872198\n",
       "203. 1.91597298375199\n",
       "204. -1.79563090562045\n",
       "205. 2.11342696153752\n",
       "206. -1.93194701119809\n",
       "207. 1.9406321537968\n",
       "208. -1.71299291903958\n",
       "209. 2.25400592251031\n",
       "210. -2.03022929598138\n",
       "211. 2.39686425168725\n",
       "212. -1.75841991519064\n",
       "213. 1.7072042518117\n",
       "214. -1.67007633296527\n",
       "215. 2.11969853320925\n",
       "216. -1.54273180505576\n",
       "217. 2.12241924301957\n",
       "218. -1.43044917539981\n",
       "219. 2.25457306902096\n",
       "220. -2.54183546829741\n",
       "221. 1.64748690498561\n",
       "222. -2.17045386622297\n",
       "223. 1.90153023397783\n",
       "224. -1.74903777603992\n",
       "225. 1.95444482175874\n",
       "226. -2.03101203800168\n",
       "227. 2.02942177133851\n",
       "228. -1.77985706180246\n",
       "229. 2.23102781329318\n",
       "230. -2.23901850696887\n",
       "231. 1.99136854917366\n",
       "232. -2.35012428943094\n",
       "233. 1.8048622492711\n",
       "234. -1.79821652116592\n",
       "235. 2.19316333133438\n",
       "236. -2.28005070929772\n",
       "237. 2.83814513819436\n",
       "238. -1.60255104674664\n",
       "239. 1.72898513270597\n",
       "240. -1.22110693904332\n",
       "241. 2.10860232465753\n",
       "242. -2.25236565543681\n",
       "243. 1.87903367590416\n",
       "244. -1.98044318533952\n",
       "245. 2.43789693880276\n",
       "246. -1.53954953775883\n",
       "247. 1.6300646902608\n",
       "248. -1.77246388644576\n",
       "249. 1.97026024099026\n",
       "250. -2.15582969952542\n",
       "251. 1.85850809466433\n",
       "252. -1.7938302366017\n",
       "253. 1.55691733217747\n",
       "254. -1.85572789935793\n",
       "255. 1.5559519485292\n",
       "256. -1.94714065957366\n",
       "257. 2.17058345925486\n",
       "258. -1.88582098775344\n",
       "259. 1.68347640961809\n",
       "260. -1.57312981557129\n",
       "261. 2.09737741627007\n",
       "262. -1.6121815633641\n",
       "263. 1.84374137308693\n",
       "264. -2.2032349457061\n",
       "265. 2.2413184988982\n",
       "266. -1.96276629696063\n",
       "267. 1.49004154576586\n",
       "268. -1.54977670612775\n",
       "269. 1.81530146554487\n",
       "270. -1.22792212346401\n",
       "271. 2.24045429105004\n",
       "272. -2.03924450003195\n",
       "273. 2.1719405482793\n",
       "274. -2.46797005084499\n",
       "275. 1.78711606274305\n",
       "276. -1.85622438007365\n",
       "277. 1.52142495912137\n",
       "278. -1.97174361717337\n",
       "279. 1.8395490993805\n",
       "280. -2.11558244372329\n",
       "281. 2.204304925716\n",
       "282. -2.29459967052654\n",
       "283. 1.81481566400131\n",
       "284. -2.345241524151\n",
       "285. 1.91597298375199\n",
       "286. -1.79563090562045\n",
       "287. 2.24027884991556\n",
       "288. -2.2012001510232\n",
       "289. 2.25320039956361\n",
       "290. -2.4636109363542\n",
       "291. 1.95058556852702\n",
       "292. -2.26001792202466\n",
       "293. 1.83344163881044\n",
       "294. -1.70683093102362\n",
       "295. 1.78012881389191\n",
       "296. -2.02787560159363\n",
       "297. 2.01127734767284\n",
       "298. -2.44088385324195\n",
       "299. 1.70850265593468\n",
       "300. -1.89532195875533\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]      [,2]      [,3]      [,4]      [,5]      [,6]     [,7]     \n",
       "[1,] -1.499210 -1.264360 -1.355253 -1.184956 -1.516956 -1.40864 -1.285483\n",
       "[2,] -1.886754 -1.592143 -1.733415 -1.623588 -1.944762 -2.20148 -1.901773\n",
       "     [,8]      [,9]      [,10]     [,11] [,12]     [,13]     [,14]    \n",
       "[1,] -1.384314 -1.121368 -1.318314 ...    2.204305  1.814816  1.915973\n",
       "[2,] -1.802184 -1.530216 -1.548602 ...   -2.294600 -2.345242 -1.795631\n",
       "     [,15]     [,16]     [,17]     [,18]     [,19]     [,20]     [,21]    \n",
       "[1,]  2.240279  2.253200  1.950586  1.833442  1.780129  2.011277  1.708503\n",
       "[2,] -2.201200 -2.463611 -2.260018 -1.706831 -2.027876 -2.440884 -1.895322"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "t(res$vectors[,c(1,2)]) %*% X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 229,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\nAElFTkSuQmCC",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "XY <- t(t(res$vectors[,c(1,2)]) %*% X)\n",
    "\n",
    "plot(XY,cex=0) # silly R setting\n",
    "points(XY[group == unique(group)[1],],pch=1)\n",
    "points(XY[group == unique(group)[2],],pch=2)\n",
    "points(XY[group == unique(group)[3],],pch=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 230,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAAMFBMVEUAAABNTU1oaGh8fHyM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\n2vNQ8ZkAAAAASUVORK5CYII=",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "#XY <- t(t(res$vectors[,c(1,2)]) %*% X)\n",
    "XY <- iris[,c(1,2)]\n",
    "\n",
    "plot(XY,cex=0) # silly R setting\n",
    "points(XY[group == unique(group)[1],],pch=1)\n",
    "points(XY[group == unique(group)[2],],pch=2)\n",
    "points(XY[group == unique(group)[3],],pch=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "可以看出变换后和变换前（的一种组合）的混杂程度果然大大的下降了。另外也可以看出其实只要一个轴就基本已经能把它们区分开来了。正如32与0.28的区别。\n",
    "\n",
    "### 判别执行\n",
    "\n",
    "得出这些判别向量$a_i$后，我们用它们去作用几个分组的均值，将$p$维总体的均值投影到$r$维上（$r$为我们使用的$a$的数量）。\n",
    "我们前面的处理使得我们知道这些均值投影会尽可能分开，即使甚至它们在高维空间都没有分开。\n",
    "\n",
    "然后对于新的未知分类样本，我们直接看它也如此投影后相比那几个分组对应的中心哪个最近就判定为那个，近是直接用欧氏距离。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 231,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th><th scope=col>Petal.Length</th><th scope=col>Petal.Width</th><th scope=col>Species</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>5.1   </td><td>3.5   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.9   </td><td>3.0   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.7   </td><td>3.2   </td><td>1.3   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>4.6   </td><td>3.1   </td><td>1.5   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>5.0   </td><td>3.6   </td><td>1.4   </td><td>0.2   </td><td>setosa</td></tr>\n",
       "\t<tr><td>5.4   </td><td>3.9   </td><td>1.7   </td><td>0.4   </td><td>setosa</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllll}\n",
       " Sepal.Length & Sepal.Width & Petal.Length & Petal.Width & Species\\\\\n",
       "\\hline\n",
       "\t 5.1    & 3.5    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 4.9    & 3.0    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 4.7    & 3.2    & 1.3    & 0.2    & setosa\\\\\n",
       "\t 4.6    & 3.1    & 1.5    & 0.2    & setosa\\\\\n",
       "\t 5.0    & 3.6    & 1.4    & 0.2    & setosa\\\\\n",
       "\t 5.4    & 3.9    & 1.7    & 0.4    & setosa\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  Sepal.Length Sepal.Width Petal.Length Petal.Width Species\n",
       "1 5.1          3.5         1.4          0.2         setosa \n",
       "2 4.9          3.0         1.4          0.2         setosa \n",
       "3 4.7          3.2         1.3          0.2         setosa \n",
       "4 4.6          3.1         1.5          0.2         setosa \n",
       "5 5.0          3.6         1.4          0.2         setosa \n",
       "6 5.4          3.9         1.7          0.4         setosa "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df <- iris\n",
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df[,c('X1','X2')] <- as.matrix(df[,-ncol(df)]) %*% res$vectors[,c(1,2)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th><th scope=col>Petal.Length</th><th scope=col>Petal.Width</th><th scope=col>Species</th><th scope=col>X1</th><th scope=col>X2</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>5.1      </td><td>3.5      </td><td>1.4      </td><td>0.2      </td><td>setosa   </td><td>-1.499210</td><td>-1.886754</td></tr>\n",
       "\t<tr><td>4.9      </td><td>3.0      </td><td>1.4      </td><td>0.2      </td><td>setosa   </td><td>-1.264360</td><td>-1.592143</td></tr>\n",
       "\t<tr><td>4.7      </td><td>3.2      </td><td>1.3      </td><td>0.2      </td><td>setosa   </td><td>-1.355253</td><td>-1.733415</td></tr>\n",
       "\t<tr><td>4.6      </td><td>3.1      </td><td>1.5      </td><td>0.2      </td><td>setosa   </td><td>-1.184956</td><td>-1.623588</td></tr>\n",
       "\t<tr><td>5.0      </td><td>3.6      </td><td>1.4      </td><td>0.2      </td><td>setosa   </td><td>-1.516956</td><td>-1.944762</td></tr>\n",
       "\t<tr><td>5.4      </td><td>3.9      </td><td>1.7      </td><td>0.4      </td><td>setosa   </td><td>-1.408640</td><td>-2.201480</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllll}\n",
       " Sepal.Length & Sepal.Width & Petal.Length & Petal.Width & Species & X1 & X2\\\\\n",
       "\\hline\n",
       "\t 5.1       & 3.5       & 1.4       & 0.2       & setosa    & -1.499210 & -1.886754\\\\\n",
       "\t 4.9       & 3.0       & 1.4       & 0.2       & setosa    & -1.264360 & -1.592143\\\\\n",
       "\t 4.7       & 3.2       & 1.3       & 0.2       & setosa    & -1.355253 & -1.733415\\\\\n",
       "\t 4.6       & 3.1       & 1.5       & 0.2       & setosa    & -1.184956 & -1.623588\\\\\n",
       "\t 5.0       & 3.6       & 1.4       & 0.2       & setosa    & -1.516956 & -1.944762\\\\\n",
       "\t 5.4       & 3.9       & 1.7       & 0.4       & setosa    & -1.408640 & -2.201480\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  Sepal.Length Sepal.Width Petal.Length Petal.Width Species X1        X2       \n",
       "1 5.1          3.5         1.4          0.2         setosa  -1.499210 -1.886754\n",
       "2 4.9          3.0         1.4          0.2         setosa  -1.264360 -1.592143\n",
       "3 4.7          3.2         1.3          0.2         setosa  -1.355253 -1.733415\n",
       "4 4.6          3.1         1.5          0.2         setosa  -1.184956 -1.623588\n",
       "5 5.0          3.6         1.4          0.2         setosa  -1.516956 -1.944762\n",
       "6 5.4          3.9         1.7          0.4         setosa  -1.408640 -2.201480"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "cm <- NULL\n",
    "for (species in unique(df$Species)){\n",
    "    cm <- rbind(cm, apply(df[df$Species == species,1:4],2,mean) %*% res$vectors[,c(1,2)])\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>-1.3848945</td><td>-1.863640 </td></tr>\n",
       "\t<tr><td> 0.9891609</td><td>-1.608068 </td></tr>\n",
       "\t<tr><td> 1.9852041</td><td>-1.944303 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{ll}\n",
       "\t -1.3848945 & -1.863640 \\\\\n",
       "\t  0.9891609 & -1.608068 \\\\\n",
       "\t  1.9852041 & -1.944303 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. -1.38489447083703\n",
       "2. 0.989160869341429\n",
       "3. 1.98520406363966\n",
       "4. -1.86364047723611\n",
       "5. -1.60806761023759\n",
       "6. -1.94430265834679\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]       [,2]     \n",
       "[1,] -1.3848945 -1.863640\n",
       "[2,]  0.9891609 -1.608068\n",
       "[3,]  1.9852041 -1.944303"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred <- NULL\n",
    "\n",
    "for(i in 1:nrow(df)){\n",
    "    score <- apply((cm - t(matrix(rep(as.matrix(df[i,c(\"X1\",\"X2\")]),3),2)))^2,1,sum)\n",
    "    id <- which(score == min(score))\n",
    "    if(length(id)>1){\n",
    "        cat(\"warming\")\n",
    "    }\n",
    "    pred <- c(pred,id)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 1\n",
       "3. 1\n",
       "4. 1\n",
       "5. 1\n",
       "6. 1\n",
       "7. 1\n",
       "8. 1\n",
       "9. 1\n",
       "10. 1\n",
       "11. 1\n",
       "12. 1\n",
       "13. 1\n",
       "14. 1\n",
       "15. 1\n",
       "16. 1\n",
       "17. 1\n",
       "18. 1\n",
       "19. 1\n",
       "20. 1\n",
       "21. 1\n",
       "22. 1\n",
       "23. 1\n",
       "24. 1\n",
       "25. 1\n",
       "26. 1\n",
       "27. 1\n",
       "28. 1\n",
       "29. 1\n",
       "30. 1\n",
       "31. 1\n",
       "32. 1\n",
       "33. 1\n",
       "34. 1\n",
       "35. 1\n",
       "36. 1\n",
       "37. 1\n",
       "38. 1\n",
       "39. 1\n",
       "40. 1\n",
       "41. 1\n",
       "42. 1\n",
       "43. 1\n",
       "44. 1\n",
       "45. 1\n",
       "46. 1\n",
       "47. 1\n",
       "48. 1\n",
       "49. 1\n",
       "50. 1\n",
       "51. 2\n",
       "52. 2\n",
       "53. 2\n",
       "54. 2\n",
       "55. 2\n",
       "56. 2\n",
       "57. 2\n",
       "58. 2\n",
       "59. 2\n",
       "60. 2\n",
       "61. 2\n",
       "62. 2\n",
       "63. 2\n",
       "64. 2\n",
       "65. 2\n",
       "66. 2\n",
       "67. 2\n",
       "68. 2\n",
       "69. 2\n",
       "70. 2\n",
       "71. 3\n",
       "72. 2\n",
       "73. 2\n",
       "74. 2\n",
       "75. 2\n",
       "76. 2\n",
       "77. 2\n",
       "78. 2\n",
       "79. 2\n",
       "80. 2\n",
       "81. 2\n",
       "82. 2\n",
       "83. 2\n",
       "84. 3\n",
       "85. 2\n",
       "86. 2\n",
       "87. 2\n",
       "88. 2\n",
       "89. 2\n",
       "90. 2\n",
       "91. 2\n",
       "92. 2\n",
       "93. 2\n",
       "94. 2\n",
       "95. 2\n",
       "96. 2\n",
       "97. 2\n",
       "98. 2\n",
       "99. 2\n",
       "100. 2\n",
       "101. 3\n",
       "102. 3\n",
       "103. 3\n",
       "104. 3\n",
       "105. 3\n",
       "106. 3\n",
       "107. 3\n",
       "108. 3\n",
       "109. 3\n",
       "110. 3\n",
       "111. 3\n",
       "112. 3\n",
       "113. 3\n",
       "114. 3\n",
       "115. 3\n",
       "116. 3\n",
       "117. 3\n",
       "118. 3\n",
       "119. 3\n",
       "120. 3\n",
       "121. 3\n",
       "122. 3\n",
       "123. 3\n",
       "124. 3\n",
       "125. 3\n",
       "126. 3\n",
       "127. 3\n",
       "128. 3\n",
       "129. 3\n",
       "130. 3\n",
       "131. 3\n",
       "132. 3\n",
       "133. 3\n",
       "134. 2\n",
       "135. 3\n",
       "136. 3\n",
       "137. 3\n",
       "138. 3\n",
       "139. 3\n",
       "140. 3\n",
       "141. 3\n",
       "142. 3\n",
       "143. 3\n",
       "144. 3\n",
       "145. 3\n",
       "146. 3\n",
       "147. 3\n",
       "148. 3\n",
       "149. 3\n",
       "150. 3\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2\n",
       " [75] 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3\n",
       "[112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 2 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
       "[149] 3 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df$predict <- pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "</ol>\n"
      ],
      "text/latex": [
       "\\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\end{enumerate*}\n"
      ],
      "text/markdown": [
       "1. 1\n",
       "2. 1\n",
       "3. 1\n",
       "4. 1\n",
       "5. 1\n",
       "6. 1\n",
       "7. 1\n",
       "8. 1\n",
       "9. 1\n",
       "10. 1\n",
       "11. 1\n",
       "12. 1\n",
       "13. 1\n",
       "14. 1\n",
       "15. 1\n",
       "16. 1\n",
       "17. 1\n",
       "18. 1\n",
       "19. 1\n",
       "20. 1\n",
       "21. 1\n",
       "22. 1\n",
       "23. 1\n",
       "24. 1\n",
       "25. 1\n",
       "26. 1\n",
       "27. 1\n",
       "28. 1\n",
       "29. 1\n",
       "30. 1\n",
       "31. 1\n",
       "32. 1\n",
       "33. 1\n",
       "34. 1\n",
       "35. 1\n",
       "36. 1\n",
       "37. 1\n",
       "38. 1\n",
       "39. 1\n",
       "40. 1\n",
       "41. 1\n",
       "42. 1\n",
       "43. 1\n",
       "44. 1\n",
       "45. 1\n",
       "46. 1\n",
       "47. 1\n",
       "48. 1\n",
       "49. 1\n",
       "50. 1\n",
       "51. 2\n",
       "52. 2\n",
       "53. 2\n",
       "54. 2\n",
       "55. 2\n",
       "56. 2\n",
       "57. 2\n",
       "58. 2\n",
       "59. 2\n",
       "60. 2\n",
       "61. 2\n",
       "62. 2\n",
       "63. 2\n",
       "64. 2\n",
       "65. 2\n",
       "66. 2\n",
       "67. 2\n",
       "68. 2\n",
       "69. 2\n",
       "70. 2\n",
       "71. 2\n",
       "72. 2\n",
       "73. 2\n",
       "74. 2\n",
       "75. 2\n",
       "76. 2\n",
       "77. 2\n",
       "78. 2\n",
       "79. 2\n",
       "80. 2\n",
       "81. 2\n",
       "82. 2\n",
       "83. 2\n",
       "84. 2\n",
       "85. 2\n",
       "86. 2\n",
       "87. 2\n",
       "88. 2\n",
       "89. 2\n",
       "90. 2\n",
       "91. 2\n",
       "92. 2\n",
       "93. 2\n",
       "94. 2\n",
       "95. 2\n",
       "96. 2\n",
       "97. 2\n",
       "98. 2\n",
       "99. 2\n",
       "100. 2\n",
       "101. 3\n",
       "102. 3\n",
       "103. 3\n",
       "104. 3\n",
       "105. 3\n",
       "106. 3\n",
       "107. 3\n",
       "108. 3\n",
       "109. 3\n",
       "110. 3\n",
       "111. 3\n",
       "112. 3\n",
       "113. 3\n",
       "114. 3\n",
       "115. 3\n",
       "116. 3\n",
       "117. 3\n",
       "118. 3\n",
       "119. 3\n",
       "120. 3\n",
       "121. 3\n",
       "122. 3\n",
       "123. 3\n",
       "124. 3\n",
       "125. 3\n",
       "126. 3\n",
       "127. 3\n",
       "128. 3\n",
       "129. 3\n",
       "130. 3\n",
       "131. 3\n",
       "132. 3\n",
       "133. 3\n",
       "134. 3\n",
       "135. 3\n",
       "136. 3\n",
       "137. 3\n",
       "138. 3\n",
       "139. 3\n",
       "140. 3\n",
       "141. 3\n",
       "142. 3\n",
       "143. 3\n",
       "144. 3\n",
       "145. 3\n",
       "146. 3\n",
       "147. 3\n",
       "148. 3\n",
       "149. 3\n",
       "150. 3\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2\n",
       " [75] 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3\n",
       "[112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
       "[149] 3 3"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "spec <- unique(df$Species)\n",
    "\n",
    "real <- sapply(df$Species,function(name){\n",
    "    which(name == spec)\n",
    "})\n",
    "real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "147"
      ],
      "text/latex": [
       "147"
      ],
      "text/markdown": [
       "147"
      ],
      "text/plain": [
       "[1] 147"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(real == pred)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "0.98"
      ],
      "text/latex": [
       "0.98"
      ],
      "text/markdown": [
       "0.98"
      ],
      "text/plain": [
       "[1] 0.98"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sum(real == pred) / length(pred)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fisher判别效果还不错，150个样本只错判了3个。和那个SPSS做的结果一致。\n",
    "\n",
    "下面测试贝叶斯判别（设先验概率一样，于是就直接比较似然度了）。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pl <- list()\n",
    "\n",
    "for(k in sl){\n",
    "    X <- t(as.matrix(iris[iris$Species == k,-ncol(iris)]))\n",
    "    mu <- apply(X,1,mean)\n",
    "    sigma <- ((X - mu) %*% t(X - mu))/(nrow(X)-1)\n",
    "    pl[[k]] <- list(mu = mu, sigma = sigma)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$setosa</dt>\n",
       "\t\t<dd><dl>\n",
       "\t<dt>$mu</dt>\n",
       "\t\t<dd><dl class=dl-horizontal>\n",
       "\t<dt>Sepal.Length</dt>\n",
       "\t\t<dd>5.006</dd>\n",
       "\t<dt>Sepal.Width</dt>\n",
       "\t\t<dd>3.428</dd>\n",
       "\t<dt>Petal.Length</dt>\n",
       "\t\t<dd>1.462</dd>\n",
       "\t<dt>Petal.Width</dt>\n",
       "\t\t<dd>0.246</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "\t<dt>$sigma</dt>\n",
       "\t\t<dd><table>\n",
       "<thead><tr><th></th><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th><th scope=col>Petal.Length</th><th scope=col>Petal.Width</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Sepal.Length</th><td>2.0294000 </td><td>1.6205333 </td><td>0.26713333</td><td>0.16873333</td></tr>\n",
       "\t<tr><th scope=row>Sepal.Width</th><td>1.6205333 </td><td>2.3469333 </td><td>0.19106667</td><td>0.15186667</td></tr>\n",
       "\t<tr><th scope=row>Petal.Length</th><td>0.2671333 </td><td>0.1910667 </td><td>0.49260000</td><td>0.09913333</td></tr>\n",
       "\t<tr><th scope=row>Petal.Width</th><td>0.1687333 </td><td>0.1518667 </td><td>0.09913333</td><td>0.18140000</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "\t<dt>$versicolor</dt>\n",
       "\t\t<dd><dl>\n",
       "\t<dt>$mu</dt>\n",
       "\t\t<dd><dl class=dl-horizontal>\n",
       "\t<dt>Sepal.Length</dt>\n",
       "\t\t<dd>5.936</dd>\n",
       "\t<dt>Sepal.Width</dt>\n",
       "\t\t<dd>2.77</dd>\n",
       "\t<dt>Petal.Length</dt>\n",
       "\t\t<dd>4.26</dd>\n",
       "\t<dt>Petal.Width</dt>\n",
       "\t\t<dd>1.326</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "\t<dt>$sigma</dt>\n",
       "\t\t<dd><table>\n",
       "<thead><tr><th></th><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th><th scope=col>Petal.Length</th><th scope=col>Petal.Width</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Sepal.Length</th><td>4.3517333</td><td>1.391333 </td><td>2.987333 </td><td>0.9110667</td></tr>\n",
       "\t<tr><th scope=row>Sepal.Width</th><td>1.3913333</td><td>1.608333 </td><td>1.350000 </td><td>0.6730000</td></tr>\n",
       "\t<tr><th scope=row>Petal.Length</th><td>2.9873333</td><td>1.350000 </td><td>3.606667 </td><td>1.1940000</td></tr>\n",
       "\t<tr><th scope=row>Petal.Width</th><td>0.9110667</td><td>0.673000 </td><td>1.194000 </td><td>0.6387333</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "\t<dt>$virginica</dt>\n",
       "\t\t<dd><dl>\n",
       "\t<dt>$mu</dt>\n",
       "\t\t<dd><dl class=dl-horizontal>\n",
       "\t<dt>Sepal.Length</dt>\n",
       "\t\t<dd>6.588</dd>\n",
       "\t<dt>Sepal.Width</dt>\n",
       "\t\t<dd>2.974</dd>\n",
       "\t<dt>Petal.Length</dt>\n",
       "\t\t<dd>5.552</dd>\n",
       "\t<dt>Petal.Width</dt>\n",
       "\t\t<dd>2.026</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "\t<dt>$sigma</dt>\n",
       "\t\t<dd><table>\n",
       "<thead><tr><th></th><th scope=col>Sepal.Length</th><th scope=col>Sepal.Width</th><th scope=col>Petal.Length</th><th scope=col>Petal.Width</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>Sepal.Length</th><td>6.6042667</td><td>1.5314667</td><td>4.9537333</td><td>0.8018667</td></tr>\n",
       "\t<tr><th scope=row>Sepal.Width</th><td>1.5314667</td><td>1.6987333</td><td>1.1658667</td><td>0.7779333</td></tr>\n",
       "\t<tr><th scope=row>Petal.Length</th><td>4.9537333</td><td>1.1658667</td><td>4.9749333</td><td>0.7974667</td></tr>\n",
       "\t<tr><th scope=row>Petal.Width</th><td>0.8018667</td><td>0.7779333</td><td>0.7974667</td><td>1.2320667</td></tr>\n",
       "</tbody>\n",
       "</table>\n",
       "</dd>\n",
       "</dl>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$setosa] \\begin{description}\n",
       "\\item[\\$mu] \\begin{description*}\n",
       "\\item[Sepal.Length] 5.006\n",
       "\\item[Sepal.Width] 3.428\n",
       "\\item[Petal.Length] 1.462\n",
       "\\item[Petal.Width] 0.246\n",
       "\\end{description*}\n",
       "\n",
       "\\item[\\$sigma] \\begin{tabular}{r|llll}\n",
       "  & Sepal.Length & Sepal.Width & Petal.Length & Petal.Width\\\\\n",
       "\\hline\n",
       "\tSepal.Length & 2.0294000  & 1.6205333  & 0.26713333 & 0.16873333\\\\\n",
       "\tSepal.Width & 1.6205333  & 2.3469333  & 0.19106667 & 0.15186667\\\\\n",
       "\tPetal.Length & 0.2671333  & 0.1910667  & 0.49260000 & 0.09913333\\\\\n",
       "\tPetal.Width & 0.1687333  & 0.1518667  & 0.09913333 & 0.18140000\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n",
       "\n",
       "\\item[\\$versicolor] \\begin{description}\n",
       "\\item[\\$mu] \\begin{description*}\n",
       "\\item[Sepal.Length] 5.936\n",
       "\\item[Sepal.Width] 2.77\n",
       "\\item[Petal.Length] 4.26\n",
       "\\item[Petal.Width] 1.326\n",
       "\\end{description*}\n",
       "\n",
       "\\item[\\$sigma] \\begin{tabular}{r|llll}\n",
       "  & Sepal.Length & Sepal.Width & Petal.Length & Petal.Width\\\\\n",
       "\\hline\n",
       "\tSepal.Length & 4.3517333 & 1.391333  & 2.987333  & 0.9110667\\\\\n",
       "\tSepal.Width & 1.3913333 & 1.608333  & 1.350000  & 0.6730000\\\\\n",
       "\tPetal.Length & 2.9873333 & 1.350000  & 3.606667  & 1.1940000\\\\\n",
       "\tPetal.Width & 0.9110667 & 0.673000  & 1.194000  & 0.6387333\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n",
       "\n",
       "\\item[\\$virginica] \\begin{description}\n",
       "\\item[\\$mu] \\begin{description*}\n",
       "\\item[Sepal.Length] 6.588\n",
       "\\item[Sepal.Width] 2.974\n",
       "\\item[Petal.Length] 5.552\n",
       "\\item[Petal.Width] 2.026\n",
       "\\end{description*}\n",
       "\n",
       "\\item[\\$sigma] \\begin{tabular}{r|llll}\n",
       "  & Sepal.Length & Sepal.Width & Petal.Length & Petal.Width\\\\\n",
       "\\hline\n",
       "\tSepal.Length & 6.6042667 & 1.5314667 & 4.9537333 & 0.8018667\\\\\n",
       "\tSepal.Width & 1.5314667 & 1.6987333 & 1.1658667 & 0.7779333\\\\\n",
       "\tPetal.Length & 4.9537333 & 1.1658667 & 4.9749333 & 0.7974667\\\\\n",
       "\tPetal.Width & 0.8018667 & 0.7779333 & 0.7974667 & 1.2320667\\\\\n",
       "\\end{tabular}\n",
       "\n",
       "\\end{description}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$setosa\n",
       ":   $mu\n",
       ":   Sepal.Length\n",
       ":   5.006Sepal.Width\n",
       ":   3.428Petal.Length\n",
       ":   1.462Petal.Width\n",
       ":   0.246\n",
       "\n",
       "\n",
       "$sigma\n",
       ":   1. 2.0294\n",
       "2. 1.62053333333333\n",
       "3. 0.267133333333333\n",
       "4. 0.168733333333333\n",
       "5. 1.62053333333333\n",
       "6. 2.34693333333333\n",
       "7. 0.191066666666666\n",
       "8. 0.151866666666667\n",
       "9. 0.267133333333333\n",
       "10. 0.191066666666666\n",
       "11. 0.4926\n",
       "12. 0.0991333333333333\n",
       "13. 0.168733333333333\n",
       "14. 0.151866666666667\n",
       "15. 0.0991333333333333\n",
       "16. 0.1814\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "$versicolor\n",
       ":   $mu\n",
       ":   Sepal.Length\n",
       ":   5.936Sepal.Width\n",
       ":   2.77Petal.Length\n",
       ":   4.26Petal.Width\n",
       ":   1.326\n",
       "\n",
       "\n",
       "$sigma\n",
       ":   1. 4.35173333333333\n",
       "2. 1.39133333333333\n",
       "3. 2.98733333333334\n",
       "4. 0.911066666666667\n",
       "5. 1.39133333333333\n",
       "6. 1.60833333333333\n",
       "7. 1.35\n",
       "8. 0.673\n",
       "9. 2.98733333333334\n",
       "10. 1.35\n",
       "11. 3.60666666666667\n",
       "12. 1.194\n",
       "13. 0.911066666666667\n",
       "14. 0.673\n",
       "15. 1.194\n",
       "16. 0.638733333333333\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "$virginica\n",
       ":   $mu\n",
       ":   Sepal.Length\n",
       ":   6.588Sepal.Width\n",
       ":   2.974Petal.Length\n",
       ":   5.552Petal.Width\n",
       ":   2.026\n",
       "\n",
       "\n",
       "$sigma\n",
       ":   1. 6.60426666666667\n",
       "2. 1.53146666666667\n",
       "3. 4.95373333333334\n",
       "4. 0.801866666666667\n",
       "5. 1.53146666666667\n",
       "6. 1.69873333333333\n",
       "7. 1.16586666666667\n",
       "8. 0.777933333333333\n",
       "9. 4.95373333333334\n",
       "10. 1.16586666666667\n",
       "11. 4.97493333333334\n",
       "12. 0.797466666666667\n",
       "13. 0.801866666666667\n",
       "14. 0.777933333333333\n",
       "15. 0.797466666666667\n",
       "16. 1.23206666666667\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$setosa\n",
       "$setosa$mu\n",
       "Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n",
       "       5.006        3.428        1.462        0.246 \n",
       "\n",
       "$setosa$sigma\n",
       "             Sepal.Length Sepal.Width Petal.Length Petal.Width\n",
       "Sepal.Length    2.0294000   1.6205333   0.26713333  0.16873333\n",
       "Sepal.Width     1.6205333   2.3469333   0.19106667  0.15186667\n",
       "Petal.Length    0.2671333   0.1910667   0.49260000  0.09913333\n",
       "Petal.Width     0.1687333   0.1518667   0.09913333  0.18140000\n",
       "\n",
       "\n",
       "$versicolor\n",
       "$versicolor$mu\n",
       "Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n",
       "       5.936        2.770        4.260        1.326 \n",
       "\n",
       "$versicolor$sigma\n",
       "             Sepal.Length Sepal.Width Petal.Length Petal.Width\n",
       "Sepal.Length    4.3517333    1.391333     2.987333   0.9110667\n",
       "Sepal.Width     1.3913333    1.608333     1.350000   0.6730000\n",
       "Petal.Length    2.9873333    1.350000     3.606667   1.1940000\n",
       "Petal.Width     0.9110667    0.673000     1.194000   0.6387333\n",
       "\n",
       "\n",
       "$virginica\n",
       "$virginica$mu\n",
       "Sepal.Length  Sepal.Width Petal.Length  Petal.Width \n",
       "       6.588        2.974        5.552        2.026 \n",
       "\n",
       "$virginica$sigma\n",
       "             Sepal.Length Sepal.Width Petal.Length Petal.Width\n",
       "Sepal.Length    6.6042667   1.5314667    4.9537333   0.8018667\n",
       "Sepal.Width     1.5314667   1.6987333    1.1658667   0.7779333\n",
       "Petal.Length    4.9537333   1.1658667    4.9749333   0.7974667\n",
       "Petal.Width     0.8018667   0.7779333    0.7974667   1.2320667\n",
       "\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "pl"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 272,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "rm <- apply(t(as.matrix(iris[,-ncol(iris)])),2,function(x){\n",
    "    #dmultinorm(x,pl[[1]]$mu,pl[[1]]$sigma)\n",
    "    likelihood <- sapply(pl,function(p){\n",
    "        dmultinorm(x,p$mu,p$sigma)\n",
    "    })\n",
    "    distance <- sapply(pl,function(p){\n",
    "        t(x - p$mu) %*% solve(p$sigma) %*% (x - p$mu)\n",
    "    })\n",
    "    likelihood_predict <- which(likelihood == max(likelihood))\n",
    "    distance_predict <- which(distance == min(distance))\n",
    "    return(c(likelihood,likelihood_predict,distance,distance_predict))\n",
    "})\n",
    "\n",
    "df[,c(\"lk_C1\",\"lk_C2\",\"lk_C3\",\"lk_predict\",\"dis_C1\",\"dis_C2\",\"dis_C3\",\"dis_predict\")] <- t(rm)\n",
    "df[,'real'] <- real"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 275,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>real</th><th scope=col>predict</th><th scope=col>lk_predict</th><th scope=col>dis_predict</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1</td><td>1</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>1</td><td>1</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>1</td><td>1</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>1</td><td>1</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>1</td><td>1</td><td>1</td><td>1</td></tr>\n",
       "\t<tr><td>1</td><td>1</td><td>1</td><td>1</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llll}\n",
       " real & predict & lk\\_predict & dis\\_predict\\\\\n",
       "\\hline\n",
       "\t 1 & 1 & 1 & 1\\\\\n",
       "\t 1 & 1 & 1 & 1\\\\\n",
       "\t 1 & 1 & 1 & 1\\\\\n",
       "\t 1 & 1 & 1 & 1\\\\\n",
       "\t 1 & 1 & 1 & 1\\\\\n",
       "\t 1 & 1 & 1 & 1\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  real predict lk_predict dis_predict\n",
       "1 1    1       1          1          \n",
       "2 1    1       1          1          \n",
       "3 1    1       1          1          \n",
       "4 1    1       1          1          \n",
       "5 1    1       1          1          \n",
       "6 1    1       1          1          "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df[,c('real','predict','lk_predict','dis_predict')])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl class=dl-horizontal>\n",
       "\t<dt>predict</dt>\n",
       "\t\t<dd>0.98</dd>\n",
       "\t<dt>lk_predict</dt>\n",
       "\t\t<dd>0.986666666666667</dd>\n",
       "\t<dt>dis_predict</dt>\n",
       "\t\t<dd>0.98</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description*}\n",
       "\\item[predict] 0.98\n",
       "\\item[lk\\textbackslash{}\\_predict] 0.986666666666667\n",
       "\\item[dis\\textbackslash{}\\_predict] 0.98\n",
       "\\end{description*}\n"
      ],
      "text/markdown": [
       "predict\n",
       ":   0.98lk_predict\n",
       ":   0.986666666666667dis_predict\n",
       ":   0.98\n",
       "\n"
      ],
      "text/plain": [
       "    predict  lk_predict dis_predict \n",
       "  0.9800000   0.9866667   0.9800000 "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "apply(df[,c('predict','lk_predict','dis_predict')],2,function(arr){\n",
    "    mean(arr == df$real)\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "起码在这个特例里三种判别方法效率都差不多。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 443,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "predict.discriminant <- function(model, data, feature, decode = TRUE){\n",
    "    X <- t(as.matrix(data[,feature]))\n",
    "    pl <- model$pl\n",
    "    fisher.a <- model$fisher.a\n",
    "    fisher.kf <- model$fisher.kf\n",
    "    fisher.n <- model$fisher.n\n",
    "    \n",
    "    fisher.rf <- fisher.a %*% X # record feature\n",
    "    \n",
    "    fisher.predict <- apply(fisher.rf, 2, function(rf){\n",
    "        L2 <- apply((matrix(rep(rf, ncol(fisher.kf)), fisher.n) - fisher.kf)^2, 2, sum)\n",
    "        return(which(L2 == min(L2)))\n",
    "    })\n",
    "    \n",
    "    bayes.predict <- apply(X, 2, function(x){\n",
    "        likelihood <- sapply(pl,function(p){\n",
    "            dmultinorm(x, p$mu, p$sigma)\n",
    "        })\n",
    "        return(which(likelihood == max(likelihood)))\n",
    "    })\n",
    "    \n",
    "    distance.predict <- apply(X, 2, function(x){\n",
    "        distance <- sapply(pl,function(p){\n",
    "            t(x - p$mu) %*% p$sigma.inv %*% (x - p$mu)\n",
    "        })\n",
    "        return(which(distance == min(distance)))\n",
    "    })\n",
    "    \n",
    "    if(decode){\n",
    "        fisher.predict <- sapply(fisher.predict, function(k){model$decode[[k]]})\n",
    "        bayes.predict <- sapply(bayes.predict, function(k){model$decode[[k]]})\n",
    "        distance.predict <- sapply(distance.predict, function(k){model$decode[[k]]})\n",
    "    }\n",
    "    \n",
    "    return(list(fisher.predict = fisher.predict, bayes.predict = bayes.predict, distance.predict = distance.predict))\n",
    "}\n",
    "\n",
    "discriminant <- function(data, feature, group, fisher.cut = 0.95, fisher.n = NULL){\n",
    "    \n",
    "    X <- t(as.matrix(data[,feature]))\n",
    "    gl <- unique(data[,group])\n",
    "    real <- sapply(data[,group],function(g){\n",
    "        which(gl == g)\n",
    "    })\n",
    "    rl <- unique(real)\n",
    "    n <- nrow(data)\n",
    "    p <- length(feature)\n",
    "    \n",
    "    pl <- lapply(rl,function(r){\n",
    "        subX <- X[,real == r]\n",
    "        mu <- apply(subX,1,mean)\n",
    "        sigma <- (subX - mu) %*% t(subX - mu)  / (n-1)\n",
    "        return(list(mu = mu, sigma = sigma, sigma.inv = solve(sigma)))\n",
    "    })\n",
    "    \n",
    "    d <- decomp(X, real)\n",
    "    #M <- solve(d$E) %*% d$B # this way will cause numerical problem? It some time runs well,but...\n",
    "    M <- solve(d$W) %*% d$B\n",
    "    res <- eigen(M)\n",
    "    if(is.null(fisher.n)){\n",
    "        fisher.n <- min(which(cumsum(res$values)/sum(res$values) > fisher.cut)  )\n",
    "    }\n",
    "    fisher.a <- t(res$vectors[,1:fisher.n])\n",
    "    #fisher.rf <- fisher.a %*% X # record feature\n",
    "    fisher.kf <- fisher.a %*% sapply(pl,function(p){p$mu}) # (mean) class feature\n",
    "\n",
    "    model <- list(pl = pl, fisher.a = fisher.a, fisher.kf = fisher.kf, fisher.n = fisher.n,\n",
    "                 decode = gl)\n",
    "    class(model) <- 'discriminant'\n",
    "    return(model)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 336,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$fisher.predict</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "</ol>\n",
       "</dd>\n",
       "\t<dt>$bayes.predict</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "</ol>\n",
       "</dd>\n",
       "\t<dt>$distance.predict</dt>\n",
       "\t\t<dd><ol class=list-inline>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>1</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>2</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "\t<li>3</li>\n",
       "</ol>\n",
       "</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$fisher.predict] \\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$bayes.predict] \\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\item[\\$distance.predict] \\begin{enumerate*}\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 1\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 2\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\item 3\n",
       "\\end{enumerate*}\n",
       "\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$fisher.predict\n",
       ":   1. 1\n",
       "2. 1\n",
       "3. 1\n",
       "4. 1\n",
       "5. 1\n",
       "6. 1\n",
       "7. 1\n",
       "8. 1\n",
       "9. 1\n",
       "10. 1\n",
       "11. 1\n",
       "12. 1\n",
       "13. 1\n",
       "14. 1\n",
       "15. 1\n",
       "16. 1\n",
       "17. 1\n",
       "18. 1\n",
       "19. 1\n",
       "20. 1\n",
       "21. 1\n",
       "22. 1\n",
       "23. 1\n",
       "24. 1\n",
       "25. 1\n",
       "26. 1\n",
       "27. 1\n",
       "28. 1\n",
       "29. 1\n",
       "30. 1\n",
       "31. 1\n",
       "32. 1\n",
       "33. 1\n",
       "34. 1\n",
       "35. 1\n",
       "36. 1\n",
       "37. 1\n",
       "38. 1\n",
       "39. 1\n",
       "40. 1\n",
       "41. 1\n",
       "42. 1\n",
       "43. 1\n",
       "44. 1\n",
       "45. 1\n",
       "46. 1\n",
       "47. 1\n",
       "48. 1\n",
       "49. 1\n",
       "50. 1\n",
       "51. 2\n",
       "52. 2\n",
       "53. 2\n",
       "54. 2\n",
       "55. 2\n",
       "56. 2\n",
       "57. 2\n",
       "58. 2\n",
       "59. 2\n",
       "60. 2\n",
       "61. 2\n",
       "62. 2\n",
       "63. 2\n",
       "64. 2\n",
       "65. 2\n",
       "66. 2\n",
       "67. 2\n",
       "68. 2\n",
       "69. 2\n",
       "70. 2\n",
       "71. 2\n",
       "72. 2\n",
       "73. 3\n",
       "74. 2\n",
       "75. 2\n",
       "76. 2\n",
       "77. 2\n",
       "78. 2\n",
       "79. 2\n",
       "80. 2\n",
       "81. 2\n",
       "82. 2\n",
       "83. 2\n",
       "84. 3\n",
       "85. 2\n",
       "86. 2\n",
       "87. 2\n",
       "88. 2\n",
       "89. 2\n",
       "90. 2\n",
       "91. 2\n",
       "92. 2\n",
       "93. 2\n",
       "94. 2\n",
       "95. 2\n",
       "96. 2\n",
       "97. 2\n",
       "98. 2\n",
       "99. 2\n",
       "100. 2\n",
       "101. 3\n",
       "102. 3\n",
       "103. 3\n",
       "104. 3\n",
       "105. 3\n",
       "106. 3\n",
       "107. 3\n",
       "108. 3\n",
       "109. 3\n",
       "110. 3\n",
       "111. 3\n",
       "112. 3\n",
       "113. 3\n",
       "114. 3\n",
       "115. 3\n",
       "116. 3\n",
       "117. 3\n",
       "118. 3\n",
       "119. 3\n",
       "120. 3\n",
       "121. 3\n",
       "122. 3\n",
       "123. 3\n",
       "124. 3\n",
       "125. 3\n",
       "126. 3\n",
       "127. 3\n",
       "128. 3\n",
       "129. 3\n",
       "130. 3\n",
       "131. 3\n",
       "132. 3\n",
       "133. 3\n",
       "134. 3\n",
       "135. 3\n",
       "136. 3\n",
       "137. 3\n",
       "138. 3\n",
       "139. 3\n",
       "140. 3\n",
       "141. 3\n",
       "142. 3\n",
       "143. 3\n",
       "144. 3\n",
       "145. 3\n",
       "146. 3\n",
       "147. 3\n",
       "148. 3\n",
       "149. 3\n",
       "150. 3\n",
       "\n",
       "\n",
       "\n",
       "$bayes.predict\n",
       ":   1. 1\n",
       "2. 1\n",
       "3. 1\n",
       "4. 1\n",
       "5. 1\n",
       "6. 1\n",
       "7. 1\n",
       "8. 1\n",
       "9. 1\n",
       "10. 1\n",
       "11. 1\n",
       "12. 1\n",
       "13. 1\n",
       "14. 1\n",
       "15. 1\n",
       "16. 1\n",
       "17. 1\n",
       "18. 1\n",
       "19. 1\n",
       "20. 1\n",
       "21. 1\n",
       "22. 1\n",
       "23. 1\n",
       "24. 1\n",
       "25. 1\n",
       "26. 1\n",
       "27. 1\n",
       "28. 1\n",
       "29. 1\n",
       "30. 1\n",
       "31. 1\n",
       "32. 1\n",
       "33. 1\n",
       "34. 1\n",
       "35. 1\n",
       "36. 1\n",
       "37. 1\n",
       "38. 1\n",
       "39. 1\n",
       "40. 1\n",
       "41. 1\n",
       "42. 1\n",
       "43. 1\n",
       "44. 1\n",
       "45. 1\n",
       "46. 1\n",
       "47. 1\n",
       "48. 1\n",
       "49. 1\n",
       "50. 1\n",
       "51. 2\n",
       "52. 2\n",
       "53. 2\n",
       "54. 2\n",
       "55. 2\n",
       "56. 2\n",
       "57. 2\n",
       "58. 2\n",
       "59. 2\n",
       "60. 2\n",
       "61. 2\n",
       "62. 2\n",
       "63. 2\n",
       "64. 2\n",
       "65. 2\n",
       "66. 2\n",
       "67. 2\n",
       "68. 2\n",
       "69. 2\n",
       "70. 2\n",
       "71. 3\n",
       "72. 2\n",
       "73. 2\n",
       "74. 2\n",
       "75. 2\n",
       "76. 2\n",
       "77. 2\n",
       "78. 2\n",
       "79. 2\n",
       "80. 2\n",
       "81. 2\n",
       "82. 2\n",
       "83. 2\n",
       "84. 3\n",
       "85. 2\n",
       "86. 2\n",
       "87. 2\n",
       "88. 2\n",
       "89. 2\n",
       "90. 2\n",
       "91. 2\n",
       "92. 2\n",
       "93. 2\n",
       "94. 2\n",
       "95. 2\n",
       "96. 2\n",
       "97. 2\n",
       "98. 2\n",
       "99. 2\n",
       "100. 2\n",
       "101. 3\n",
       "102. 3\n",
       "103. 3\n",
       "104. 3\n",
       "105. 3\n",
       "106. 3\n",
       "107. 3\n",
       "108. 3\n",
       "109. 3\n",
       "110. 3\n",
       "111. 3\n",
       "112. 3\n",
       "113. 3\n",
       "114. 3\n",
       "115. 3\n",
       "116. 3\n",
       "117. 3\n",
       "118. 3\n",
       "119. 3\n",
       "120. 3\n",
       "121. 3\n",
       "122. 3\n",
       "123. 3\n",
       "124. 3\n",
       "125. 3\n",
       "126. 3\n",
       "127. 3\n",
       "128. 3\n",
       "129. 3\n",
       "130. 3\n",
       "131. 3\n",
       "132. 3\n",
       "133. 3\n",
       "134. 3\n",
       "135. 3\n",
       "136. 3\n",
       "137. 3\n",
       "138. 3\n",
       "139. 3\n",
       "140. 3\n",
       "141. 3\n",
       "142. 3\n",
       "143. 3\n",
       "144. 3\n",
       "145. 3\n",
       "146. 3\n",
       "147. 3\n",
       "148. 3\n",
       "149. 3\n",
       "150. 3\n",
       "\n",
       "\n",
       "\n",
       "$distance.predict\n",
       ":   1. 1\n",
       "2. 1\n",
       "3. 1\n",
       "4. 1\n",
       "5. 1\n",
       "6. 1\n",
       "7. 1\n",
       "8. 1\n",
       "9. 1\n",
       "10. 1\n",
       "11. 1\n",
       "12. 1\n",
       "13. 1\n",
       "14. 1\n",
       "15. 1\n",
       "16. 1\n",
       "17. 1\n",
       "18. 1\n",
       "19. 1\n",
       "20. 1\n",
       "21. 1\n",
       "22. 1\n",
       "23. 1\n",
       "24. 1\n",
       "25. 1\n",
       "26. 1\n",
       "27. 1\n",
       "28. 1\n",
       "29. 1\n",
       "30. 1\n",
       "31. 1\n",
       "32. 1\n",
       "33. 1\n",
       "34. 1\n",
       "35. 1\n",
       "36. 1\n",
       "37. 1\n",
       "38. 1\n",
       "39. 1\n",
       "40. 1\n",
       "41. 1\n",
       "42. 1\n",
       "43. 1\n",
       "44. 1\n",
       "45. 1\n",
       "46. 1\n",
       "47. 1\n",
       "48. 1\n",
       "49. 1\n",
       "50. 1\n",
       "51. 2\n",
       "52. 2\n",
       "53. 2\n",
       "54. 2\n",
       "55. 2\n",
       "56. 2\n",
       "57. 2\n",
       "58. 2\n",
       "59. 2\n",
       "60. 2\n",
       "61. 2\n",
       "62. 2\n",
       "63. 2\n",
       "64. 2\n",
       "65. 2\n",
       "66. 2\n",
       "67. 2\n",
       "68. 2\n",
       "69. 2\n",
       "70. 2\n",
       "71. 3\n",
       "72. 2\n",
       "73. 3\n",
       "74. 2\n",
       "75. 2\n",
       "76. 2\n",
       "77. 2\n",
       "78. 2\n",
       "79. 2\n",
       "80. 2\n",
       "81. 2\n",
       "82. 2\n",
       "83. 2\n",
       "84. 3\n",
       "85. 2\n",
       "86. 2\n",
       "87. 2\n",
       "88. 2\n",
       "89. 2\n",
       "90. 2\n",
       "91. 2\n",
       "92. 2\n",
       "93. 2\n",
       "94. 2\n",
       "95. 2\n",
       "96. 2\n",
       "97. 2\n",
       "98. 2\n",
       "99. 2\n",
       "100. 2\n",
       "101. 3\n",
       "102. 3\n",
       "103. 3\n",
       "104. 3\n",
       "105. 3\n",
       "106. 3\n",
       "107. 3\n",
       "108. 3\n",
       "109. 3\n",
       "110. 3\n",
       "111. 3\n",
       "112. 3\n",
       "113. 3\n",
       "114. 3\n",
       "115. 3\n",
       "116. 3\n",
       "117. 3\n",
       "118. 3\n",
       "119. 3\n",
       "120. 3\n",
       "121. 3\n",
       "122. 3\n",
       "123. 3\n",
       "124. 3\n",
       "125. 3\n",
       "126. 3\n",
       "127. 3\n",
       "128. 3\n",
       "129. 3\n",
       "130. 3\n",
       "131. 3\n",
       "132. 3\n",
       "133. 3\n",
       "134. 3\n",
       "135. 3\n",
       "136. 3\n",
       "137. 3\n",
       "138. 3\n",
       "139. 3\n",
       "140. 3\n",
       "141. 3\n",
       "142. 3\n",
       "143. 3\n",
       "144. 3\n",
       "145. 3\n",
       "146. 3\n",
       "147. 3\n",
       "148. 3\n",
       "149. 3\n",
       "150. 3\n",
       "\n",
       "\n",
       "\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$fisher.predict\n",
       "  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2\n",
       " [75] 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3\n",
       "[112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
       "[149] 3 3\n",
       "\n",
       "$bayes.predict\n",
       "  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 2 2\n",
       " [75] 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3\n",
       "[112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
       "[149] 3 3\n",
       "\n",
       "$distance.predict\n",
       "  [1] 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1\n",
       " [38] 1 1 1 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 2 3 2\n",
       " [75] 2 2 2 2 2 2 2 2 2 3 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 3\n",
       "[112] 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3 3\n",
       "[149] 3 3\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model <- discriminant(iris, c('Sepal.Length','Sepal.Width','Petal.Length','Petal.Width' ), 'Species')\n",
    "\n",
    "predict(model, iris, c('Sepal.Length','Sepal.Width','Petal.Length','Petal.Width' ),decode=F)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$fisher.predict</dt>\n",
       "\t\t<dd>0.986666666666667</dd>\n",
       "\t<dt>$bayes.predict</dt>\n",
       "\t\t<dd>0.986666666666667</dd>\n",
       "\t<dt>$distance.predict</dt>\n",
       "\t\t<dd>0.98</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$fisher.predict] 0.986666666666667\n",
       "\\item[\\$bayes.predict] 0.986666666666667\n",
       "\\item[\\$distance.predict] 0.98\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$fisher.predict\n",
       ":   0.986666666666667\n",
       "$bayes.predict\n",
       ":   0.986666666666667\n",
       "$distance.predict\n",
       ":   0.98\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$fisher.predict\n",
       "[1] 0.9866667\n",
       "\n",
       "$bayes.predict\n",
       "[1] 0.9866667\n",
       "\n",
       "$distance.predict\n",
       "[1] 0.98\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lapply(predict(model, iris, c('Sepal.Length','Sepal.Width','Petal.Length','Petal.Width' )),function(pred){\n",
    "    mean(pred == iris$Species)\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 343,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$fisher.predict</dt>\n",
       "\t\t<dd>0.98</dd>\n",
       "\t<dt>$bayes.predict</dt>\n",
       "\t\t<dd>0.986666666666667</dd>\n",
       "\t<dt>$distance.predict</dt>\n",
       "\t\t<dd>0.98</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$fisher.predict] 0.98\n",
       "\\item[\\$bayes.predict] 0.986666666666667\n",
       "\\item[\\$distance.predict] 0.98\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$fisher.predict\n",
       ":   0.98\n",
       "$bayes.predict\n",
       ":   0.986666666666667\n",
       "$distance.predict\n",
       ":   0.98\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$fisher.predict\n",
       "[1] 0.98\n",
       "\n",
       "$bayes.predict\n",
       "[1] 0.9866667\n",
       "\n",
       "$distance.predict\n",
       "[1] 0.98\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model <- discriminant(iris, c('Sepal.Length','Sepal.Width','Petal.Length','Petal.Width' ), 'Species',fisher.n=2)\n",
    "\n",
    "lapply(predict(model, iris, c('Sepal.Length','Sepal.Width','Petal.Length','Petal.Width' )),function(pred){\n",
    "    mean(pred == iris$Species)\n",
    "})\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "有趣的一点是Fisher判别法只使用一个判别函数比使用两个还能多正确一个。在优化目标并不是直接为划分正确率的情况下也说明了反过拟合的必要性。\n",
    "\n",
    "我们再分别利用这三者对总体的假设直接构造对应的样本，看看另外两个此时判别能力如何。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 349,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "k1 <- rmultinorm(100,c(1,-1,1,-1,1),rcov(5,5))\n",
    "k2 <-  rmultinorm(100,c(-1,-1,-1,-1,-1),rcov(5,5))\n",
    "k3 <-  rmultinorm(100,c(3,-1,-1,-2,2),rcov(5,5))\n",
    "\n",
    "k <- cbind(k1,k2,k3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df <- data.frame(t(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 354,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df$group <- c(rep(1,100),rep(2,100),rep(3,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 356,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X1</th><th scope=col>X2</th><th scope=col>X3</th><th scope=col>X4</th><th scope=col>X5</th><th scope=col>group</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-2.8916029</td><td>-2.902262 </td><td> 0.6323476</td><td> 1.3995561</td><td>-3.5396638</td><td>1         </td></tr>\n",
       "\t<tr><td>-0.3224974</td><td>-0.081010 </td><td>-1.3497843</td><td> 1.4782905</td><td>-3.0862487</td><td>1         </td></tr>\n",
       "\t<tr><td> 0.5394312</td><td> 2.095832 </td><td>-2.1313710</td><td> 1.8509769</td><td> 0.4862144</td><td>1         </td></tr>\n",
       "\t<tr><td>-0.1561339</td><td>-1.654859 </td><td> 2.0273449</td><td> 0.4444467</td><td> 3.7377704</td><td>1         </td></tr>\n",
       "\t<tr><td>-1.2512918</td><td>-5.378832 </td><td> 2.9046856</td><td>-3.7755733</td><td>-0.2343796</td><td>1         </td></tr>\n",
       "\t<tr><td>-2.2298556</td><td>-4.325569 </td><td> 4.8545390</td><td>-0.2694173</td><td>-3.6357512</td><td>1         </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " X1 & X2 & X3 & X4 & X5 & group\\\\\n",
       "\\hline\n",
       "\t -2.8916029 & -2.902262  &  0.6323476 &  1.3995561 & -3.5396638 & 1         \\\\\n",
       "\t -0.3224974 & -0.081010  & -1.3497843 &  1.4782905 & -3.0862487 & 1         \\\\\n",
       "\t  0.5394312 &  2.095832  & -2.1313710 &  1.8509769 &  0.4862144 & 1         \\\\\n",
       "\t -0.1561339 & -1.654859  &  2.0273449 &  0.4444467 &  3.7377704 & 1         \\\\\n",
       "\t -1.2512918 & -5.378832  &  2.9046856 & -3.7755733 & -0.2343796 & 1         \\\\\n",
       "\t -2.2298556 & -4.325569  &  4.8545390 & -0.2694173 & -3.6357512 & 1         \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  X1         X2        X3         X4         X5         group\n",
       "1 -2.8916029 -2.902262  0.6323476  1.3995561 -3.5396638 1    \n",
       "2 -0.3224974 -0.081010 -1.3497843  1.4782905 -3.0862487 1    \n",
       "3  0.5394312  2.095832 -2.1313710  1.8509769  0.4862144 1    \n",
       "4 -0.1561339 -1.654859  2.0273449  0.4444467  3.7377704 1    \n",
       "5 -1.2512918 -5.378832  2.9046856 -3.7755733 -0.2343796 1    \n",
       "6 -2.2298556 -4.325569  4.8545390 -0.2694173 -3.6357512 1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 362,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "perm <- sample(1:300)\n",
    "train <- perm[1:250]\n",
    "test <- perm[251:300]\n",
    "\n",
    "model <- discriminant(df[train,], c('X1','X2','X3','X4','X5' ), 'group')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 368,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$fisher.predict</dt>\n",
       "\t\t<dd>0.712</dd>\n",
       "\t<dt>$bayes.predict</dt>\n",
       "\t\t<dd>0.924</dd>\n",
       "\t<dt>$distance.predict</dt>\n",
       "\t\t<dd>0.924</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$fisher.predict] 0.712\n",
       "\\item[\\$bayes.predict] 0.924\n",
       "\\item[\\$distance.predict] 0.924\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$fisher.predict\n",
       ":   0.712\n",
       "$bayes.predict\n",
       ":   0.924\n",
       "$distance.predict\n",
       ":   0.924\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$fisher.predict\n",
       "[1] 0.712\n",
       "\n",
       "$bayes.predict\n",
       "[1] 0.924\n",
       "\n",
       "$distance.predict\n",
       "[1] 0.924\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lapply(predict(model, df[train,], c('X1','X2','X3','X4','X5' )),function(pred){\n",
    "  mean(pred == df[train,]$group )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 369,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$fisher.predict</dt>\n",
       "\t\t<dd>0.7</dd>\n",
       "\t<dt>$bayes.predict</dt>\n",
       "\t\t<dd>0.98</dd>\n",
       "\t<dt>$distance.predict</dt>\n",
       "\t\t<dd>0.98</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$fisher.predict] 0.7\n",
       "\\item[\\$bayes.predict] 0.98\n",
       "\\item[\\$distance.predict] 0.98\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$fisher.predict\n",
       ":   0.7\n",
       "$bayes.predict\n",
       ":   0.98\n",
       "$distance.predict\n",
       ":   0.98\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$fisher.predict\n",
       "[1] 0.7\n",
       "\n",
       "$bayes.predict\n",
       "[1] 0.98\n",
       "\n",
       "$distance.predict\n",
       "[1] 0.98\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lapply(predict(model, df[test,], c('X1','X2','X3','X4','X5' )),function(pred){\n",
    "  mean(pred == df[test,]$group )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "k1 <- matrix(rexp(500,1),5)\n",
    "k2 <- matrix(rexp(500,2),5)\n",
    "k3 <- matrix(rexp(500,3),5)\n",
    "\n",
    "A <- matrix(runif(25),5)\n",
    "k <- A %*% cbind(k1,k2,k3)\n",
    "\n",
    "df <- data.frame(t(k))\n",
    "df$group <- c(rep(1,100),rep(2,100),rep(3,100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 386,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<tbody>\n",
       "\t<tr><td>2.112143 </td><td>1.1036980</td><td>1.923615 </td><td>1.6471977</td><td>2.166963 </td></tr>\n",
       "\t<tr><td>1.103698 </td><td>0.7773182</td><td>1.047516 </td><td>0.9140029</td><td>1.245098 </td></tr>\n",
       "\t<tr><td>1.923615 </td><td>1.0475156</td><td>1.859194 </td><td>1.6070872</td><td>1.996341 </td></tr>\n",
       "\t<tr><td>1.647198 </td><td>0.9140029</td><td>1.607087 </td><td>1.6574597</td><td>1.911987 </td></tr>\n",
       "\t<tr><td>2.166963 </td><td>1.2450983</td><td>1.996341 </td><td>1.9119874</td><td>2.485298 </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{lllll}\n",
       "\t 2.112143  & 1.1036980 & 1.923615  & 1.6471977 & 2.166963 \\\\\n",
       "\t 1.103698  & 0.7773182 & 1.047516  & 0.9140029 & 1.245098 \\\\\n",
       "\t 1.923615  & 1.0475156 & 1.859194  & 1.6070872 & 1.996341 \\\\\n",
       "\t 1.647198  & 0.9140029 & 1.607087  & 1.6574597 & 1.911987 \\\\\n",
       "\t 2.166963  & 1.2450983 & 1.996341  & 1.9119874 & 2.485298 \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/markdown": [
       "1. 2.11214344970941\n",
       "2. 1.10369800615173\n",
       "3. 1.92361546608992\n",
       "4. 1.64719772872314\n",
       "5. 2.16696323860173\n",
       "6. 1.10369800615173\n",
       "7. 0.77731819012135\n",
       "8. 1.04751557074973\n",
       "9. 0.914002871354362\n",
       "10. 1.24509829901744\n",
       "11. 1.92361546608992\n",
       "12. 1.04751557074973\n",
       "13. 1.8591935441949\n",
       "14. 1.60708719795754\n",
       "15. 1.9963406786779\n",
       "16. 1.64719772872314\n",
       "17. 0.914002871354362\n",
       "18. 1.60708719795754\n",
       "19. 1.6574597230818\n",
       "20. 1.91198740448395\n",
       "21. 2.16696323860173\n",
       "22. 1.24509829901744\n",
       "23. 1.9963406786779\n",
       "24. 1.91198740448395\n",
       "25. 2.48529760378002\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "     [,1]     [,2]      [,3]     [,4]      [,5]    \n",
       "[1,] 2.112143 1.1036980 1.923615 1.6471977 2.166963\n",
       "[2,] 1.103698 0.7773182 1.047516 0.9140029 1.245098\n",
       "[3,] 1.923615 1.0475156 1.859194 1.6070872 1.996341\n",
       "[4,] 1.647198 0.9140029 1.607087 1.6574597 1.911987\n",
       "[5,] 2.166963 1.2450983 1.996341 1.9119874 2.485298"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "cov(t(k))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X1</th><th scope=col>X2</th><th scope=col>X3</th><th scope=col>X4</th><th scope=col>X5</th><th scope=col>group</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>2.640433 </td><td>1.4719307</td><td>2.7465423</td><td>2.7520528</td><td>3.100895 </td><td>1        </td></tr>\n",
       "\t<tr><td>1.015351 </td><td>0.6716775</td><td>0.8916166</td><td>0.9632102</td><td>1.322703 </td><td>1        </td></tr>\n",
       "\t<tr><td>4.878303 </td><td>1.9083695</td><td>4.2809817</td><td>3.9256200</td><td>4.518885 </td><td>1        </td></tr>\n",
       "\t<tr><td>2.087606 </td><td>0.4932775</td><td>1.6301839</td><td>1.3350924</td><td>1.844029 </td><td>1        </td></tr>\n",
       "\t<tr><td>1.165760 </td><td>1.2351997</td><td>1.4797145</td><td>2.2282558</td><td>2.257422 </td><td>1        </td></tr>\n",
       "\t<tr><td>4.270935 </td><td>2.1546303</td><td>3.6395632</td><td>2.5806415</td><td>4.094943 </td><td>1        </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " X1 & X2 & X3 & X4 & X5 & group\\\\\n",
       "\\hline\n",
       "\t 2.640433  & 1.4719307 & 2.7465423 & 2.7520528 & 3.100895  & 1        \\\\\n",
       "\t 1.015351  & 0.6716775 & 0.8916166 & 0.9632102 & 1.322703  & 1        \\\\\n",
       "\t 4.878303  & 1.9083695 & 4.2809817 & 3.9256200 & 4.518885  & 1        \\\\\n",
       "\t 2.087606  & 0.4932775 & 1.6301839 & 1.3350924 & 1.844029  & 1        \\\\\n",
       "\t 1.165760  & 1.2351997 & 1.4797145 & 2.2282558 & 2.257422  & 1        \\\\\n",
       "\t 4.270935  & 2.1546303 & 3.6395632 & 2.5806415 & 4.094943  & 1        \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  X1       X2        X3        X4        X5       group\n",
       "1 2.640433 1.4719307 2.7465423 2.7520528 3.100895 1    \n",
       "2 1.015351 0.6716775 0.8916166 0.9632102 1.322703 1    \n",
       "3 4.878303 1.9083695 4.2809817 3.9256200 4.518885 1    \n",
       "4 2.087606 0.4932775 1.6301839 1.3350924 1.844029 1    \n",
       "5 1.165760 1.2351997 1.4797145 2.2282558 2.257422 1    \n",
       "6 4.270935 2.1546303 3.6395632 2.5806415 4.094943 1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "head(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 388,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$fisher.predict</dt>\n",
       "\t\t<dd>0.648</dd>\n",
       "\t<dt>$bayes.predict</dt>\n",
       "\t\t<dd>0.608</dd>\n",
       "\t<dt>$distance.predict</dt>\n",
       "\t\t<dd>0.528</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$fisher.predict] 0.648\n",
       "\\item[\\$bayes.predict] 0.608\n",
       "\\item[\\$distance.predict] 0.528\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$fisher.predict\n",
       ":   0.648\n",
       "$bayes.predict\n",
       ":   0.608\n",
       "$distance.predict\n",
       ":   0.528\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$fisher.predict\n",
       "[1] 0.648\n",
       "\n",
       "$bayes.predict\n",
       "[1] 0.608\n",
       "\n",
       "$distance.predict\n",
       "[1] 0.528\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model <- discriminant(df[train,], c('X1','X2','X3','X4','X5' ), 'group')\n",
    "\n",
    "lapply(predict(model, df[train,], c('X1','X2','X3','X4','X5' )),function(pred){\n",
    "  mean(pred == df[train,]$group )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 389,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$fisher.predict</dt>\n",
       "\t\t<dd>0.54</dd>\n",
       "\t<dt>$bayes.predict</dt>\n",
       "\t\t<dd>0.52</dd>\n",
       "\t<dt>$distance.predict</dt>\n",
       "\t\t<dd>0.5</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$fisher.predict] 0.54\n",
       "\\item[\\$bayes.predict] 0.52\n",
       "\\item[\\$distance.predict] 0.5\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$fisher.predict\n",
       ":   0.54\n",
       "$bayes.predict\n",
       ":   0.52\n",
       "$distance.predict\n",
       ":   0.5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$fisher.predict\n",
       "[1] 0.54\n",
       "\n",
       "$bayes.predict\n",
       "[1] 0.52\n",
       "\n",
       "$distance.predict\n",
       "[1] 0.5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lapply(predict(model, df[test,], c('X1','X2','X3','X4','X5' )),function(pred){\n",
    "  mean(pred == df[test,]$group )\n",
    "})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "很好，一旦偏离正态假设，就全都不靠谱了。不过姑且看一下Fisher判别法投影出的二维图像"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model <- discriminant(df[train,], c('X1','X2','X3','X4','X5' ), 'group',fisher.n = 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 400,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X1</th><th scope=col>X2</th><th scope=col>group</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-2.3207343   </td><td> 0.0654012899</td><td>1            </td></tr>\n",
       "\t<tr><td>-0.9673992   </td><td> 0.0107871219</td><td>1            </td></tr>\n",
       "\t<tr><td>-3.5782781   </td><td>-0.1867106147</td><td>1            </td></tr>\n",
       "\t<tr><td>-1.2258968   </td><td>-0.0007397261</td><td>1            </td></tr>\n",
       "\t<tr><td>-1.6945303   </td><td> 0.0284690919</td><td>1            </td></tr>\n",
       "\t<tr><td>-3.1625740   </td><td> 0.0541920123</td><td>1            </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " X1 & X2 & group\\\\\n",
       "\\hline\n",
       "\t -2.3207343    &  0.0654012899 & 1            \\\\\n",
       "\t -0.9673992    &  0.0107871219 & 1            \\\\\n",
       "\t -3.5782781    & -0.1867106147 & 1            \\\\\n",
       "\t -1.2258968    & -0.0007397261 & 1            \\\\\n",
       "\t -1.6945303    &  0.0284690919 & 1            \\\\\n",
       "\t -3.1625740    &  0.0541920123 & 1            \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  X1         X2            group\n",
       "1 -2.3207343  0.0654012899 1    \n",
       "2 -0.9673992  0.0107871219 1    \n",
       "3 -3.5782781 -0.1867106147 1    \n",
       "4 -1.2258968 -0.0007397261 1    \n",
       "5 -1.6945303  0.0284690919 1    \n",
       "6 -3.1625740  0.0541920123 1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df2 <- data.frame(t(model$fisher.a %*% k))\n",
    "df2$group <- df$group\n",
    "head(df2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Warning message:\n",
      "\"package 'ggplot2' was built under R version 3.3.2\""
     ]
    }
   ],
   "source": [
    "library(ggplot2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAB11BMVEUAAAATK0MTLEQULUUU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",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(df,aes(X1,X2,colour = group)) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "看得出貌似是大期望那些吸引了大量方差导致的，是否先做标准化可能可以缓解这个问题？"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X1</th><th scope=col>X2</th><th scope=col>X3</th><th scope=col>X4</th><th scope=col>X5</th><th scope=col>group</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td> 0.5181231 </td><td> 0.3967307 </td><td> 0.7151251 </td><td> 0.8166790 </td><td> 0.60999331</td><td>1          </td></tr>\n",
       "\t<tr><td>-0.6000617 </td><td>-0.5109394 </td><td>-0.6452674 </td><td>-0.5727956 </td><td>-0.51795506</td><td>1          </td></tr>\n",
       "\t<tr><td> 2.0579550 </td><td> 0.8917521 </td><td> 1.8404747 </td><td> 1.7282416 </td><td> 1.50945827</td><td>1          </td></tr>\n",
       "\t<tr><td> 0.1377351 </td><td>-0.7132857 </td><td>-0.1036061 </td><td>-0.2839380 </td><td>-0.18726608</td><td>1          </td></tr>\n",
       "\t<tr><td>-0.4965682 </td><td> 0.1282236 </td><td>-0.2139595 </td><td> 0.4098223 </td><td> 0.07495881</td><td>1          </td></tr>\n",
       "\t<tr><td> 1.6400375 </td><td> 1.1710681 </td><td> 1.3700618 </td><td> 0.6835361 </td><td> 1.24054153</td><td>1          </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllll}\n",
       " X1 & X2 & X3 & X4 & X5 & group\\\\\n",
       "\\hline\n",
       "\t  0.5181231  &  0.3967307  &  0.7151251  &  0.8166790  &  0.60999331 & 1          \\\\\n",
       "\t -0.6000617  & -0.5109394  & -0.6452674  & -0.5727956  & -0.51795506 & 1          \\\\\n",
       "\t  2.0579550  &  0.8917521  &  1.8404747  &  1.7282416  &  1.50945827 & 1          \\\\\n",
       "\t  0.1377351  & -0.7132857  & -0.1036061  & -0.2839380  & -0.18726608 & 1          \\\\\n",
       "\t -0.4965682  &  0.1282236  & -0.2139595  &  0.4098223  &  0.07495881 & 1          \\\\\n",
       "\t  1.6400375  &  1.1710681  &  1.3700618  &  0.6835361  &  1.24054153 & 1          \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  X1         X2         X3         X4         X5          group\n",
       "1  0.5181231  0.3967307  0.7151251  0.8166790  0.60999331 1    \n",
       "2 -0.6000617 -0.5109394 -0.6452674 -0.5727956 -0.51795506 1    \n",
       "3  2.0579550  0.8917521  1.8404747  1.7282416  1.50945827 1    \n",
       "4  0.1377351 -0.7132857 -0.1036061 -0.2839380 -0.18726608 1    \n",
       "5 -0.4965682  0.1282236 -0.2139595  0.4098223  0.07495881 1    \n",
       "6  1.6400375  1.1710681  1.3700618  0.6835361  1.24054153 1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df3 <- data.frame(scale(df[,-ncol(df)]))\n",
    "df3$group <- df$group\n",
    "head(df3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$X1</dt>\n",
       "\t\t<dd>1.09461051334137e-17</dd>\n",
       "\t<dt>$X2</dt>\n",
       "\t\t<dd>8.65733627726054e-17</dd>\n",
       "\t<dt>$X3</dt>\n",
       "\t\t<dd>7.34283149330291e-17</dd>\n",
       "\t<dt>$X4</dt>\n",
       "\t\t<dd>-6.46509755453106e-17</dd>\n",
       "\t<dt>$X5</dt>\n",
       "\t\t<dd>1.15475843586362e-16</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$X1] 1.09461051334137e-17\n",
       "\\item[\\$X2] 8.65733627726054e-17\n",
       "\\item[\\$X3] 7.34283149330291e-17\n",
       "\\item[\\$X4] -6.46509755453106e-17\n",
       "\\item[\\$X5] 1.15475843586362e-16\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$X1\n",
       ":   1.09461051334137e-17\n",
       "$X2\n",
       ":   8.65733627726054e-17\n",
       "$X3\n",
       ":   7.34283149330291e-17\n",
       "$X4\n",
       ":   -6.46509755453106e-17\n",
       "$X5\n",
       ":   1.15475843586362e-16\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$X1\n",
       "[1] 1.094611e-17\n",
       "\n",
       "$X2\n",
       "[1] 8.657336e-17\n",
       "\n",
       "$X3\n",
       "[1] 7.342831e-17\n",
       "\n",
       "$X4\n",
       "[1] -6.465098e-17\n",
       "\n",
       "$X5\n",
       "[1] 1.154758e-16\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lapply(df3,mean)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 416,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$X1</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$X2</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$X3</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$X4</dt>\n",
       "\t\t<dd>1</dd>\n",
       "\t<dt>$X5</dt>\n",
       "\t\t<dd>1</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$X1] 1\n",
       "\\item[\\$X2] 1\n",
       "\\item[\\$X3] 1\n",
       "\\item[\\$X4] 1\n",
       "\\item[\\$X5] 1\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$X1\n",
       ":   1\n",
       "$X2\n",
       ":   1\n",
       "$X3\n",
       ":   1\n",
       "$X4\n",
       ":   1\n",
       "$X5\n",
       ":   1\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$X1\n",
       "[1] 1\n",
       "\n",
       "$X2\n",
       "[1] 1\n",
       "\n",
       "$X3\n",
       "[1] 1\n",
       "\n",
       "$X4\n",
       "[1] 1\n",
       "\n",
       "$X5\n",
       "[1] 1\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lapply(df3,sd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 421,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$fisher.predict</dt>\n",
       "\t\t<dd>0.648</dd>\n",
       "\t<dt>$bayes.predict</dt>\n",
       "\t\t<dd>0.608</dd>\n",
       "\t<dt>$distance.predict</dt>\n",
       "\t\t<dd>0.528</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$fisher.predict] 0.648\n",
       "\\item[\\$bayes.predict] 0.608\n",
       "\\item[\\$distance.predict] 0.528\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$fisher.predict\n",
       ":   0.648\n",
       "$bayes.predict\n",
       ":   0.608\n",
       "$distance.predict\n",
       ":   0.528\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$fisher.predict\n",
       "[1] 0.648\n",
       "\n",
       "$bayes.predict\n",
       "[1] 0.608\n",
       "\n",
       "$distance.predict\n",
       "[1] 0.528\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model <- discriminant(df3[train,], c('X1','X2','X3','X4','X5' ), 'group',fisher.n = 2)\n",
    "\n",
    "lapply(predict(model, df3[train,], c('X1','X2','X3','X4','X5' )),function(pred){\n",
    "  mean(pred == df3[train,]$group )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 422,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$fisher.predict</dt>\n",
       "\t\t<dd>0.54</dd>\n",
       "\t<dt>$bayes.predict</dt>\n",
       "\t\t<dd>0.52</dd>\n",
       "\t<dt>$distance.predict</dt>\n",
       "\t\t<dd>0.5</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$fisher.predict] 0.54\n",
       "\\item[\\$bayes.predict] 0.52\n",
       "\\item[\\$distance.predict] 0.5\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$fisher.predict\n",
       ":   0.54\n",
       "$bayes.predict\n",
       ":   0.52\n",
       "$distance.predict\n",
       ":   0.5\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$fisher.predict\n",
       "[1] 0.54\n",
       "\n",
       "$bayes.predict\n",
       "[1] 0.52\n",
       "\n",
       "$distance.predict\n",
       "[1] 0.5\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "lapply(predict(model, df3[test,], c('X1','X2','X3','X4','X5' )),function(pred){\n",
    "  mean(pred == df3[test,]$group )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 423,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>X1</th><th scope=col>X2</th><th scope=col>group</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>-0.57014546 </td><td> 0.049179616</td><td>1           </td></tr>\n",
       "\t<tr><td> 0.60940895 </td><td> 0.010116280</td><td>1           </td></tr>\n",
       "\t<tr><td>-1.66620907 </td><td>-0.131145970</td><td>1           </td></tr>\n",
       "\t<tr><td> 0.38410482 </td><td> 0.001871586</td><td>1           </td></tr>\n",
       "\t<tr><td>-0.02435183 </td><td> 0.022763488</td><td>1           </td></tr>\n",
       "\t<tr><td>-1.30388515 </td><td> 0.041162067</td><td>1           </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lll}\n",
       " X1 & X2 & group\\\\\n",
       "\\hline\n",
       "\t -0.57014546  &  0.049179616 & 1           \\\\\n",
       "\t  0.60940895  &  0.010116280 & 1           \\\\\n",
       "\t -1.66620907  & -0.131145970 & 1           \\\\\n",
       "\t  0.38410482  &  0.001871586 & 1           \\\\\n",
       "\t -0.02435183  &  0.022763488 & 1           \\\\\n",
       "\t -1.30388515  &  0.041162067 & 1           \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "  X1          X2           group\n",
       "1 -0.57014546  0.049179616 1    \n",
       "2  0.60940895  0.010116280 1    \n",
       "3 -1.66620907 -0.131145970 1    \n",
       "4  0.38410482  0.001871586 1    \n",
       "5 -0.02435183  0.022763488 1    \n",
       "6 -1.30388515  0.041162067 1    "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df4 <- data.frame(t(model$fisher.a %*% t(as.matrix(df3[,-ncol(df3)]))))\n",
    "df4$group <- df$group\n",
    "head(df4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 424,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {},
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAA0gAAANICAMAAADKOT/pAAAB11BMVEUAAAATK0MTLEQULUUU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\nVIgiGVMhimRMhSiSMRXy/wFXzzKZa/H50gAAAABJRU5ErkJggg==",
      "text/plain": [
       "plot without title"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "ggplot(df4, aes(X1,X2,colour = group)) + geom_point()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "。。。应该想到这种线性变换其实没什么用，这种相对散布差异是一种更复杂的信息，不是那么好抹掉的。这也反映了这三种方法的贫乏。"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 425,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df <- read.csv(\"disease.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 426,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>class</th><th scope=col>train</th><th scope=col>Zn</th><th scope=col>Cu</th><th scope=col>Fe</th><th scope=col>Ca</th><th scope=col>Mg</th><th scope=col>K</th><th scope=col>Na</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1     </td><td>1     </td><td>166.0 </td><td>15.80 </td><td>24.50 </td><td> 700  </td><td>112.0 </td><td> 179.0</td><td> 513  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>185.0 </td><td>15.70 </td><td>31.50 </td><td> 701  </td><td>125.0 </td><td> 184.0</td><td> 427  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>193.0 </td><td> 9.80 </td><td>25.90 </td><td> 541  </td><td>163.0 </td><td> 128.0</td><td> 642  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>159.0 </td><td>14.20 </td><td>39.70 </td><td> 896  </td><td> 99.2 </td><td> 239.0</td><td> 726  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>226.0 </td><td>16.20 </td><td>23.80 </td><td> 606  </td><td>152.0 </td><td>  70.3</td><td> 218  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>171.0 </td><td> 9.29 </td><td> 9.29 </td><td> 307  </td><td>187.0 </td><td>  45.5</td><td> 257  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>201.0 </td><td>13.30 </td><td>26.60 </td><td> 551  </td><td>101.0 </td><td>  49.4</td><td> 141  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>147.0 </td><td>14.50 </td><td>30.00 </td><td> 659  </td><td>102.0 </td><td> 154.0</td><td> 680  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>172.0 </td><td> 8.85 </td><td> 7.86 </td><td> 551  </td><td> 75.7 </td><td>  98.4</td><td> 318  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>156.0 </td><td>11.50 </td><td>32.50 </td><td> 639  </td><td>107.0 </td><td> 103.0</td><td> 552  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>132.0 </td><td>15.90 </td><td>17.70 </td><td> 578  </td><td> 92.4 </td><td>1314.0</td><td>1372  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>182.0 </td><td>11.30 </td><td>11.30 </td><td> 767  </td><td>111.0 </td><td> 264.0</td><td> 672  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>186.0 </td><td> 9.26 </td><td>37.10 </td><td> 958  </td><td>233.0 </td><td>  73.0</td><td> 347  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>162.0 </td><td> 8.23 </td><td>27.10 </td><td> 625  </td><td>108.0 </td><td>  62.4</td><td> 465  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>150.0 </td><td> 6.63 </td><td>21.00 </td><td> 627  </td><td>140.0 </td><td> 179.0</td><td> 639  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>159.0 </td><td>10.70 </td><td>11.70 </td><td> 612  </td><td>190.0 </td><td>  98.5</td><td> 390  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>117.0 </td><td>16.10 </td><td> 7.04 </td><td> 988  </td><td> 95.5 </td><td> 136.0</td><td> 572  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>181.0 </td><td>10.10 </td><td> 4.04 </td><td>1437  </td><td>184.0 </td><td> 101.0</td><td> 542  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>146.0 </td><td>20.70 </td><td>23.80 </td><td>1232  </td><td>128.0 </td><td> 150.0</td><td>1092  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td> 42.3 </td><td>10.30 </td><td> 9.70 </td><td> 629  </td><td> 93.7 </td><td> 439.0</td><td> 888  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td> 28.2 </td><td>12.40 </td><td>53.10 </td><td> 370  </td><td> 44.1 </td><td> 454.0</td><td> 852  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>154.0 </td><td>13.80 </td><td>53.30 </td><td> 621  </td><td>105.0 </td><td> 160.0</td><td> 723  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>179.0 </td><td>12.20 </td><td>17.90 </td><td>1139  </td><td>150.0 </td><td>  45.2</td><td> 218  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td> 13.5 </td><td> 3.36 </td><td>16.80 </td><td> 135  </td><td> 32.6 </td><td>  51.6</td><td> 182  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>175.0 </td><td> 5.84 </td><td>24.90 </td><td> 807  </td><td>123.0 </td><td>  55.6</td><td> 126  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>113.0 </td><td>15.80 </td><td>47.30 </td><td> 626  </td><td> 53.6 </td><td> 168.0</td><td> 627  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td> 50.5 </td><td>11.60 </td><td> 6.30 </td><td> 608  </td><td> 58.9 </td><td>  58.9</td><td> 139  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td> 78.6 </td><td>14.60 </td><td> 9.70 </td><td> 421  </td><td> 70.8 </td><td> 133.0</td><td> 464  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td> 90.0 </td><td> 3.27 </td><td> 8.17 </td><td> 622  </td><td> 52.3 </td><td> 770.0</td><td> 852  </td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>178.0 </td><td>28.80 </td><td>32.40 </td><td> 992  </td><td>112.0 </td><td>  70.2</td><td> 169  </td></tr>\n",
       "\t<tr><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td><td>...</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td> 58.2 </td><td> 5.42 </td><td>29.70 </td><td> 323  </td><td>138.0 </td><td> 179.0</td><td> 513.0</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>106.0 </td><td> 1.87 </td><td>40.50 </td><td> 542  </td><td>177.0 </td><td> 184.0</td><td> 427.0</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>152.0 </td><td> 0.80 </td><td>12.50 </td><td>1332  </td><td>176.0 </td><td> 128.0</td><td> 646.0</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td> 85.5 </td><td> 1.70 </td><td> 3.99 </td><td> 503  </td><td> 62.3 </td><td> 238.0</td><td> 762.6</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>144.0 </td><td> 0.70 </td><td>15.10 </td><td> 547  </td><td> 79.7 </td><td>  71.0</td><td> 218.5</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td> 85.7 </td><td> 1.09 </td><td> 4.20 </td><td> 790  </td><td>170.0 </td><td>  45.8</td><td> 257.9</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>144.0 </td><td> 0.30 </td><td> 9.11 </td><td> 417  </td><td>552.0 </td><td>  49.5</td><td> 141.5</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>170.0 </td><td> 4.16 </td><td> 9.32 </td><td> 943  </td><td>260.0 </td><td> 155.0</td><td> 680.8</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>176.0 </td><td> 0.57 </td><td>27.30 </td><td> 318  </td><td>133.0 </td><td>  99.4</td><td> 318.8</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>192.0 </td><td> 7.06 </td><td>32.90 </td><td>1969  </td><td>343.0 </td><td> 103.0</td><td> 553.0</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>188.0 </td><td> 8.28 </td><td>22.60 </td><td>1208  </td><td>231.0 </td><td>1314.0</td><td>1372.0</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>153.0 </td><td> 5.87 </td><td>34.80 </td><td> 328  </td><td>163.0 </td><td> 264.0</td><td> 672.5</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>143.0 </td><td> 2.84 </td><td>15.70 </td><td> 265  </td><td>123.0 </td><td>  73.0</td><td> 347.5</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>213.0 </td><td>19.10 </td><td>36.20 </td><td>2220  </td><td>249.0 </td><td>  62.0</td><td> 465.8</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>192.0 </td><td>20.10 </td><td>23.80 </td><td>1606  </td><td>156.0 </td><td>  40.0</td><td> 168.0</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>171.0 </td><td>10.50 </td><td>30.50 </td><td> 672  </td><td>145.0 </td><td>  47.0</td><td> 330.5</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>162.0 </td><td>13.20 </td><td>19.80 </td><td>1521  </td><td>166.0 </td><td>  36.2</td><td> 133.0</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>203.0 </td><td>13.00 </td><td>90.80 </td><td>1544  </td><td>162.0 </td><td>  98.9</td><td> 394.5</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>164.0 </td><td>20.10 </td><td>28.90 </td><td>1062  </td><td>161.0 </td><td>  47.3</td><td> 134.5</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>167.0 </td><td>13.10 </td><td>14.10 </td><td>2278  </td><td>212.0 </td><td>  36.5</td><td>  96.5</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>164.0 </td><td>12.90 </td><td>18.60 </td><td>2993  </td><td>197.0 </td><td>  65.5</td><td> 237.8</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>167.0 </td><td>15.00 </td><td>27.00 </td><td>2056  </td><td>260.0 </td><td>  44.8</td><td>  72.0</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>158.0 </td><td>14.40 </td><td>37.00 </td><td>1025  </td><td>101.0 </td><td> 180.0</td><td> 899.5</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>133.0 </td><td>22.80 </td><td>31.30 </td><td>1633  </td><td>401.0 </td><td> 228.0</td><td> 289.0</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>169.0 </td><td> 8.00 </td><td>30.80 </td><td>1068  </td><td> 99.1 </td><td>  53.0</td><td> 817.0</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>247.0 </td><td>17.30 </td><td> 8.65 </td><td>2554  </td><td>241.0 </td><td>  77.5</td><td> 373.5</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>185.0 </td><td> 3.90 </td><td>31.30 </td><td>1211  </td><td>190.0 </td><td> 134.0</td><td> 649.8</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>209.0 </td><td> 6.43 </td><td>86.90 </td><td>2157  </td><td>288.0 </td><td>  74.0</td><td> 219.8</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>182.0 </td><td> 6.49 </td><td>61.70 </td><td>3870  </td><td>432.0 </td><td> 143.0</td><td> 367.5</td></tr>\n",
       "\t<tr><td>NA    </td><td>2     </td><td>235.0 </td><td>15.60 </td><td>23.40 </td><td>1806  </td><td>166.0 </td><td>  68.9</td><td> 188.0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       " class & train & Zn & Cu & Fe & Ca & Mg & K & Na\\\\\n",
       "\\hline\n",
       "\t 1      & 1      & 166.0  & 15.80  & 24.50  &  700   & 112.0  &  179.0 &  513  \\\\\n",
       "\t 1      & 1      & 185.0  & 15.70  & 31.50  &  701   & 125.0  &  184.0 &  427  \\\\\n",
       "\t 1      & 1      & 193.0  &  9.80  & 25.90  &  541   & 163.0  &  128.0 &  642  \\\\\n",
       "\t 1      & 1      & 159.0  & 14.20  & 39.70  &  896   &  99.2  &  239.0 &  726  \\\\\n",
       "\t 1      & 1      & 226.0  & 16.20  & 23.80  &  606   & 152.0  &   70.3 &  218  \\\\\n",
       "\t 1      & 1      & 171.0  &  9.29  &  9.29  &  307   & 187.0  &   45.5 &  257  \\\\\n",
       "\t 1      & 1      & 201.0  & 13.30  & 26.60  &  551   & 101.0  &   49.4 &  141  \\\\\n",
       "\t 1      & 1      & 147.0  & 14.50  & 30.00  &  659   & 102.0  &  154.0 &  680  \\\\\n",
       "\t 1      & 1      & 172.0  &  8.85  &  7.86  &  551   &  75.7  &   98.4 &  318  \\\\\n",
       "\t 1      & 1      & 156.0  & 11.50  & 32.50  &  639   & 107.0  &  103.0 &  552  \\\\\n",
       "\t 1      & 1      & 132.0  & 15.90  & 17.70  &  578   &  92.4  & 1314.0 & 1372  \\\\\n",
       "\t 1      & 1      & 182.0  & 11.30  & 11.30  &  767   & 111.0  &  264.0 &  672  \\\\\n",
       "\t 1      & 1      & 186.0  &  9.26  & 37.10  &  958   & 233.0  &   73.0 &  347  \\\\\n",
       "\t 1      & 1      & 162.0  &  8.23  & 27.10  &  625   & 108.0  &   62.4 &  465  \\\\\n",
       "\t 1      & 1      & 150.0  &  6.63  & 21.00  &  627   & 140.0  &  179.0 &  639  \\\\\n",
       "\t 1      & 1      & 159.0  & 10.70  & 11.70  &  612   & 190.0  &   98.5 &  390  \\\\\n",
       "\t 1      & 1      & 117.0  & 16.10  &  7.04  &  988   &  95.5  &  136.0 &  572  \\\\\n",
       "\t 1      & 1      & 181.0  & 10.10  &  4.04  & 1437   & 184.0  &  101.0 &  542  \\\\\n",
       "\t 1      & 1      & 146.0  & 20.70  & 23.80  & 1232   & 128.0  &  150.0 & 1092  \\\\\n",
       "\t 1      & 1      &  42.3  & 10.30  &  9.70  &  629   &  93.7  &  439.0 &  888  \\\\\n",
       "\t 1      & 1      &  28.2  & 12.40  & 53.10  &  370   &  44.1  &  454.0 &  852  \\\\\n",
       "\t 1      & 1      & 154.0  & 13.80  & 53.30  &  621   & 105.0  &  160.0 &  723  \\\\\n",
       "\t 1      & 1      & 179.0  & 12.20  & 17.90  & 1139   & 150.0  &   45.2 &  218  \\\\\n",
       "\t 1      & 1      &  13.5  &  3.36  & 16.80  &  135   &  32.6  &   51.6 &  182  \\\\\n",
       "\t 1      & 1      & 175.0  &  5.84  & 24.90  &  807   & 123.0  &   55.6 &  126  \\\\\n",
       "\t 1      & 1      & 113.0  & 15.80  & 47.30  &  626   &  53.6  &  168.0 &  627  \\\\\n",
       "\t 1      & 1      &  50.5  & 11.60  &  6.30  &  608   &  58.9  &   58.9 &  139  \\\\\n",
       "\t 1      & 1      &  78.6  & 14.60  &  9.70  &  421   &  70.8  &  133.0 &  464  \\\\\n",
       "\t 1      & 1      &  90.0  &  3.27  &  8.17  &  622   &  52.3  &  770.0 &  852  \\\\\n",
       "\t 1      & 1      & 178.0  & 28.80  & 32.40  &  992   & 112.0  &   70.2 &  169  \\\\\n",
       "\t ... & ... & ... & ... & ... & ... & ... & ... & ...\\\\\n",
       "\t NA     & 2      &  58.2  &  5.42  & 29.70  &  323   & 138.0  &  179.0 &  513.0\\\\\n",
       "\t NA     & 2      & 106.0  &  1.87  & 40.50  &  542   & 177.0  &  184.0 &  427.0\\\\\n",
       "\t NA     & 2      & 152.0  &  0.80  & 12.50  & 1332   & 176.0  &  128.0 &  646.0\\\\\n",
       "\t NA     & 2      &  85.5  &  1.70  &  3.99  &  503   &  62.3  &  238.0 &  762.6\\\\\n",
       "\t NA     & 2      & 144.0  &  0.70  & 15.10  &  547   &  79.7  &   71.0 &  218.5\\\\\n",
       "\t NA     & 2      &  85.7  &  1.09  &  4.20  &  790   & 170.0  &   45.8 &  257.9\\\\\n",
       "\t NA     & 2      & 144.0  &  0.30  &  9.11  &  417   & 552.0  &   49.5 &  141.5\\\\\n",
       "\t NA     & 2      & 170.0  &  4.16  &  9.32  &  943   & 260.0  &  155.0 &  680.8\\\\\n",
       "\t NA     & 2      & 176.0  &  0.57  & 27.30  &  318   & 133.0  &   99.4 &  318.8\\\\\n",
       "\t NA     & 2      & 192.0  &  7.06  & 32.90  & 1969   & 343.0  &  103.0 &  553.0\\\\\n",
       "\t NA     & 2      & 188.0  &  8.28  & 22.60  & 1208   & 231.0  & 1314.0 & 1372.0\\\\\n",
       "\t NA     & 2      & 153.0  &  5.87  & 34.80  &  328   & 163.0  &  264.0 &  672.5\\\\\n",
       "\t NA     & 2      & 143.0  &  2.84  & 15.70  &  265   & 123.0  &   73.0 &  347.5\\\\\n",
       "\t NA     & 2      & 213.0  & 19.10  & 36.20  & 2220   & 249.0  &   62.0 &  465.8\\\\\n",
       "\t NA     & 2      & 192.0  & 20.10  & 23.80  & 1606   & 156.0  &   40.0 &  168.0\\\\\n",
       "\t NA     & 2      & 171.0  & 10.50  & 30.50  &  672   & 145.0  &   47.0 &  330.5\\\\\n",
       "\t NA     & 2      & 162.0  & 13.20  & 19.80  & 1521   & 166.0  &   36.2 &  133.0\\\\\n",
       "\t NA     & 2      & 203.0  & 13.00  & 90.80  & 1544   & 162.0  &   98.9 &  394.5\\\\\n",
       "\t NA     & 2      & 164.0  & 20.10  & 28.90  & 1062   & 161.0  &   47.3 &  134.5\\\\\n",
       "\t NA     & 2      & 167.0  & 13.10  & 14.10  & 2278   & 212.0  &   36.5 &   96.5\\\\\n",
       "\t NA     & 2      & 164.0  & 12.90  & 18.60  & 2993   & 197.0  &   65.5 &  237.8\\\\\n",
       "\t NA     & 2      & 167.0  & 15.00  & 27.00  & 2056   & 260.0  &   44.8 &   72.0\\\\\n",
       "\t NA     & 2      & 158.0  & 14.40  & 37.00  & 1025   & 101.0  &  180.0 &  899.5\\\\\n",
       "\t NA     & 2      & 133.0  & 22.80  & 31.30  & 1633   & 401.0  &  228.0 &  289.0\\\\\n",
       "\t NA     & 2      & 169.0  &  8.00  & 30.80  & 1068   &  99.1  &   53.0 &  817.0\\\\\n",
       "\t NA     & 2      & 247.0  & 17.30  &  8.65  & 2554   & 241.0  &   77.5 &  373.5\\\\\n",
       "\t NA     & 2      & 185.0  &  3.90  & 31.30  & 1211   & 190.0  &  134.0 &  649.8\\\\\n",
       "\t NA     & 2      & 209.0  &  6.43  & 86.90  & 2157   & 288.0  &   74.0 &  219.8\\\\\n",
       "\t NA     & 2      & 182.0  &  6.49  & 61.70  & 3870   & 432.0  &  143.0 &  367.5\\\\\n",
       "\t NA     & 2      & 235.0  & 15.60  & 23.40  & 1806   & 166.0  &   68.9 &  188.0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "    class train Zn    Cu    Fe    Ca   Mg    K      Na    \n",
       "1   1     1     166.0 15.80 24.50  700 112.0  179.0  513  \n",
       "2   1     1     185.0 15.70 31.50  701 125.0  184.0  427  \n",
       "3   1     1     193.0  9.80 25.90  541 163.0  128.0  642  \n",
       "4   1     1     159.0 14.20 39.70  896  99.2  239.0  726  \n",
       "5   1     1     226.0 16.20 23.80  606 152.0   70.3  218  \n",
       "6   1     1     171.0  9.29  9.29  307 187.0   45.5  257  \n",
       "7   1     1     201.0 13.30 26.60  551 101.0   49.4  141  \n",
       "8   1     1     147.0 14.50 30.00  659 102.0  154.0  680  \n",
       "9   1     1     172.0  8.85  7.86  551  75.7   98.4  318  \n",
       "10  1     1     156.0 11.50 32.50  639 107.0  103.0  552  \n",
       "11  1     1     132.0 15.90 17.70  578  92.4 1314.0 1372  \n",
       "12  1     1     182.0 11.30 11.30  767 111.0  264.0  672  \n",
       "13  1     1     186.0  9.26 37.10  958 233.0   73.0  347  \n",
       "14  1     1     162.0  8.23 27.10  625 108.0   62.4  465  \n",
       "15  1     1     150.0  6.63 21.00  627 140.0  179.0  639  \n",
       "16  1     1     159.0 10.70 11.70  612 190.0   98.5  390  \n",
       "17  1     1     117.0 16.10  7.04  988  95.5  136.0  572  \n",
       "18  1     1     181.0 10.10  4.04 1437 184.0  101.0  542  \n",
       "19  1     1     146.0 20.70 23.80 1232 128.0  150.0 1092  \n",
       "20  1     1      42.3 10.30  9.70  629  93.7  439.0  888  \n",
       "21  1     1      28.2 12.40 53.10  370  44.1  454.0  852  \n",
       "22  1     1     154.0 13.80 53.30  621 105.0  160.0  723  \n",
       "23  1     1     179.0 12.20 17.90 1139 150.0   45.2  218  \n",
       "24  1     1      13.5  3.36 16.80  135  32.6   51.6  182  \n",
       "25  1     1     175.0  5.84 24.90  807 123.0   55.6  126  \n",
       "26  1     1     113.0 15.80 47.30  626  53.6  168.0  627  \n",
       "27  1     1      50.5 11.60  6.30  608  58.9   58.9  139  \n",
       "28  1     1      78.6 14.60  9.70  421  70.8  133.0  464  \n",
       "29  1     1      90.0  3.27  8.17  622  52.3  770.0  852  \n",
       "30  1     1     178.0 28.80 32.40  992 112.0   70.2  169  \n",
       "... ...   ...   ...   ...   ...   ...  ...   ...    ...   \n",
       "61  NA    2      58.2  5.42 29.70  323 138.0  179.0  513.0\n",
       "62  NA    2     106.0  1.87 40.50  542 177.0  184.0  427.0\n",
       "63  NA    2     152.0  0.80 12.50 1332 176.0  128.0  646.0\n",
       "64  NA    2      85.5  1.70  3.99  503  62.3  238.0  762.6\n",
       "65  NA    2     144.0  0.70 15.10  547  79.7   71.0  218.5\n",
       "66  NA    2      85.7  1.09  4.20  790 170.0   45.8  257.9\n",
       "67  NA    2     144.0  0.30  9.11  417 552.0   49.5  141.5\n",
       "68  NA    2     170.0  4.16  9.32  943 260.0  155.0  680.8\n",
       "69  NA    2     176.0  0.57 27.30  318 133.0   99.4  318.8\n",
       "70  NA    2     192.0  7.06 32.90 1969 343.0  103.0  553.0\n",
       "71  NA    2     188.0  8.28 22.60 1208 231.0 1314.0 1372.0\n",
       "72  NA    2     153.0  5.87 34.80  328 163.0  264.0  672.5\n",
       "73  NA    2     143.0  2.84 15.70  265 123.0   73.0  347.5\n",
       "74  NA    2     213.0 19.10 36.20 2220 249.0   62.0  465.8\n",
       "75  NA    2     192.0 20.10 23.80 1606 156.0   40.0  168.0\n",
       "76  NA    2     171.0 10.50 30.50  672 145.0   47.0  330.5\n",
       "77  NA    2     162.0 13.20 19.80 1521 166.0   36.2  133.0\n",
       "78  NA    2     203.0 13.00 90.80 1544 162.0   98.9  394.5\n",
       "79  NA    2     164.0 20.10 28.90 1062 161.0   47.3  134.5\n",
       "80  NA    2     167.0 13.10 14.10 2278 212.0   36.5   96.5\n",
       "81  NA    2     164.0 12.90 18.60 2993 197.0   65.5  237.8\n",
       "82  NA    2     167.0 15.00 27.00 2056 260.0   44.8   72.0\n",
       "83  NA    2     158.0 14.40 37.00 1025 101.0  180.0  899.5\n",
       "84  NA    2     133.0 22.80 31.30 1633 401.0  228.0  289.0\n",
       "85  NA    2     169.0  8.00 30.80 1068  99.1   53.0  817.0\n",
       "86  NA    2     247.0 17.30  8.65 2554 241.0   77.5  373.5\n",
       "87  NA    2     185.0  3.90 31.30 1211 190.0  134.0  649.8\n",
       "88  NA    2     209.0  6.43 86.90 2157 288.0   74.0  219.8\n",
       "89  NA    2     182.0  6.49 61.70 3870 432.0  143.0  367.5\n",
       "90  NA    2     235.0 15.60 23.40 1806 166.0   68.9  188.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 427,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th scope=col>class</th><th scope=col>train</th><th scope=col>Zn</th><th scope=col>Cu</th><th scope=col>Fe</th><th scope=col>Ca</th><th scope=col>Mg</th><th scope=col>K</th><th scope=col>Na</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><td>1     </td><td>1     </td><td>166.0 </td><td> 15.80</td><td> 24.50</td><td> 700  </td><td> 112.0</td><td> 179.0</td><td> 513.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>185.0 </td><td> 15.70</td><td> 31.50</td><td> 701  </td><td> 125.0</td><td> 184.0</td><td> 427.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>193.0 </td><td>  9.80</td><td> 25.90</td><td> 541  </td><td> 163.0</td><td> 128.0</td><td> 642.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>159.0 </td><td> 14.20</td><td> 39.70</td><td> 896  </td><td>  99.2</td><td> 239.0</td><td> 726.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>226.0 </td><td> 16.20</td><td> 23.80</td><td> 606  </td><td> 152.0</td><td>  70.3</td><td> 218.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>171.0 </td><td>  9.29</td><td>  9.29</td><td> 307  </td><td> 187.0</td><td>  45.5</td><td> 257.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>201.0 </td><td> 13.30</td><td> 26.60</td><td> 551  </td><td> 101.0</td><td>  49.4</td><td> 141.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>147.0 </td><td> 14.50</td><td> 30.00</td><td> 659  </td><td> 102.0</td><td> 154.0</td><td> 680.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>172.0 </td><td>  8.85</td><td>  7.86</td><td> 551  </td><td>  75.7</td><td>  98.4</td><td> 318.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>156.0 </td><td> 11.50</td><td> 32.50</td><td> 639  </td><td> 107.0</td><td> 103.0</td><td> 552.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>132.0 </td><td> 15.90</td><td> 17.70</td><td> 578  </td><td>  92.4</td><td>1314.0</td><td>1372.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>182.0 </td><td> 11.30</td><td> 11.30</td><td> 767  </td><td> 111.0</td><td> 264.0</td><td> 672.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>186.0 </td><td>  9.26</td><td> 37.10</td><td> 958  </td><td> 233.0</td><td>  73.0</td><td> 347.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>162.0 </td><td>  8.23</td><td> 27.10</td><td> 625  </td><td> 108.0</td><td>  62.4</td><td> 465.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>150.0 </td><td>  6.63</td><td> 21.00</td><td> 627  </td><td> 140.0</td><td> 179.0</td><td> 639.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>159.0 </td><td> 10.70</td><td> 11.70</td><td> 612  </td><td> 190.0</td><td>  98.5</td><td> 390.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>117.0 </td><td> 16.10</td><td>  7.04</td><td> 988  </td><td>  95.5</td><td> 136.0</td><td> 572.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>181.0 </td><td> 10.10</td><td>  4.04</td><td>1437  </td><td> 184.0</td><td> 101.0</td><td> 542.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>146.0 </td><td> 20.70</td><td> 23.80</td><td>1232  </td><td> 128.0</td><td> 150.0</td><td>1092.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td> 42.3 </td><td> 10.30</td><td>  9.70</td><td> 629  </td><td>  93.7</td><td> 439.0</td><td> 888.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td> 28.2 </td><td> 12.40</td><td> 53.10</td><td> 370  </td><td>  44.1</td><td> 454.0</td><td> 852.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>154.0 </td><td> 13.80</td><td> 53.30</td><td> 621  </td><td> 105.0</td><td> 160.0</td><td> 723.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>179.0 </td><td> 12.20</td><td> 17.90</td><td>1139  </td><td> 150.0</td><td>  45.2</td><td> 218.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td> 13.5 </td><td>  3.36</td><td> 16.80</td><td> 135  </td><td>  32.6</td><td>  51.6</td><td> 182.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>175.0 </td><td>  5.84</td><td> 24.90</td><td> 807  </td><td> 123.0</td><td>  55.6</td><td> 126.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>113.0 </td><td> 15.80</td><td> 47.30</td><td> 626  </td><td>  53.6</td><td> 168.0</td><td> 627.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td> 50.5 </td><td> 11.60</td><td>  6.30</td><td> 608  </td><td>  58.9</td><td>  58.9</td><td> 139.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td> 78.6 </td><td> 14.60</td><td>  9.70</td><td> 421  </td><td>  70.8</td><td> 133.0</td><td> 464.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td> 90.0 </td><td>  3.27</td><td>  8.17</td><td> 622  </td><td>  52.3</td><td> 770.0</td><td> 852.0</td></tr>\n",
       "\t<tr><td>1     </td><td>1     </td><td>178.0 </td><td> 28.80</td><td> 32.40</td><td> 992  </td><td> 112.0</td><td>  70.2</td><td> 169.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>213.0 </td><td> 19.10</td><td> 36.20</td><td>2220  </td><td> 249.0</td><td>  40.0</td><td> 168.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>170.0 </td><td> 13.90</td><td> 29.80</td><td>1285  </td><td> 226.0</td><td>  47.9</td><td> 330.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>162.0 </td><td> 13.20</td><td> 19.80</td><td>1521  </td><td> 166.0</td><td>  36.2</td><td> 133.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>203.0 </td><td> 13.00</td><td> 90.80</td><td>1544  </td><td> 162.0</td><td>  98.9</td><td> 394.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>167.0 </td><td> 13.10</td><td> 14.10</td><td>2278  </td><td> 212.0</td><td>  46.3</td><td> 134.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>164.0 </td><td> 12.90</td><td> 18.60</td><td>2993  </td><td> 197.0</td><td>  36.3</td><td>  94.5</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>167.0 </td><td> 15.00</td><td> 27.00</td><td>2056  </td><td> 260.0</td><td>  64.6</td><td> 237.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>158.0 </td><td> 14.40</td><td> 37.00</td><td>1025  </td><td> 101.0</td><td>  44.6</td><td>  72.5</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>133.0 </td><td> 22.80</td><td> 31.00</td><td>1633  </td><td> 401.0</td><td> 180.0</td><td> 899.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>156.0 </td><td>135.00</td><td>322.00</td><td>6747  </td><td>1090.0</td><td> 228.0</td><td> 810.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>169.0 </td><td>  8.00</td><td>308.00</td><td>1068  </td><td>  99.1</td><td>  53.0</td><td> 289.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>247.0 </td><td> 17.30</td><td>  8.65</td><td>2554  </td><td> 241.0</td><td>  77.9</td><td> 373.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>166.0 </td><td>  8.10</td><td> 62.80</td><td>1233  </td><td> 252.0</td><td> 134.0</td><td> 649.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>209.0 </td><td>  6.43</td><td> 86.90</td><td>2157  </td><td> 288.0</td><td>  74.0</td><td> 219.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>182.0 </td><td>  6.49</td><td> 61.70</td><td>3870  </td><td> 432.0</td><td> 143.0</td><td> 367.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>235.0 </td><td> 15.60</td><td> 23.40</td><td>1806  </td><td> 166.0</td><td>  68.8</td><td> 188.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>173.0 </td><td> 19.10</td><td> 17.00</td><td>2497  </td><td> 295.0</td><td>  65.8</td><td> 287.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>151.0 </td><td> 19.70</td><td> 64.20</td><td>2031  </td><td> 403.0</td><td> 182.0</td><td> 874.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>191.0 </td><td> 65.40</td><td> 35.00</td><td>5361  </td><td> 392.0</td><td> 137.0</td><td> 688.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>223.0 </td><td> 24.40</td><td> 86.00</td><td>3603  </td><td> 353.0</td><td>  97.7</td><td> 479.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>221.0 </td><td> 20.10</td><td>155.00</td><td>3172  </td><td> 368.0</td><td> 150.0</td><td> 739.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>217.0 </td><td> 25.00</td><td> 28.20</td><td>2343  </td><td> 373.0</td><td> 110.0</td><td> 494.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>164.0 </td><td> 22.20</td><td> 35.50</td><td>2212  </td><td> 281.0</td><td> 153.0</td><td> 549.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>173.0 </td><td>  8.99</td><td> 36.00</td><td>1624  </td><td> 216.0</td><td> 103.0</td><td> 257.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>202.0 </td><td> 18.60</td><td> 17.70</td><td>3785  </td><td> 225.0</td><td>  31.0</td><td>  67.3</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>182.0 </td><td> 17.30</td><td> 24.80</td><td>3073  </td><td> 246.0</td><td>  50.7</td><td> 109.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>211.0 </td><td> 24.00</td><td> 17.00</td><td>3836  </td><td> 428.0</td><td>  73.5</td><td> 351.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>246.0 </td><td> 21.50</td><td> 93.20</td><td>2112  </td><td> 354.0</td><td>  71.7</td><td> 195.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>164.0 </td><td> 16.10</td><td> 38.00</td><td>2135  </td><td> 152.0</td><td>  64.3</td><td> 240.0</td></tr>\n",
       "\t<tr><td>2     </td><td>1     </td><td>179.0 </td><td> 21.00</td><td> 35.00</td><td>1560  </td><td> 226.0</td><td>  47.9</td><td> 330.0</td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|lllllllll}\n",
       " class & train & Zn & Cu & Fe & Ca & Mg & K & Na\\\\\n",
       "\\hline\n",
       "\t 1      & 1      & 166.0  &  15.80 &  24.50 &  700   &  112.0 &  179.0 &  513.0\\\\\n",
       "\t 1      & 1      & 185.0  &  15.70 &  31.50 &  701   &  125.0 &  184.0 &  427.0\\\\\n",
       "\t 1      & 1      & 193.0  &   9.80 &  25.90 &  541   &  163.0 &  128.0 &  642.0\\\\\n",
       "\t 1      & 1      & 159.0  &  14.20 &  39.70 &  896   &   99.2 &  239.0 &  726.0\\\\\n",
       "\t 1      & 1      & 226.0  &  16.20 &  23.80 &  606   &  152.0 &   70.3 &  218.0\\\\\n",
       "\t 1      & 1      & 171.0  &   9.29 &   9.29 &  307   &  187.0 &   45.5 &  257.0\\\\\n",
       "\t 1      & 1      & 201.0  &  13.30 &  26.60 &  551   &  101.0 &   49.4 &  141.0\\\\\n",
       "\t 1      & 1      & 147.0  &  14.50 &  30.00 &  659   &  102.0 &  154.0 &  680.0\\\\\n",
       "\t 1      & 1      & 172.0  &   8.85 &   7.86 &  551   &   75.7 &   98.4 &  318.0\\\\\n",
       "\t 1      & 1      & 156.0  &  11.50 &  32.50 &  639   &  107.0 &  103.0 &  552.0\\\\\n",
       "\t 1      & 1      & 132.0  &  15.90 &  17.70 &  578   &   92.4 & 1314.0 & 1372.0\\\\\n",
       "\t 1      & 1      & 182.0  &  11.30 &  11.30 &  767   &  111.0 &  264.0 &  672.0\\\\\n",
       "\t 1      & 1      & 186.0  &   9.26 &  37.10 &  958   &  233.0 &   73.0 &  347.0\\\\\n",
       "\t 1      & 1      & 162.0  &   8.23 &  27.10 &  625   &  108.0 &   62.4 &  465.0\\\\\n",
       "\t 1      & 1      & 150.0  &   6.63 &  21.00 &  627   &  140.0 &  179.0 &  639.0\\\\\n",
       "\t 1      & 1      & 159.0  &  10.70 &  11.70 &  612   &  190.0 &   98.5 &  390.0\\\\\n",
       "\t 1      & 1      & 117.0  &  16.10 &   7.04 &  988   &   95.5 &  136.0 &  572.0\\\\\n",
       "\t 1      & 1      & 181.0  &  10.10 &   4.04 & 1437   &  184.0 &  101.0 &  542.0\\\\\n",
       "\t 1      & 1      & 146.0  &  20.70 &  23.80 & 1232   &  128.0 &  150.0 & 1092.0\\\\\n",
       "\t 1      & 1      &  42.3  &  10.30 &   9.70 &  629   &   93.7 &  439.0 &  888.0\\\\\n",
       "\t 1      & 1      &  28.2  &  12.40 &  53.10 &  370   &   44.1 &  454.0 &  852.0\\\\\n",
       "\t 1      & 1      & 154.0  &  13.80 &  53.30 &  621   &  105.0 &  160.0 &  723.0\\\\\n",
       "\t 1      & 1      & 179.0  &  12.20 &  17.90 & 1139   &  150.0 &   45.2 &  218.0\\\\\n",
       "\t 1      & 1      &  13.5  &   3.36 &  16.80 &  135   &   32.6 &   51.6 &  182.0\\\\\n",
       "\t 1      & 1      & 175.0  &   5.84 &  24.90 &  807   &  123.0 &   55.6 &  126.0\\\\\n",
       "\t 1      & 1      & 113.0  &  15.80 &  47.30 &  626   &   53.6 &  168.0 &  627.0\\\\\n",
       "\t 1      & 1      &  50.5  &  11.60 &   6.30 &  608   &   58.9 &   58.9 &  139.0\\\\\n",
       "\t 1      & 1      &  78.6  &  14.60 &   9.70 &  421   &   70.8 &  133.0 &  464.0\\\\\n",
       "\t 1      & 1      &  90.0  &   3.27 &   8.17 &  622   &   52.3 &  770.0 &  852.0\\\\\n",
       "\t 1      & 1      & 178.0  &  28.80 &  32.40 &  992   &  112.0 &   70.2 &  169.0\\\\\n",
       "\t 2      & 1      & 213.0  &  19.10 &  36.20 & 2220   &  249.0 &   40.0 &  168.0\\\\\n",
       "\t 2      & 1      & 170.0  &  13.90 &  29.80 & 1285   &  226.0 &   47.9 &  330.0\\\\\n",
       "\t 2      & 1      & 162.0  &  13.20 &  19.80 & 1521   &  166.0 &   36.2 &  133.0\\\\\n",
       "\t 2      & 1      & 203.0  &  13.00 &  90.80 & 1544   &  162.0 &   98.9 &  394.0\\\\\n",
       "\t 2      & 1      & 167.0  &  13.10 &  14.10 & 2278   &  212.0 &   46.3 &  134.0\\\\\n",
       "\t 2      & 1      & 164.0  &  12.90 &  18.60 & 2993   &  197.0 &   36.3 &   94.5\\\\\n",
       "\t 2      & 1      & 167.0  &  15.00 &  27.00 & 2056   &  260.0 &   64.6 &  237.0\\\\\n",
       "\t 2      & 1      & 158.0  &  14.40 &  37.00 & 1025   &  101.0 &   44.6 &   72.5\\\\\n",
       "\t 2      & 1      & 133.0  &  22.80 &  31.00 & 1633   &  401.0 &  180.0 &  899.0\\\\\n",
       "\t 2      & 1      & 156.0  & 135.00 & 322.00 & 6747   & 1090.0 &  228.0 &  810.0\\\\\n",
       "\t 2      & 1      & 169.0  &   8.00 & 308.00 & 1068   &   99.1 &   53.0 &  289.0\\\\\n",
       "\t 2      & 1      & 247.0  &  17.30 &   8.65 & 2554   &  241.0 &   77.9 &  373.0\\\\\n",
       "\t 2      & 1      & 166.0  &   8.10 &  62.80 & 1233   &  252.0 &  134.0 &  649.0\\\\\n",
       "\t 2      & 1      & 209.0  &   6.43 &  86.90 & 2157   &  288.0 &   74.0 &  219.0\\\\\n",
       "\t 2      & 1      & 182.0  &   6.49 &  61.70 & 3870   &  432.0 &  143.0 &  367.0\\\\\n",
       "\t 2      & 1      & 235.0  &  15.60 &  23.40 & 1806   &  166.0 &   68.8 &  188.0\\\\\n",
       "\t 2      & 1      & 173.0  &  19.10 &  17.00 & 2497   &  295.0 &   65.8 &  287.0\\\\\n",
       "\t 2      & 1      & 151.0  &  19.70 &  64.20 & 2031   &  403.0 &  182.0 &  874.0\\\\\n",
       "\t 2      & 1      & 191.0  &  65.40 &  35.00 & 5361   &  392.0 &  137.0 &  688.0\\\\\n",
       "\t 2      & 1      & 223.0  &  24.40 &  86.00 & 3603   &  353.0 &   97.7 &  479.0\\\\\n",
       "\t 2      & 1      & 221.0  &  20.10 & 155.00 & 3172   &  368.0 &  150.0 &  739.0\\\\\n",
       "\t 2      & 1      & 217.0  &  25.00 &  28.20 & 2343   &  373.0 &  110.0 &  494.0\\\\\n",
       "\t 2      & 1      & 164.0  &  22.20 &  35.50 & 2212   &  281.0 &  153.0 &  549.0\\\\\n",
       "\t 2      & 1      & 173.0  &   8.99 &  36.00 & 1624   &  216.0 &  103.0 &  257.0\\\\\n",
       "\t 2      & 1      & 202.0  &  18.60 &  17.70 & 3785   &  225.0 &   31.0 &   67.3\\\\\n",
       "\t 2      & 1      & 182.0  &  17.30 &  24.80 & 3073   &  246.0 &   50.7 &  109.0\\\\\n",
       "\t 2      & 1      & 211.0  &  24.00 &  17.00 & 3836   &  428.0 &   73.5 &  351.0\\\\\n",
       "\t 2      & 1      & 246.0  &  21.50 &  93.20 & 2112   &  354.0 &   71.7 &  195.0\\\\\n",
       "\t 2      & 1      & 164.0  &  16.10 &  38.00 & 2135   &  152.0 &   64.3 &  240.0\\\\\n",
       "\t 2      & 1      & 179.0  &  21.00 &  35.00 & 1560   &  226.0 &   47.9 &  330.0\\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "   class train Zn    Cu     Fe     Ca   Mg     K      Na    \n",
       "1  1     1     166.0  15.80  24.50  700  112.0  179.0  513.0\n",
       "2  1     1     185.0  15.70  31.50  701  125.0  184.0  427.0\n",
       "3  1     1     193.0   9.80  25.90  541  163.0  128.0  642.0\n",
       "4  1     1     159.0  14.20  39.70  896   99.2  239.0  726.0\n",
       "5  1     1     226.0  16.20  23.80  606  152.0   70.3  218.0\n",
       "6  1     1     171.0   9.29   9.29  307  187.0   45.5  257.0\n",
       "7  1     1     201.0  13.30  26.60  551  101.0   49.4  141.0\n",
       "8  1     1     147.0  14.50  30.00  659  102.0  154.0  680.0\n",
       "9  1     1     172.0   8.85   7.86  551   75.7   98.4  318.0\n",
       "10 1     1     156.0  11.50  32.50  639  107.0  103.0  552.0\n",
       "11 1     1     132.0  15.90  17.70  578   92.4 1314.0 1372.0\n",
       "12 1     1     182.0  11.30  11.30  767  111.0  264.0  672.0\n",
       "13 1     1     186.0   9.26  37.10  958  233.0   73.0  347.0\n",
       "14 1     1     162.0   8.23  27.10  625  108.0   62.4  465.0\n",
       "15 1     1     150.0   6.63  21.00  627  140.0  179.0  639.0\n",
       "16 1     1     159.0  10.70  11.70  612  190.0   98.5  390.0\n",
       "17 1     1     117.0  16.10   7.04  988   95.5  136.0  572.0\n",
       "18 1     1     181.0  10.10   4.04 1437  184.0  101.0  542.0\n",
       "19 1     1     146.0  20.70  23.80 1232  128.0  150.0 1092.0\n",
       "20 1     1      42.3  10.30   9.70  629   93.7  439.0  888.0\n",
       "21 1     1      28.2  12.40  53.10  370   44.1  454.0  852.0\n",
       "22 1     1     154.0  13.80  53.30  621  105.0  160.0  723.0\n",
       "23 1     1     179.0  12.20  17.90 1139  150.0   45.2  218.0\n",
       "24 1     1      13.5   3.36  16.80  135   32.6   51.6  182.0\n",
       "25 1     1     175.0   5.84  24.90  807  123.0   55.6  126.0\n",
       "26 1     1     113.0  15.80  47.30  626   53.6  168.0  627.0\n",
       "27 1     1      50.5  11.60   6.30  608   58.9   58.9  139.0\n",
       "28 1     1      78.6  14.60   9.70  421   70.8  133.0  464.0\n",
       "29 1     1      90.0   3.27   8.17  622   52.3  770.0  852.0\n",
       "30 1     1     178.0  28.80  32.40  992  112.0   70.2  169.0\n",
       "31 2     1     213.0  19.10  36.20 2220  249.0   40.0  168.0\n",
       "32 2     1     170.0  13.90  29.80 1285  226.0   47.9  330.0\n",
       "33 2     1     162.0  13.20  19.80 1521  166.0   36.2  133.0\n",
       "34 2     1     203.0  13.00  90.80 1544  162.0   98.9  394.0\n",
       "35 2     1     167.0  13.10  14.10 2278  212.0   46.3  134.0\n",
       "36 2     1     164.0  12.90  18.60 2993  197.0   36.3   94.5\n",
       "37 2     1     167.0  15.00  27.00 2056  260.0   64.6  237.0\n",
       "38 2     1     158.0  14.40  37.00 1025  101.0   44.6   72.5\n",
       "39 2     1     133.0  22.80  31.00 1633  401.0  180.0  899.0\n",
       "40 2     1     156.0 135.00 322.00 6747 1090.0  228.0  810.0\n",
       "41 2     1     169.0   8.00 308.00 1068   99.1   53.0  289.0\n",
       "42 2     1     247.0  17.30   8.65 2554  241.0   77.9  373.0\n",
       "43 2     1     166.0   8.10  62.80 1233  252.0  134.0  649.0\n",
       "44 2     1     209.0   6.43  86.90 2157  288.0   74.0  219.0\n",
       "45 2     1     182.0   6.49  61.70 3870  432.0  143.0  367.0\n",
       "46 2     1     235.0  15.60  23.40 1806  166.0   68.8  188.0\n",
       "47 2     1     173.0  19.10  17.00 2497  295.0   65.8  287.0\n",
       "48 2     1     151.0  19.70  64.20 2031  403.0  182.0  874.0\n",
       "49 2     1     191.0  65.40  35.00 5361  392.0  137.0  688.0\n",
       "50 2     1     223.0  24.40  86.00 3603  353.0   97.7  479.0\n",
       "51 2     1     221.0  20.10 155.00 3172  368.0  150.0  739.0\n",
       "52 2     1     217.0  25.00  28.20 2343  373.0  110.0  494.0\n",
       "53 2     1     164.0  22.20  35.50 2212  281.0  153.0  549.0\n",
       "54 2     1     173.0   8.99  36.00 1624  216.0  103.0  257.0\n",
       "55 2     1     202.0  18.60  17.70 3785  225.0   31.0   67.3\n",
       "56 2     1     182.0  17.30  24.80 3073  246.0   50.7  109.0\n",
       "57 2     1     211.0  24.00  17.00 3836  428.0   73.5  351.0\n",
       "58 2     1     246.0  21.50  93.20 2112  354.0   71.7  195.0\n",
       "59 2     1     164.0  16.10  38.00 2135  152.0   64.3  240.0\n",
       "60 2     1     179.0  21.00  35.00 1560  226.0   47.9  330.0"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 448,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<dl>\n",
       "\t<dt>$fisher.predict</dt>\n",
       "\t\t<dd>0.933333333333333</dd>\n",
       "\t<dt>$bayes.predict</dt>\n",
       "\t\t<dd>0.933333333333333</dd>\n",
       "\t<dt>$distance.predict</dt>\n",
       "\t\t<dd>0.883333333333333</dd>\n",
       "</dl>\n"
      ],
      "text/latex": [
       "\\begin{description}\n",
       "\\item[\\$fisher.predict] 0.933333333333333\n",
       "\\item[\\$bayes.predict] 0.933333333333333\n",
       "\\item[\\$distance.predict] 0.883333333333333\n",
       "\\end{description}\n"
      ],
      "text/markdown": [
       "$fisher.predict\n",
       ":   0.933333333333333\n",
       "$bayes.predict\n",
       ":   0.933333333333333\n",
       "$distance.predict\n",
       ":   0.883333333333333\n",
       "\n",
       "\n"
      ],
      "text/plain": [
       "$fisher.predict\n",
       "[1] 0.9333333\n",
       "\n",
       "$bayes.predict\n",
       "[1] 0.9333333\n",
       "\n",
       "$distance.predict\n",
       "[1] 0.8833333\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model <- discriminant(df[df$train == 1,], c('Zn','Cu','Fe','Ca','Mg','K','Na' ), 'class')\n",
    "\n",
    "lapply(predict(model, df[df$train == 1,], c('Zn','Cu','Fe','Ca','Mg','K','Na' )),function(pred){\n",
    "  mean(pred == df[df$train == 1,]$class )\n",
    "})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 452,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "pred <- predict(model, df, c('Zn','Cu','Fe','Ca','Mg','K','Na' ))\n",
    "df$fisher.predict <- pred$fisher.predict\n",
    "df$bayes.predict <- pred$bayes.predict\n",
    "df$distance.predict <- pred$distance.predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 460,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table>\n",
       "<thead><tr><th></th><th scope=col>class</th><th scope=col>train</th><th scope=col>Zn</th><th scope=col>Cu</th><th scope=col>Fe</th><th scope=col>Ca</th><th scope=col>Mg</th><th scope=col>K</th><th scope=col>Na</th><th scope=col>fisher.predict</th><th scope=col>bayes.predict</th><th scope=col>distance.predict</th></tr></thead>\n",
       "<tbody>\n",
       "\t<tr><th scope=row>85</th><td>NA   </td><td>2    </td><td>169  </td><td> 8.00</td><td>30.80</td><td>1068 </td><td> 99.1</td><td> 53.0</td><td>817.0</td><td>1    </td><td>1    </td><td>1    </td></tr>\n",
       "\t<tr><th scope=row>86</th><td>NA   </td><td>2    </td><td>247  </td><td>17.30</td><td> 8.65</td><td>2554 </td><td>241.0</td><td> 77.5</td><td>373.5</td><td>2    </td><td>2    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>87</th><td>NA   </td><td>2    </td><td>185  </td><td> 3.90</td><td>31.30</td><td>1211 </td><td>190.0</td><td>134.0</td><td>649.8</td><td>2    </td><td>2    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>88</th><td>NA   </td><td>2    </td><td>209  </td><td> 6.43</td><td>86.90</td><td>2157 </td><td>288.0</td><td> 74.0</td><td>219.8</td><td>2    </td><td>2    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>89</th><td>NA   </td><td>2    </td><td>182  </td><td> 6.49</td><td>61.70</td><td>3870 </td><td>432.0</td><td>143.0</td><td>367.5</td><td>2    </td><td>2    </td><td>2    </td></tr>\n",
       "\t<tr><th scope=row>90</th><td>NA   </td><td>2    </td><td>235  </td><td>15.60</td><td>23.40</td><td>1806 </td><td>166.0</td><td> 68.9</td><td>188.0</td><td>2    </td><td>2    </td><td>2    </td></tr>\n",
       "</tbody>\n",
       "</table>\n"
      ],
      "text/latex": [
       "\\begin{tabular}{r|llllllllllll}\n",
       "  & class & train & Zn & Cu & Fe & Ca & Mg & K & Na & fisher.predict & bayes.predict & distance.predict\\\\\n",
       "\\hline\n",
       "\t85 & NA    & 2     & 169   &  8.00 & 30.80 & 1068  &  99.1 &  53.0 & 817.0 & 1     & 1     & 1    \\\\\n",
       "\t86 & NA    & 2     & 247   & 17.30 &  8.65 & 2554  & 241.0 &  77.5 & 373.5 & 2     & 2     & 2    \\\\\n",
       "\t87 & NA    & 2     & 185   &  3.90 & 31.30 & 1211  & 190.0 & 134.0 & 649.8 & 2     & 2     & 2    \\\\\n",
       "\t88 & NA    & 2     & 209   &  6.43 & 86.90 & 2157  & 288.0 &  74.0 & 219.8 & 2     & 2     & 2    \\\\\n",
       "\t89 & NA    & 2     & 182   &  6.49 & 61.70 & 3870  & 432.0 & 143.0 & 367.5 & 2     & 2     & 2    \\\\\n",
       "\t90 & NA    & 2     & 235   & 15.60 & 23.40 & 1806  & 166.0 &  68.9 & 188.0 & 2     & 2     & 2    \\\\\n",
       "\\end{tabular}\n"
      ],
      "text/plain": [
       "   class train Zn  Cu    Fe    Ca   Mg    K     Na    fisher.predict\n",
       "85 NA    2     169  8.00 30.80 1068  99.1  53.0 817.0 1             \n",
       "86 NA    2     247 17.30  8.65 2554 241.0  77.5 373.5 2             \n",
       "87 NA    2     185  3.90 31.30 1211 190.0 134.0 649.8 2             \n",
       "88 NA    2     209  6.43 86.90 2157 288.0  74.0 219.8 2             \n",
       "89 NA    2     182  6.49 61.70 3870 432.0 143.0 367.5 2             \n",
       "90 NA    2     235 15.60 23.40 1806 166.0  68.9 188.0 2             \n",
       "   bayes.predict distance.predict\n",
       "85 1             1               \n",
       "86 2             2               \n",
       "87 2             2               \n",
       "88 2             2               \n",
       "89 2             2               \n",
       "90 2             2               "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "tail(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 461,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "$pl\n",
       "$pl[[1]]\n",
       "$pl[[1]]$mu\n",
       "       Zn        Cu        Fe        Ca        Mg         K        Na \n",
       "143.10333  12.33433  23.06667 698.16667 113.39333 201.13333 526.83333 \n",
       "\n",
       "$pl[[1]]$sigma\n",
       "            Zn          Cu         Fe         Ca            Mg           K\n",
       "Zn  1416.37406  31.1317554   31.86480  2982.0082   856.2023842 -1953.77904\n",
       "Cu    31.13176  12.5482837   10.01260   244.3886     0.9735062   -11.94204\n",
       "Fe    31.86480  10.0125989   92.92275  -125.1780   -26.6978588   -92.10420\n",
       "Ca  2982.00819 244.3886158 -125.17802 35884.1384  2679.5802260 -4570.79605\n",
       "Mg   856.20238   0.9735062  -26.69786  2679.5802  1078.6789605 -1795.59192\n",
       "K  -1953.77904 -11.9420395  -92.10420 -4570.7960 -1795.5919209 33171.57537\n",
       "Na -1911.36412  85.9462994  280.77362  3625.7938 -1316.4225989 29142.82147\n",
       "           Na\n",
       "Zn -1911.3641\n",
       "Cu    85.9463\n",
       "Fe   280.7736\n",
       "Ca  3625.7938\n",
       "Mg -1316.4226\n",
       "K  29142.8215\n",
       "Na 44409.5960\n",
       "\n",
       "$pl[[1]]$sigma.inv\n",
       "              Zn            Cu            Fe            Ca            Mg\n",
       "Zn  1.669667e-03 -3.007345e-03 -0.0009784991 -4.674767e-05 -1.214622e-03\n",
       "Cu -3.007345e-03  1.124955e-01 -0.0106620661 -8.366107e-04  4.022535e-03\n",
       "Fe -9.784991e-04 -1.066207e-02  0.0140825825  2.237936e-04  7.388680e-04\n",
       "Ca -4.674767e-05 -8.366107e-04  0.0002237936  4.746286e-05 -6.936208e-05\n",
       "Mg -1.214622e-03  4.022535e-03  0.0007388680 -6.936208e-05  2.155040e-03\n",
       "K  -5.443201e-05  4.067632e-05  0.0003361868  1.688723e-05  8.224392e-05\n",
       "Na  8.739985e-05 -1.188878e-04 -0.0003274995 -1.882083e-05 -4.915933e-05\n",
       "               K            Na\n",
       "Zn -5.443201e-05  8.739985e-05\n",
       "Cu  4.067632e-05 -1.188878e-04\n",
       "Fe  3.361868e-04 -3.274995e-04\n",
       "Ca  1.688723e-05 -1.882083e-05\n",
       "Mg  8.224392e-05 -4.915933e-05\n",
       "K   8.910003e-05 -6.195768e-05\n",
       "Na -6.195768e-05  6.931772e-05\n",
       "\n",
       "\n",
       "$pl[[2]]\n",
       "$pl[[2]]$mu\n",
       "        Zn         Cu         Fe         Ca         Mg          K         Na \n",
       " 186.60000   21.92367   62.01167 2511.13333  295.13667   90.37000  367.21000 \n",
       "\n",
       "$pl[[2]]$sigma\n",
       "           Zn         Cu          Fe         Ca         Mg          K\n",
       "Zn  433.07119   -38.1418   -86.15186   2324.078  -175.3925  -163.5705\n",
       "Cu  -38.14180   277.3659   460.56715  11546.657  1788.7580   334.4779\n",
       "Fe  -86.15186   460.5671  2822.52455  13978.915  3285.1144   776.2226\n",
       "Ca 2324.07797 11546.6570 13978.91531 794785.788 85979.5450 13751.1647\n",
       "Mg -175.39254  1788.7580  3285.11444  85979.545 15498.1398  3275.3862\n",
       "K  -163.57051   334.4779   776.22264  13751.165  3275.3862  1294.4570\n",
       "Na -731.93186  1338.1927  3116.25486  46358.854 12868.0396  5622.0512\n",
       "           Na\n",
       "Zn  -731.9319\n",
       "Cu  1338.1927\n",
       "Fe  3116.2549\n",
       "Ca 46358.8536\n",
       "Mg 12868.0396\n",
       "K   5622.0512\n",
       "Na 29321.7672\n",
       "\n",
       "$pl[[2]]$sigma.inv\n",
       "              Zn            Cu            Fe            Ca            Mg\n",
       "Zn  2.801674e-03  0.0019714476 -9.884740e-05 -3.441886e-05 -1.008037e-04\n",
       "Cu  1.971448e-03  0.0195379658 -9.904885e-04 -1.231516e-04 -1.633713e-03\n",
       "Fe -9.884740e-05 -0.0009904885  5.338073e-04  1.248457e-05 -4.905530e-05\n",
       "Ca -3.441886e-05 -0.0001231516  1.248457e-05  4.584353e-06 -1.655387e-05\n",
       "Mg -1.008037e-04 -0.0016337126 -4.905530e-05 -1.655387e-05  4.914278e-04\n",
       "K   8.221854e-04  0.0028632728 -1.921765e-04 -1.086177e-05 -8.450114e-04\n",
       "Na -6.851945e-05 -0.0003745205  2.464166e-05  5.533744e-06  4.978256e-05\n",
       "               K            Na\n",
       "Zn  8.221854e-04 -6.851945e-05\n",
       "Cu  2.863273e-03 -3.745205e-04\n",
       "Fe -1.921765e-04  2.464166e-05\n",
       "Ca -1.086177e-05  5.533744e-06\n",
       "Mg -8.450114e-04  4.978256e-05\n",
       "K   7.233491e-03 -1.088639e-03\n",
       "Na -1.088639e-03  2.250029e-04\n",
       "\n",
       "\n",
       "\n",
       "$fisher.a\n",
       "           [,1]       [,2]       [,3]       [,4]       [,5]        [,6]\n",
       "[1,] 0.01983756 -0.9931298 0.09683571 0.01793796 0.05708433 0.003938765\n",
       "            [,7]\n",
       "[1,] -0.01807459\n",
       "\n",
       "$fisher.kf\n",
       "         [,1]     [,2]\n",
       "[1,] 3.089496 43.54466\n",
       "\n",
       "$fisher.n\n",
       "[1] 1\n",
       "\n",
       "$decode\n",
       "[1] 1 2\n",
       "\n",
       "attr(,\"class\")\n",
       "[1] \"discriminant\""
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "R 3.3",
   "language": "R",
   "name": "ir33"
  },
  "language_info": {
   "codemirror_mode": "r",
   "file_extension": ".r",
   "mimetype": "text/x-r-source",
   "name": "R",
   "pygments_lexer": "r",
   "version": "3.3.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
